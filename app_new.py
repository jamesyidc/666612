#!/usr/bin/env python3
"""
åŠ å¯†è´§å¸æ•°æ®åˆ†æç³»ç»Ÿ - å®Œå…¨ä»¿ç…§å‚è€ƒé¡µé¢é£æ ¼
"""
from flask import Flask, render_template_string, render_template, request, jsonify, send_from_directory, make_response, redirect
import sqlite3
from datetime import datetime, timedelta
import json
import pytz
import os
from functools import wraps
import time
import traceback

app = Flask(__name__)
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

def get_china_today():
    """è·å–ä¸­å›½æ—¶åŒºçš„ä»Šæ—¥æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)"""
    return datetime.now(BEIJING_TZ).strftime('%Y-%m-%d')

def get_china_now():
    """è·å–ä¸­å›½æ—¶åŒºçš„å½“å‰æ—¶é—´"""
    return datetime.now(BEIJING_TZ)

# å¯¼å…¥äº¤æ˜“API Blueprint
from trading_api import trading_bp
app.register_blueprint(trading_bp)

# Kçº¿å›¾æœåŠ¡URLé…ç½®
CHART_BASE_URL = "https://5000-iz6uddj6rs3xe48ilsyqq-2e1b9533.sandbox.novita.ai"

# ============================================
# æœåŠ¡å™¨ç«¯ç¼“å­˜ç³»ç»Ÿ
# ============================================
class ServerCache:
    """æœåŠ¡å™¨ç«¯å†…å­˜ç¼“å­˜ï¼Œå­˜å‚¨è®¡ç®—ç»“æœ"""
    def __init__(self):
        self.cache = {}
        self.timestamps = {}
        
    def get(self, key, max_age=60):
        """
        è·å–ç¼“å­˜æ•°æ®
        key: ç¼“å­˜é”®
        max_age: æœ€å¤§ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
        """
        if key not in self.cache:
            return None
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if time.time() - self.timestamps.get(key, 0) > max_age:
            # è¿‡æœŸï¼Œåˆ é™¤ç¼“å­˜
            del self.cache[key]
            del self.timestamps[key]
            return None
        
        return self.cache[key]
    
    def set(self, key, value):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self.cache[key] = value
        self.timestamps[key] = time.time()
    
    def clear(self, key=None):
        """æ¸…é™¤ç¼“å­˜"""
        if key:
            if key in self.cache:
                del self.cache[key]
            if key in self.timestamps:
                del self.timestamps[key]
        else:
            self.cache.clear()
            self.timestamps.clear()
    
    def get_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_keys': len(self.cache),
            'keys': list(self.cache.keys())
        }

# åˆ›å»ºå…¨å±€ç¼“å­˜å®ä¾‹
server_cache = ServerCache()

def cached_response(max_age=60):
    """
    ç¼“å­˜è£…é¥°å™¨ - åœ¨æœåŠ¡å™¨ç«¯ç¼“å­˜APIå“åº”
    max_age: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{f.__name__}:{':'.join(map(str, args))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = server_cache.get(cache_key, max_age=max_age)
            if cached_data is not None:
                # åˆ›å»ºå“åº”å‰¯æœ¬å¹¶æ·»åŠ ç¼“å­˜æ ‡è®°
                response_data = cached_data.copy()
                response_data['_from_server_cache'] = True
                response_data['_cache_age_seconds'] = int(time.time() - server_cache.timestamps.get(cache_key, 0))
                return jsonify(response_data)
            
            # æ‰§è¡ŒåŸå‡½æ•°è·å–ç»“æœ
            result = f(*args, **kwargs)
            
            # æå–å¹¶ç¼“å­˜JSONæ•°æ®
            if hasattr(result, 'json') and callable(result.json):
                try:
                    data = result.json
                    if isinstance(data, dict) and data.get('success'):
                        server_cache.set(cache_key, data)
                except:
                    pass
            
            return result
        
        return decorated_function
    return decorator

# ä¸»é¡µé¢HTML - å®Œå…¨ä»¿ç…§å‚è€ƒè®¾è®¡
MAIN_HTML = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>åŠ å¯†è´§å¸æ•°æ®å†å²å›çœ‹</title>
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.4.3/dist/echarts.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            background: #1e2139;
            color: #fff;
            overflow-x: hidden;
        }
        
        .container {
            max-width: 100%;
            margin: 0 auto;
            padding: 0;
        }
        
        /* é¡¶éƒ¨å¯¼èˆªæ  */
        .top-nav {
            background: #2a2d47;
            padding: 12px 20px;
            display: flex;
            align-items: center;
            gap: 15px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.3);
            justify-content: space-between;
        }
        
        .nav-left {
            display: flex;
            align-items: center;
            gap: 15px;
        }
        
        .nav-right {
            display: flex;
            gap: 10px;
        }
        
        /* ç³»ç»Ÿå¯¼èˆªæ  */
        .systems-nav {
            background: linear-gradient(135deg, #2a2d47 0%, #3a3d5c 100%);
            padding: 15px 20px;
            border-bottom: 2px solid #3b7dff;
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            align-items: center;
        }
        
        .systems-nav-title {
            font-size: 14px;
            font-weight: 600;
            color: #8b92b8;
            margin-right: 10px;
        }
        
        .system-link {
            background: rgba(59, 125, 255, 0.1);
            border: 1px solid rgba(59, 125, 255, 0.3);
            color: #00d4ff;
            padding: 8px 16px;
            border-radius: 6px;
            font-size: 13px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 6px;
        }
        
        .system-link:hover {
            background: rgba(59, 125, 255, 0.2);
            border-color: #3b7dff;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(59, 125, 255, 0.3);
        }
        
        .system-link.featured {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            color: #fff;
        }
        
        .system-link.featured:hover {
            background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
        }
        
        .home-btn {
            background: linear-gradient(135deg, #00d4ff 0%, #0099ff 100%);
            color: #fff;
            border: none;
            padding: 8px 20px;
            border-radius: 6px;
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 6px;
        }
        
        .home-btn:hover {
            background: linear-gradient(135deg, #0099ff 0%, #00d4ff 100%);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 212, 255, 0.4);
        }
        
        .nav-brand {
            display: flex;
            align-items: center;
            gap: 8px;
            background: #3b7dff;
            padding: 6px 15px;
            border-radius: 6px;
            font-size: 14px;
            font-weight: 500;
        }
        
        .nav-title {
            font-size: 18px;
            font-weight: 500;
            color: #fff;
            margin-left: 10px;
        }
        
        /* æ§åˆ¶æ  */
        .control-bar {
            background: #2a2d47;
            padding: 15px 20px;
            display: flex;
            align-items: center;
            gap: 15px;
            flex-wrap: wrap;
            border-bottom: 1px solid #3a3d5c;
        }
        
        .control-group {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .control-label {
            color: #8b92b8;
            font-size: 13px;
        }
        
        .control-input {
            background: #1e2139;
            border: 1px solid #3a3d5c;
            color: #fff;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 13px;
            outline: none;
        }
        
        .control-input:focus {
            border-color: #3b7dff;
        }
        
        .control-btn {
            background: #3b7dff;
            border: none;
            color: white;
            padding: 7px 18px;
            border-radius: 4px;
            font-size: 13px;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .control-btn:hover {
            background: #2563eb;
        }
        
        .control-btn.secondary {
            background: #4a5178;
        }
        
        .control-btn.secondary:hover {
            background: #5a6188;
        }
        
        /* æ•°æ®ç»Ÿè®¡æ  */
        .stats-bar {
            background: #2a2d47;
            padding: 12px 20px;
            display: flex;
            gap: 25px;
            flex-wrap: wrap;
            border-bottom: 1px solid #3a3d5c;
            font-size: 13px;
        }
        
        .stat-item {
            display: flex;
            gap: 5px;
        }
        
        .stat-label {
            color: #8b92b8;
        }
        
        .stat-value {
            color: #fff;
            font-weight: 500;
            margin-left: 8px;
        }
        
        .stat-value.rise {
            color: #10b981;
        }
        
        .stat-value.fall {
            color: #ef4444;
        }
        
        /* æ¬¡çº§ç»Ÿè®¡æ  */
        .secondary-stats {
            background: #1e2139;
            padding: 10px 20px;
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            font-size: 13px;
        }
        
        /* æ—¶é—´è½´å®¹å™¨ - ç«–ç›´å¸ƒå±€ */
        .timeline-container {
            background: #2a2d47;
            padding: 15px 20px;
            border-top: 1px solid #3a3d5c;
            max-height: 500px;  /* å¢åŠ é«˜åº¦ä»¥æ˜¾ç¤ºæ›´å¤šä¿¡æ¯ */
            overflow-y: auto;
        }
        
        .timeline-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            position: sticky;
            top: 0;
            background: #2a2d47;
            padding-bottom: 10px;
            border-bottom: 1px solid #3a3d5c;
        }
        
        .timeline-title {
            color: #8b92b8;
            font-size: 13px;
            font-weight: 500;
        }
        
        .timeline-info {
            color: #3b7dff;
            font-size: 12px;
        }
        
        /* ç«–ç›´æ—¶é—´è½´è½¨é“ */
        .timeline-track {
            position: relative;
            padding-left: 30px;
            margin-top: 10px;
        }
        
        /* ç«–ç›´çº¿ */
        .timeline-line {
            position: absolute;
            left: 15px;
            top: 0;
            bottom: 0;
            width: 2px;
            background: #3a3d5c;
        }
        
        /* ç«–ç›´æ’åˆ—çš„æ—¶é—´ç‚¹å®¹å™¨ */
        .timeline-points {
            display: flex;
            flex-direction: column;
            gap: 20px;  /* å¢åŠ é—´è·ä»¥å®¹çº³æ›´å¤šä¿¡æ¯ */
        }
        
        /* æ—¶é—´ç‚¹é¡¹ */
        .timeline-point {
            position: relative;
            display: flex;
            align-items: flex-start;  /* æ”¹ä¸ºé¡¶éƒ¨å¯¹é½ï¼Œé€‚åº”å¤šè¡Œå†…å®¹ */
            cursor: pointer;
            padding: 10px 12px;  /* å¢åŠ padding */
            border-radius: 4px;
            transition: all 0.3s;
            min-height: 80px;  /* æœ€å°é«˜åº¦ç¡®ä¿æ˜¾ç¤ºå¤šè¡Œä¿¡æ¯ */
        }
        
        .timeline-point:hover {
            background: rgba(59, 125, 255, 0.1);
        }
        
        /* æ—¶é—´ç‚¹åœ†åœˆ */
        .timeline-point::before {
            content: '';
            position: absolute;
            left: -22px;
            width: 12px;
            height: 12px;
            background: #3b7dff;
            border: 2px solid #2a2d47;
            border-radius: 50%;
            transition: all 0.3s;
            z-index: 2;
        }
        
        .timeline-point:hover::before {
            width: 16px;
            height: 16px;
            left: -24px;
            background: #2563eb;
            box-shadow: 0 0 10px rgba(59, 125, 255, 0.5);
        }
        
        .timeline-point.active::before {
            background: #10b981;
            width: 16px;
            height: 16px;
            left: -24px;
            box-shadow: 0 0 8px rgba(16, 185, 129, 0.5);
        }
        
        /* æ—¶é—´æ ‡ç­¾ */
        .timeline-label {
            color: #8b92b8;
            font-size: 12px;
            display: flex;
            flex-direction: column;
            gap: 2px;
        }
        
        .timeline-point:hover .timeline-label {
            color: #fff;
        }
        
        .timeline-point.active .timeline-label {
            color: #10b981;
            font-weight: 500;
        }
        
        .timeline-label-time {
            font-size: 13px;
            font-weight: 500;
        }
        
        .timeline-label-stats {
            font-size: 11px;
            opacity: 0.85;
            line-height: 1.5;
            color: #a0aec0;
            max-width: 600px;  /* é™åˆ¶æœ€å¤§å®½åº¦ */
        }
        
        .timeline-label-stats div {
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        
        /* å›¾è¡¨åŒºåŸŸ */
        .chart-section {
            background: #2a2d47;
            margin: 0;
            padding: 20px;
        }
        
        .chart-title {
            color: #8b92b8;
            font-size: 14px;
            margin-bottom: 15px;
            text-align: center;
        }
        
        #mainChart {
            width: 100%;
            height: 450px;  /* å¢åŠ é«˜åº¦ï¼Œè®©å›¾è¡¨æ›´æ¸…æ™° */
        }
        
        /* æ•°æ®åˆ—è¡¨æ ‡é¢˜ */
        .data-list-header {
            background: #2a2d47;
            padding: 12px 20px;
            color: #3b7dff;
            font-size: 14px;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        /* è¡¨æ ¼å®¹å™¨ */
        .table-container {
            background: #1e2139;
            overflow-x: auto;
        }
        
        /* æ•°æ®è¡¨æ ¼ */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-size: 12px;
        }
        
        .data-table thead {
            background: #ef4444;
            position: sticky;
            top: 0;
            z-index: 10;
        }
        
        .data-table th {
            padding: 10px 8px;
            text-align: center;
            font-weight: 500;
            color: #fff;
            border-right: 1px solid #dc2626;
            white-space: nowrap;
        }
        
        .data-table tbody tr {
            border-bottom: 1px solid #2a2d47;
        }
        
        .data-table tbody tr:hover {
            background: #2a2d47;
        }
        
        .data-table td {
            padding: 8px 6px;
            text-align: center;
            border-right: 1px solid #2a2d47;
            white-space: nowrap;
        }
        
        /* æ“ä½œåˆ— */
        .action-btn {
            background: #ef4444;
            border: none;
            color: white;
            padding: 4px 10px;
            border-radius: 3px;
            font-size: 11px;
            cursor: pointer;
            font-weight: 500;
        }
        
        .action-btn:hover {
            background: #dc2626;
        }
        
        /* å¸ç§åç§° */
        .coin-symbol {
            font-weight: 600;
            color: #fff;
        }
        
        /* æ•°å€¼é¢œè‰² */
        .value-positive {
            color: #ef4444;
        }
        
        .value-negative {
            color: #10b981;
        }
        
        .value-neutral {
            color: #8b92b8;
        }
        
        /* çŠ¶æ€æ ‡ç­¾ */
        .status-tag {
            display: inline-block;
            padding: 2px 6px;
            border-radius: 3px;
            font-size: 11px;
        }
        
        .status-tag.rise {
            background: #dc2626;
            color: white;
        }
        
        .status-tag.fall {
            background: #10b981;
            color: white;
        }
        
        /* ä¼˜å…ˆçº§é¢œè‰² */
        .priority-1 { color: #ff0000; font-weight: bold; }
        .priority-2 { color: #ff6600; font-weight: bold; }
        .priority-3 { color: #ff9900; }
        .priority-4 { color: #ffcc00; }
        .priority-5 { color: #99cc00; }
        .priority-6 { color: #8b92b8; }
        
        /* åŠ è½½çŠ¶æ€ */
        .loading {
            text-align: center;
            padding: 40px;
            color: #8b92b8;
            font-size: 14px;
        }
        
        /* å“åº”å¼ */
        @media (max-width: 768px) {
            .control-bar {
                flex-direction: column;
                align-items: stretch;
            }
            
            .stats-bar {
                flex-direction: column;
                gap: 10px;
            }
            
            .data-table {
                font-size: 11px;
            }
            
            .data-table th,
            .data-table td {
                padding: 6px 4px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- é¡¶éƒ¨å¯¼èˆª -->
        <div class="top-nav">
            <div class="nav-left">
                <div class="nav-brand">
                    <span>ğŸ“Š</span> æ•°æ®å›çœ‹
                </div>
                <div class="nav-title">åŠ å¯†è´§å¸æ•°æ®å†å²å›çœ‹</div>
            </div>
            <div class="nav-right">
                <button class="home-btn" onclick="window.location.href='/'">
                    <span>ğŸ </span> è¿”å›é¦–é¡µ
                </button>
            </div>
        </div>
        
        <!-- ç³»ç»Ÿå¯¼èˆªæ  -->
        <div class="systems-nav">
            <div class="systems-nav-title">å¿«é€Ÿè®¿é—®:</div>
            <a href="/sar-slope" class="system-link featured">
                <span>ğŸ“ˆ</span> SARæ–œç‡ç³»ç»Ÿ
            </a>
            <a href="/kline-indicators" class="system-link">
                <span>ğŸ“Š</span> Kçº¿æŒ‡æ ‡ç³»ç»Ÿ
            </a>
            <a href="/support-resistance" class="system-link">
                <span>ğŸ“‰</span> æ”¯æ’‘é˜»åŠ›ç³»ç»Ÿ
            </a>
            <a href="/position-system" class="system-link">
                <span>ğŸ’¼</span> ä»“ä½ç³»ç»Ÿ
            </a>
            <a href="/gdrive-monitor-status" class="system-link">
                <span>â˜ï¸</span> Google Driveç›‘æ§
            </a>
            <a href="/crypto-index" class="system-link">
                <span>ğŸ“ˆ</span> æŒ‡æ•°ç³»ç»Ÿ
            </a>
            <a href="/coin-pool" class="system-link">
                <span>ğŸŠ</span> å¸æ± ç³»ç»Ÿ
            </a>
            <a href="/price-comparison" class="system-link">
                <span>ğŸ’±</span> æ¯”ä»·ç³»ç»Ÿ
            </a>
            <a href="/fund-monitor" class="system-link featured">
                <span>ğŸ’°</span> èµ„é‡‘ç›‘æ§ç³»ç»Ÿ
            </a>
        </div>
        
        <!-- æ§åˆ¶æ  -->
        <div class="control-bar">
            <div class="control-group">
                <span class="control-label">é€‰é¡¹æ—¥æœŸ:</span>
                <input type="date" id="queryDate" class="control-input">
            </div>
            
            <div class="control-group">
                <span class="control-label">æ—¶é—´é€‰æ‹©:</span>
                <input type="time" id="queryTime" class="control-input" value="00:00">
            </div>
            
            <div class="control-group">
                <span class="control-label">è‡³</span>
                <input type="time" id="endTime" class="control-input" value="23:59">
            </div>
            
            <button class="control-btn" onclick="queryData()">ğŸ” æŸ¥è¯¢</button>
            <button class="control-btn secondary" onclick="loadToday()">ğŸ“Š ä»Šå¤©</button>
            <button class="control-btn secondary" onclick="loadLatest()">ğŸ“¡ ç«‹å³åŠ è½½</button>
            <button class="control-btn secondary" onclick="batchImportData()" id="batchImportBtn">ğŸ“¥ æ‰¹é‡å¯¼å…¥ä»Šæ—¥æ•°æ®</button>
        </div>
        
        <!-- ä¸»è¦ç»Ÿè®¡æ  -->
        <div class="stats-bar">
            <div class="stat-item">
                <span class="stat-label">è¿ç®—æ—¶é—´:</span>
                <span class="stat-value" id="calcTime">2025-12-06 13:42:42</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ€¥æ¶¨:</span>
                <span class="stat-value rise" id="rushUp">1</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ€¥è·Œ:</span>
                <span class="stat-value fall" id="rushDown">22</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æœ¬è½®æ€¥æ¶¨:</span>
                <span class="stat-value" id="roundRushUp">1</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æœ¬è½®æ€¥è·Œ:</span>
                <span class="stat-value" id="roundRushDown">22</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">è®¡æ¬¡:</span>
                <span class="stat-value" id="countTimes">10</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">è®¡æ¬¡å¾—åˆ†:</span>
                <span class="stat-value" id="countScore">â˜†â˜†â˜†</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">çŠ¶æ€:</span>
                <span class="stat-value" id="status">éœ‡è¡æ— åº</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ¯”å€¼:</span>
                <span class="stat-value" id="ratio">10</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">å·®å€¼:</span>
                <span class="stat-value" id="diff">-21</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ¯”ä»·æœ€ä½:</span>
                <span class="stat-value" id="priceLowest">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ¯”ä»·åˆ›æ–°é«˜:</span>
                <span class="stat-value" id="priceNewhigh">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">24hæ¶¨â‰¥10%:</span>
                <span class="stat-value rise" id="rise24hCount">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">24hè·Œâ‰¤-10%:</span>
                <span class="stat-value fall" id="fall24hCount">0</span>
            </div>

        </div>
        
        <!-- æ¬¡çº§ç»Ÿè®¡æ  -->
        <div class="secondary-stats">
            <div class="stat-item">
                <span class="stat-label">å·²å›è°ƒå†å²: æ— </span>
            </div>
            <div class="stat-item">
                <span class="stat-label">å›è°ƒå¤©æ•°: 168 ç§’/0æ¬¡</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ—¶é—´åé™: 2025-12-04 10:22:00 ~ 2025-12-04 18:32:00</span>
            </div>
        </div>
        
        <!-- å›¾è¡¨åŒºåŸŸ -->
        <div class="chart-section">
            <div class="chart-header" style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <div class="chart-title">æ€¥æ¶¨/æ€¥è·Œå†å²è¶‹åŠ¿å›¾</div>
                <div class="chart-pagination" style="display: flex; gap: 10px; align-items: center;">
                    <span id="chartTimeRange" style="color: #8b92b8; font-size: 12px;"></span>
                    <button id="btnPrevPage" class="page-btn" style="padding: 5px 12px; background: #3a3d5c; color: #8b92b8; border: 1px solid #4a4d6c; border-radius: 4px; cursor: pointer;" disabled>
                        â—€ ä¸Šä¸€é¡µ
                    </button>
                    <span id="chartPageInfo" style="color: #8b92b8; font-size: 12px;">ç¬¬1é¡µ</span>
                    <button id="btnNextPage" class="page-btn" style="padding: 5px 12px; background: #3a3d5c; color: #8b92b8; border: 1px solid #4a4d6c; border-radius: 4px; cursor: pointer;" disabled>
                        ä¸‹ä¸€é¡µ â–¶
                    </button>
                </div>
            </div>
            <div id="mainChart"></div>
        </div>
        
        <!-- æ—¶é—´è½´ - æ”¾åœ¨å›¾è¡¨ä¸‹æ–¹ -->
        <div class="timeline-container">
            <div class="timeline-header">
                <span class="timeline-title">å†å²æ•°æ®æ—¶é—´è½´</span>
                <span class="timeline-info" id="timelineInfo">åŠ è½½ä¸­...</span>
            </div>
            <div class="timeline-track">
                <div class="timeline-line"></div>
                <div id="timelinePoints" class="timeline-points"></div>
            </div>
        </div>
        
        <!-- æ•°æ®åˆ—è¡¨æ ‡é¢˜ -->
        <div class="data-list-header">
            <span>ğŸ“‹</span> å¸åˆ—è¡¨
        </div>
        
        <!-- æ•°æ®è¡¨æ ¼ -->
        <div class="table-container">
            <table class="data-table">
                <thead>
                    <tr>
                        <th>ä¼˜å…ˆçº§</th>
                        <th>åºå·</th>
                        <th>å¸å</th>
                        <th>æ¶¨è·Œ</th>
                        <th>æ€¥æ¶¨</th>
                        <th>æ€¥è·Œ</th>
                        <th>æ›´æ–°æ—¶é—´</th>
                        <th>å†å²é«˜ç‚¹</th>
                        <th>é«˜ç‚¹æ—¶é—´</th>
                        <th>è·Œå¹…</th>
                        <th>24h%</th>
                        <th>æ’è¡Œ</th>
                        <th>å½“å‰ä»·æ ¼</th>
                        <th>æœ€é«˜å æ¯”</th>
                        <th>æœ€ä½å æ¯”</th>
                    </tr>
                </thead>
                <tbody id="dataTableBody">
                    <tr>
                        <td colspan="15" class="loading">æ­£åœ¨åŠ è½½æ•°æ®...</td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>

    <script>
        // åˆå§‹åŒ–å›¾è¡¨
        const chart = echarts.init(document.getElementById('mainChart'));
        
        // åˆå§‹åŒ–æ—¥æœŸ
        const today = new Date();
        document.getElementById('queryDate').valueAsDate = today;
        
        // å›¾è¡¨é…ç½®
        function updateChart(data) {
            const option = {
                backgroundColor: 'transparent',
                grid: {
                    left: '50px',
                    right: '50px',
                    bottom: '120px',  // å¢åŠ åº•éƒ¨ç©ºé—´ç»™æ—‹è½¬çš„æ¨ªè½´æ ‡ç­¾
                    top: '50px',
                    containLabel: true
                },
                tooltip: {
                    trigger: 'axis',  // æ”¹ä¸ºaxisè§¦å‘ï¼Œæ˜¾ç¤ºåŒä¸€æ—¶é—´ç‚¹æ‰€æœ‰æ•°æ®
                    backgroundColor: 'rgba(0, 0, 0, 0.9)',
                    borderColor: '#3a3d5c',
                    borderWidth: 1,
                    textStyle: { color: '#fff', fontSize: 12 },
                    axisPointer: {
                        type: 'cross',
                        crossStyle: {
                            color: '#8b92b8'
                        }
                    },
                    formatter: function(params) {
                        if (!params || params.length === 0) return '';
                        const time = params[0].axisValue;
                        let html = `<div style="padding: 8px;">
                            <div style="font-weight: bold; margin-bottom: 8px; font-size: 13px; border-bottom: 1px solid #3a3d5c; padding-bottom: 5px;">${time}</div>`;
                        
                        params.forEach(item => {
                            html += `<div style="margin-top: 5px; display: flex; align-items: center; justify-content: space-between; gap: 15px;">
                                <span style="display: flex; align-items: center;">
                                    <span style="display: inline-block; width: 10px; height: 10px; border-radius: 50%; background-color: ${item.color}; margin-right: 8px;"></span>
                                    ${item.seriesName}
                                </span>
                                <span style="color: ${item.color}; font-weight: bold;">${item.value}</span>
                            </div>`;
                        });
                        
                        html += '</div>';
                        return html;
                    }
                },
                legend: {
                    data: ['æ€¥æ¶¨', 'æ€¥è·Œ', 'å·®å€¼(æ€¥æ¶¨-æ€¥è·Œ)', 'è®¡æ¬¡'],
                    top: 10,
                    left: 'center',
                    textStyle: { color: '#8b92b8', fontSize: 13 },
                    itemWidth: 30,
                    itemHeight: 14,
                    itemGap: 20
                },
                xAxis: {
                    type: 'category',
                    data: data.times || [],
                    axisLine: { 
                        lineStyle: { color: '#3a3d5c', width: 1 }
                    },
                    axisLabel: { 
                        color: '#8b92b8',
                        fontSize: 10,
                        rotate: 45,  // æ—‹è½¬45åº¦ï¼Œé¿å…é‡å 
                        interval: 0,  // æ˜¾ç¤ºæ‰€æœ‰æ ‡ç­¾
                        margin: 12,
                        align: 'right',  // å³å¯¹é½
                        verticalAlign: 'middle'
                    },
                    axisTick: {
                        show: true,
                        lineStyle: { color: '#3a3d5c' }
                    },
                    splitLine: { 
                        show: true,  // æ˜¾ç¤ºåˆ†éš”çº¿
                        lineStyle: {
                            color: '#3a3d5c',
                            type: 'solid',  // å®çº¿
                            width: 1,
                            opacity: 0.3
                        }
                    }
                },
                yAxis: [
                    {
                        type: 'value',
                        name: 'æ•°é‡',
                        nameTextStyle: { 
                            color: '#8b92b8', 
                            fontSize: 12,
                            padding: [0, 0, 0, 10]
                        },
                        axisLine: { 
                            show: true,
                            lineStyle: { color: '#3a3d5c' } 
                        },
                        axisLabel: { 
                            color: '#8b92b8', 
                            fontSize: 11 
                        },
                        splitLine: { 
                            lineStyle: { 
                                color: '#3a3d5c', 
                                type: 'dashed',
                                opacity: 0.5
                            } 
                        }
                    },
                    {
                        type: 'value',
                        name: 'è®¡æ¬¡',
                        nameTextStyle: { 
                            color: '#3b7dff', 
                            fontSize: 12,
                            padding: [0, 10, 0, 0]
                        },
                        axisLine: { 
                            show: true,
                            lineStyle: { color: '#3a3d5c' } 
                        },
                        axisLabel: { 
                            color: '#3b7dff', 
                            fontSize: 11 
                        },
                        splitLine: { show: false }
                    }
                ],
                series: [
                    {
                        name: 'æ€¥æ¶¨',
                        type: 'line',
                        data: data.rush_up || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹ï¼Œå½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#ef4444'
                        },
                        itemStyle: { 
                            color: '#ef4444',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    },
                    {
                        name: 'æ€¥è·Œ',
                        type: 'line',
                        data: data.rush_down || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹ï¼Œå½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#10b981'
                        },
                        itemStyle: { 
                            color: '#10b981',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    },
                    {
                        name: 'å·®å€¼(æ€¥æ¶¨-æ€¥è·Œ)',
                        type: 'line',
                        data: data.diff || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹ï¼Œå½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#fbbf24'
                        },
                        itemStyle: { 
                            color: '#fbbf24',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    },
                    {
                        name: 'è®¡æ¬¡',
                        type: 'line',
                        yAxisIndex: 1,
                        data: data.count || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹ï¼Œå½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#3b7dff'
                        },
                        itemStyle: { 
                            color: '#3b7dff',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    }
                ]
            };
            
            chart.setOption(option);
        }
        
        // æŸ¥è¯¢æ•°æ®
        function queryData() {
            const date = document.getElementById('queryDate').value;
            const time = document.getElementById('queryTime').value;
            const datetime = date + ' ' + time;
            
            fetch('/api/query?time=' + encodeURIComponent(datetime))
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert('âŒ ' + data.error);
                        return;
                    }
                    updateUI(data);
                    loadChartData();  // åŠ è½½æ‰€æœ‰å†å²æ•°æ®è¶‹åŠ¿å›¾
                })
                .catch(error => {
                    alert('æŸ¥è¯¢å¤±è´¥: ' + error);
                });
        }
        
        // åŠ è½½ä»Šå¤©
        function loadToday() {
            const today = new Date();
            document.getElementById('queryDate').valueAsDate = today;
            queryData();
        }
        
        // åŠ è½½æœ€æ–°
        function loadLatest() {
            fetch('/api/latest')
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert('âŒ ' + data.error);
                        return;
                    }
                    updateUI(data);
                    loadChartData();  // åŠ è½½æ‰€æœ‰å†å²æ•°æ®è¶‹åŠ¿å›¾
                })
                .catch(error => {
                    alert('åŠ è½½å¤±è´¥: ' + error);
                });
        }
        
        // æ‰¹é‡å¯¼å…¥ä»Šæ—¥æ•°æ®
        function batchImportData() {
            const btn = document.getElementById('batchImportBtn');
            const originalText = btn.innerHTML;
            
            // ç¦ç”¨æŒ‰é’®å¹¶æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            btn.disabled = true;
            btn.innerHTML = 'â³ æ­£åœ¨æ‰¹é‡å¯¼å…¥...';
            btn.style.opacity = '0.6';
            btn.style.cursor = 'not-allowed';
            
            fetch('/api/query/batch-import', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                }
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    const stats = data.stats;
                    let message = `âœ… æ‰¹é‡å¯¼å…¥å®Œæˆï¼\n\n`;
                    message += `ğŸ“Š ç»Ÿè®¡ç»“æœï¼š\n`;
                    message += `   æ€»æ–‡ä»¶æ•°: ${stats.total}\n`;
                    message += `   âœ… æˆåŠŸå¯¼å…¥: ${stats.success}\n`;
                    message += `   â„¹ï¸  å·²å­˜åœ¨: ${stats.exists}\n`;
                    if (stats.invalid > 0) {
                        message += `   âš ï¸  æ— æ•ˆæ•°æ®: ${stats.invalid}\n`;
                    }
                    if (stats.error > 0) {
                        message += `   âŒ å¤±è´¥: ${stats.error}\n`;
                    }
                    
                    alert(message);
                    
                    // å¦‚æœæœ‰æ–°æ•°æ®å¯¼å…¥ï¼Œåˆ™åˆ·æ–°é¡µé¢æ•°æ®
                    if (stats.success > 0) {
                        loadToday();
                    }
                } else {
                    alert('âŒ æ‰¹é‡å¯¼å…¥å¤±è´¥: ' + data.error);
                }
            })
            .catch(error => {
                alert('âŒ æ‰¹é‡å¯¼å…¥å¤±è´¥: ' + error);
            })
            .finally(() => {
                // æ¢å¤æŒ‰é’®çŠ¶æ€
                btn.disabled = false;
                btn.innerHTML = originalText;
                btn.style.opacity = '1';
                btn.style.cursor = 'pointer';
            });
        }
        
        // åŠ è½½æ¶¨è·Œé€Ÿæ•°æ®
        function loadPriceSpeedData() {
            fetch('/api/price-speed/latest')
                .then(response => response.json())
                .then(response => {
                    if (response.success && response.data) {
                        const data = response.data;
                        
                        // ç»Ÿè®¡å„çº§åˆ«æ•°é‡
                        const upCount = data.filter(coin => 
                            coin.alert_level && coin.alert_level.includes('up') && coin.alert_level !== 'normal'
                        ).length;
                        
                        const downCount = data.filter(coin => 
                            coin.alert_level && coin.alert_level.includes('down') && coin.alert_level !== 'normal'
                        ).length;
                        
                        const normalCount = data.filter(coin => 
                            coin.alert_level === 'normal'
                        ).length;
                        
                        // æ›´æ–°UI (å·²ç§»é™¤æ€¥æ¶¨é€Ÿã€æ€¥è·Œé€Ÿã€æ­£å¸¸ç»Ÿè®¡)
                    }
                })
                .catch(err => {
                    console.error('åŠ è½½æ¶¨è·Œé€Ÿæ•°æ®å¤±è´¥:', err);
                    // å¦‚æœå¤±è´¥ï¼Œæ˜¾ç¤ºé»˜è®¤å€¼ (å·²ç§»é™¤æ€¥æ¶¨é€Ÿã€æ€¥è·Œé€Ÿã€æ­£å¸¸ç»Ÿè®¡)
                });
        }
        
        // æ›´æ–°UI
        function updateUI(data) {
            document.getElementById('calcTime').textContent = data.snapshot_time;
            document.getElementById('rushUp').textContent = data.rush_up;
            document.getElementById('rushDown').textContent = data.rush_down;
            document.getElementById('roundRushUp').textContent = data.round_rush_up || data.rush_up;
            document.getElementById('roundRushDown').textContent = data.round_rush_down || data.rush_down;
            document.getElementById('countTimes').textContent = data.count;
            document.getElementById('countScore').textContent = data.count_score_display || '---';
            document.getElementById('status').textContent = data.status;
            document.getElementById('ratio').textContent = data.ratio;
            document.getElementById('diff').textContent = data.diff;
            document.getElementById('priceLowest').textContent = data.price_lowest || 0;
            document.getElementById('priceNewhigh').textContent = data.price_newhigh || 0;
            document.getElementById('rise24hCount').textContent = data.rise_24h_count || 0;
            document.getElementById('fall24hCount').textContent = data.fall_24h_count || 0;
            
            // åŠ è½½æ¶¨è·Œé€Ÿæ•°æ®
            loadPriceSpeedData();
            
            // æ›´æ–°è¡¨æ ¼
            const tbody = document.getElementById('dataTableBody');
            if (data.coins && data.coins.length > 0) {
                let html = '';
                data.coins.forEach((coin, idx) => {
                    const changeClass = coin.change > 0 ? 'value-positive' : (coin.change < 0 ? 'value-negative' : 'value-neutral');
                    const change24Class = coin.change_24h > 0 ? 'value-positive' : (coin.change_24h < 0 ? 'value-negative' : 'value-neutral');
                    const priority = coin.priority || 'æœªçŸ¥';
                    const priorityClass = 'priority-' + priority.replace('ç­‰çº§', '');
                    
                    const rushUpTag = coin.rush_up > 0 ? '<span class="status-tag rise">' + coin.rush_up + '</span>' : coin.rush_up;
                    const rushDownTag = coin.rush_down > 0 ? '<span class="status-tag fall">' + coin.rush_down + '</span>' : coin.rush_down;
                    
                    html += '<tr>';
                    html += '<td class="' + priorityClass + '">' + priority + '</td>';
                    html += '<td>' + (idx + 1) + '</td>';
                    html += '<td class="coin-symbol">' + coin.symbol + '</td>';
                    html += '<td class="' + changeClass + '">' + coin.change.toFixed(2) + '</td>';
                    html += '<td>' + rushUpTag + '</td>';
                    html += '<td>' + rushDownTag + '</td>';
                    html += '<td>' + coin.update_time + '</td>';
                    html += '<td>' + coin.high_price.toFixed(2) + '</td>';
                    html += '<td>' + coin.high_time + '</td>';
                    html += '<td class="value-negative">' + coin.decline.toFixed(2) + '</td>';
                    html += '<td class="' + change24Class + '">' + coin.change_24h.toFixed(2) + '</td>';
                    html += '<td>' + coin.rank + '</td>';
                    html += '<td>' + coin.current_price.toFixed(4) + '</td>';
                    html += '<td>' + (coin.ratio1 || 'N/A') + '</td>';
                    html += '<td>' + (coin.ratio2 || 'N/A') + '</td>';
                    html += '</tr>';
                });
                tbody.innerHTML = html;
            } else {
                tbody.innerHTML = '<tr><td colspan="15" class="loading">æš‚æ— æ•°æ®</td></tr>';
            }
        }
        
        // åŠ è½½å›¾è¡¨æ•°æ®
        // å½“å‰é¡µç ï¼ˆå…¨å±€å˜é‡ï¼‰
        let currentPage = 0;
        
        function loadChartData(page = 0) {
            // åŠ è½½æŒ‡å®šé¡µçš„å†å²æ•°æ®ç‚¹ï¼ˆ12å°æ—¶/é¡µï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®ç‚¹ï¼‰
            currentPage = page;
            fetch(`/api/chart?page=${page}`)
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        console.error(data.error);
                        return;
                    }
                    updateChart(data);
                    
                    // æ›´æ–°åˆ†é¡µä¿¡æ¯
                    document.getElementById('chartPageInfo').textContent = 
                        `ç¬¬${page + 1}/${data.total_pages}é¡µ`;
                    document.getElementById('chartTimeRange').textContent = 
                        `${data.time_range.start} - ${data.time_range.end}`;
                    
                    // æ›´æ–°æŒ‰é’®çŠ¶æ€
                    document.getElementById('btnPrevPage').disabled = !data.has_prev;
                    document.getElementById('btnNextPage').disabled = !data.has_next;
                })
                .catch(error => {
                    console.error('å›¾è¡¨åŠ è½½å¤±è´¥:', error);
                });
        }
        
        // ç¿»é¡µæŒ‰é’®äº‹ä»¶
        document.addEventListener('DOMContentLoaded', function() {
            document.getElementById('btnPrevPage').addEventListener('click', function() {
                loadChartData(currentPage + 1);  // ä¸Šä¸€é¡µï¼ˆæ›´æ—©çš„æ•°æ®ï¼‰
            });
            
            document.getElementById('btnNextPage').addEventListener('click', function() {
                loadChartData(currentPage - 1);  // ä¸‹ä¸€é¡µï¼ˆæ›´æ–°çš„æ•°æ®ï¼‰
            });
        });
        
        // é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åŠ è½½æœ€æ–°æ•°æ®
        // åŠ è½½æ—¶é—´è½´æ•°æ® - ç«–ç›´å¸ƒå±€
        function loadTimeline() {
            fetch('/api/timeline')
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        document.getElementById('timelineInfo').textContent = data.error;
                        return;
                    }
                    
                    document.getElementById('timelineInfo').textContent = 
                        `å…± ${data.snapshots.length} ä¸ªæ•°æ®ç‚¹`;
                    
                    const pointsContainer = document.getElementById('timelinePoints');
                    pointsContainer.innerHTML = '';
                    
                    // æ—¶é—´ä»ä¸Šåˆ°ä¸‹ï¼šæœ€æ—©çš„åœ¨ä¸Šé¢ï¼Œæœ€æ–°çš„åœ¨ä¸‹é¢
                    data.snapshots.forEach((snapshot, index) => {
                        const point = document.createElement('div');
                        point.className = 'timeline-point';
                        point.setAttribute('data-time', snapshot.snapshot_time);
                        
                        // æœ€åä¸€ä¸ªï¼ˆæœ€æ–°çš„ï¼‰æ ‡è®°ä¸ºæ¿€æ´»
                        if (index === data.snapshots.length - 1) {
                            point.classList.add('active');
                        }
                        
                        const label = document.createElement('div');
                        label.className = 'timeline-label';
                        
                        // æ—¶é—´æ˜¾ç¤º
                        const timeSpan = document.createElement('div');
                        timeSpan.className = 'timeline-label-time';
                        timeSpan.textContent = snapshot.snapshot_time;
                        
                        // ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º - æ˜¾ç¤ºæ‰€æœ‰å…³é”®å­—æ®µ
                        const statsSpan = document.createElement('div');
                        statsSpan.className = 'timeline-label-stats';
                        
                        // ç¬¬ä¸€è¡Œï¼šæ€¥æ¶¨ã€æ€¥è·Œã€è®¡æ¬¡ã€å¾—åˆ†
                        const line1 = `æ€¥æ¶¨:${snapshot.rush_up} æ€¥è·Œ:${snapshot.rush_down} è®¡æ¬¡:${snapshot.count} ${snapshot.count_score_display || ''}`;
                        
                        // ç¬¬äºŒè¡Œï¼šçŠ¶æ€ã€æ¯”å€¼ã€å·®å€¼
                        const line2 = `çŠ¶æ€:${snapshot.status || ''} æ¯”å€¼:${snapshot.ratio || 0} å·®å€¼:${snapshot.diff}`;
                        
                        // ç¬¬ä¸‰è¡Œï¼šæœ¬è½®ã€æ¯”ä»·ã€24h
                        const line3 = `æœ¬è½®æ€¥æ¶¨:${snapshot.round_rush_up || 0} æœ¬è½®æ€¥è·Œ:${snapshot.round_rush_down || 0} 24hæ¶¨â‰¥10%:${snapshot.rise_24h_count || 0} 24hè·Œâ‰¤-10%:${snapshot.fall_24h_count || 0}`;
                        
                        statsSpan.innerHTML = `
                            <div style="margin-bottom: 2px;">${line1}</div>
                            <div style="margin-bottom: 2px;">${line2}</div>
                            <div>${line3}</div>
                        `;
                        
                        label.appendChild(timeSpan);
                        label.appendChild(statsSpan);
                        point.appendChild(label);
                        
                        point.onclick = function() {
                            // ç§»é™¤æ‰€æœ‰æ¿€æ´»çŠ¶æ€
                            document.querySelectorAll('.timeline-point').forEach(p => {
                                p.classList.remove('active');
                            });
                            // æ¿€æ´»å½“å‰ç‚¹
                            this.classList.add('active');
                            // åŠ è½½æ•°æ®
                            loadSnapshotData(snapshot.snapshot_time);
                        };
                        
                        pointsContainer.appendChild(point);
                    });
                })
                .catch(error => {
                    console.error('åŠ è½½æ—¶é—´è½´å¤±è´¥:', error);
                    document.getElementById('timelineInfo').textContent = 'åŠ è½½å¤±è´¥';
                });
        }
        
        // åŠ è½½æŒ‡å®šå¿«ç…§çš„æ•°æ®
        function loadSnapshotData(snapshotTime) {
            fetch('/api/query?time=' + encodeURIComponent(snapshotTime))
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert(data.error);
                        return;
                    }
                    updateUI(data);
                    updateChart(data);
                    
                    // æ›´æ–°æ—¶é—´è½´æ¿€æ´»çŠ¶æ€
                    document.querySelectorAll('.timeline-point').forEach(point => {
                        point.classList.remove('active');
                    });
                    event.target.classList.add('active');
                })
                .catch(error => console.error('åŠ è½½æ•°æ®å¤±è´¥:', error));
        }
        
        window.onload = function() {
            loadLatest();
            loadTimeline();
        };
        
        // å“åº”å¼è°ƒæ•´
        window.addEventListener('resize', function() {
            chart.resize();
        });
    </script>
</body>
</html>
"""

# APIè·¯ç”±ä¿æŒä¸å˜ï¼Œä½¿ç”¨ä¹‹å‰çš„ä»£ç 
@app.route('/')
def index():
    """é¦–é¡µ - åŠŸèƒ½å¯¼èˆª"""
    return render_template('index.html')

@app.route('/query')
def query_page():
    """å†å²æ•°æ®æŸ¥è¯¢é¡µé¢"""
    return render_template_string(MAIN_HTML)

@app.route('/chart')
def chart_page():
    """è¶‹åŠ¿å›¾è¡¨é¡µé¢"""
    return render_template_string(MAIN_HTML)

@app.route('/timeline')
def timeline_page():
    """æ—¶é—´è½´é¡µé¢"""
    return render_template_string(MAIN_HTML)

@app.route('/status')
def status_page():
    """ç³»ç»ŸçŠ¶æ€é¡µé¢"""
    return render_template('status.html')

@app.route('/panic')
def panic_page():
    """ææ…Œæ¸…æ´—æŒ‡æ•°é¡µé¢"""
    return render_template('panic_new.html')

@app.route('/api/panic/latest')
def api_panic_latest():
    """ææ…Œæ¸…æ´—æŒ‡æ•°æœ€æ–°æ•°æ®API"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # ä½¿ç”¨æ–°çš„ panic_wash_index è¡¨
        cursor.execute('''
            SELECT record_time, panic_index, hour_24_people, total_position, 
                   hour_1_amount, hour_24_amount
            FROM panic_wash_index 
            ORDER BY record_time DESC 
            LIMIT 1
        ''')
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            panic_index_percentage = row[1]  # ç™¾åˆ†æ¯”å½¢å¼ï¼ˆå¦‚ 8.67ï¼‰
            # å¦‚æœæ˜¯æ•´æ•°å°±ä¸æ˜¾ç¤ºå°æ•°éƒ¨åˆ†ï¼Œå¦åˆ™ä¿ç•™2ä½å°æ•°
            panic_index = int(panic_index_percentage) if panic_index_percentage == int(panic_index_percentage) else round(panic_index_percentage, 2)
            
            people_wan = round(row[2] / 10000, 2)  # äºº -> ä¸‡äººï¼ˆå»æ‰4ä¸ª0ï¼‰
            position_yi = round(row[3] / 100000000, 2)  # ç¾å…ƒ -> äº¿ç¾å…ƒï¼ˆå»æ‰8ä¸ª0 = é™¤ä»¥1äº¿ï¼‰
            hour_1_amount_usd = row[4]  # 1å°æ—¶çˆ†ä»“é‡‘é¢ï¼ˆç¾å…ƒï¼‰
            hour_24_amount_usd = row[5]  # 24å°æ—¶çˆ†ä»“é‡‘é¢ï¼ˆç¾å…ƒï¼‰
            
            # å•ä½è½¬æ¢ï¼šç¾å…ƒ -> ä¸‡ç¾å…ƒ
            hour_1_amount_wan = round(hour_1_amount_usd / 10000, 2)  # ç¾å…ƒ -> ä¸‡ç¾å…ƒï¼ˆå»æ‰4ä¸ª0ï¼‰
            hour_24_amount_wan = round(hour_24_amount_usd / 10000, 2)  # ç¾å…ƒ -> ä¸‡ç¾å…ƒï¼ˆå»æ‰4ä¸ª0ï¼‰
            
            # æ ¹æ®ææ…ŒæŒ‡æ•°ç¡®å®šç­‰çº§ï¼ˆç°åœ¨ä½¿ç”¨ç™¾åˆ†æ¯”å½¢å¼åˆ¤æ–­ï¼š8.67% åœ¨ä½ææ…ŒèŒƒå›´ï¼‰
            if panic_index_percentage < 5:
                panic_level = 'ä½ææ…Œ'
                level_color = 'green'
            elif panic_index_percentage < 10:
                panic_level = 'ä¸­åº¦ææ…Œ'
                level_color = 'yellow'
            else:
                panic_level = 'é«˜åº¦ææ…Œ'
                level_color = 'red'
            
            return jsonify({
                'success': True,
                'data': {
                    'record_time': row[0],
                    'panic_index': panic_index,
                    'panic_level': panic_level,
                    'level_color': level_color,
                    'hour_24_people': people_wan,
                    'total_position': position_yi,
                    'hour_1_amount': hour_1_amount_wan,  # è¿”å›ä¸‡ç¾å…ƒ
                    'hour_24_amount': hour_24_amount_wan,  # è¿”å›ä¸‡ç¾å…ƒ
                    'market_zone': f'{people_wan}ä¸‡äºº/{position_yi}äº¿ç¾å…ƒ'
                }
            })
        else:
            return jsonify({'success': False, 'error': 'æš‚æ— æ•°æ®'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/stats')
def api_stats():
    """ç»Ÿè®¡æ•°æ®API - åŒ…å«æœ¬è½®æ€¥æ¶¨æ€¥è·Œå’Œææ…Œæ¸…æ´—æŒ‡æ•°"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ€»è®°å½•æ•°
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots")
        total_records = cursor.fetchone()[0]
        
        # ä»Šæ—¥è®°å½•æ•°
        today = datetime.now(BEIJING_TZ).date().strftime('%Y-%m-%d')
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots WHERE snapshot_date = ?", (today,))
        today_records = cursor.fetchone()[0]
        
        # æ•°æ®å¤©æ•°
        cursor.execute("SELECT COUNT(DISTINCT snapshot_date) FROM crypto_snapshots")
        data_days = cursor.fetchone()[0]
        
        # è·å–æœ€æ–°ä¸¤æ¡è®°å½•ç”¨äºè®¡ç®—æœ¬è½®å·®å€¼
        cursor.execute("""
            SELECT snapshot_time, rush_up, rush_down, round_rush_up, round_rush_down
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 2
        """)
        latest_records = cursor.fetchall()
        
        last_update_time = '-'
        current_round_rush_up = 0
        current_round_rush_down = 0
        
        if latest_records and len(latest_records) >= 1:
            # snapshot_time æ ¼å¼: "2025-12-10 16:35:00", æå–æ—¶é—´éƒ¨åˆ† HH:MM
            time_str = latest_records[0][0]
            if time_str:
                # å¦‚æœåŒ…å«æ—¥æœŸï¼Œæå–æ—¶é—´éƒ¨åˆ†ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD HH:MM:SSï¼‰
                if ' ' in time_str:
                    last_update_time = time_str.split(' ')[1][:5]  # æå– HH:MM
                else:
                    # å¦‚æœåªæœ‰æ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SSï¼‰
                    last_update_time = time_str[:5]
            else:
                last_update_time = '-'
            current_rush_up = latest_records[0][1]
            current_rush_down = latest_records[0][2]
            
            if len(latest_records) >= 2:
                prev_rush_up = latest_records[1][1]
                prev_rush_down = latest_records[1][2]
                
                # æœ¬è½®æ€¥æ¶¨ = å½“å‰æ€¥æ¶¨ - ä¸Šä¸€è½®æ€¥æ¶¨
                current_round_rush_up = current_rush_up - prev_rush_up
                # æœ¬è½®æ€¥è·Œ = å½“å‰æ€¥è·Œ - ä¸Šä¸€è½®æ€¥è·Œ
                current_round_rush_down = current_rush_down - prev_rush_down
        
        # è·å–ææ…Œæ¸…æ´—æŒ‡æ•°ï¼ˆä»æ–°çš„ç‹¬ç«‹é‡‡é›†è¡¨ï¼‰
        cursor.execute("""
            SELECT panic_index, hour_24_people, total_position, record_time
            FROM panic_wash_index
            ORDER BY record_time DESC
            LIMIT 1
        """)
        panic_data = cursor.fetchone()
        
        panic_indicator = '-'
        panic_color = 'gray'
        panic_trend_rating = 0
        panic_market_zone = '-'
        panic_people_wan = 0
        panic_position_yi = 0
        
        if panic_data:
            panic_indicator = panic_data[0]  # ææ…ŒæŒ‡æ•°ï¼ˆç™¾åˆ†æ¯”ï¼‰
            panic_people_wan = round(panic_data[1] / 10000, 2)  # çˆ†ä»“äººæ•°ï¼ˆä¸‡äººï¼‰
            panic_position_yi = round(panic_data[2] / 100000000, 2)  # æŒä»“é‡ï¼ˆäº¿ç¾å…ƒï¼‰
            
            # æ ¹æ®ææ…ŒæŒ‡æ•°è®¾ç½®é¢œè‰²ï¼ˆç°åœ¨æ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼šå¦‚8.67%ï¼‰
            if panic_indicator < 5:
                panic_color = 'ç»¿'  # ä½ææ…Œï¼ˆ<5%ï¼‰
            elif panic_indicator < 10:
                panic_color = 'é»„'  # ä¸­ææ…Œï¼ˆ5-10%ï¼‰
            else:
                panic_color = 'çº¢'  # é«˜ææ…Œï¼ˆ>10%ï¼‰
            
            # å¸‚åœºåŒºé—´æè¿°
            panic_market_zone = f"{panic_people_wan}ä¸‡äºº/{panic_position_yi}äº¿ç¾å…ƒ"
        
        conn.close()
        
        return jsonify({
            'total_records': total_records,
            'today_records': today_records,
            'data_days': data_days,
            'last_update_time': last_update_time,
            'current_round_rush_up': current_round_rush_up,
            'current_round_rush_down': current_round_rush_down,
            'panic_indicator': panic_indicator,
            'panic_color': panic_color,
            'panic_trend_rating': panic_trend_rating,
            'panic_market_zone': panic_market_zone
        })
    except Exception as e:
        return jsonify({
            'total_records': 0,
            'today_records': 0,
            'data_days': 0,
            'last_update_time': '-',
            'current_round_rush_up': 0,
            'current_round_rush_down': 0,
            'panic_indicator': '-',
            'panic_color': 'gray',
            'panic_trend_rating': 0,
            'panic_market_zone': '-',
            'error': str(e)
        })

@app.route('/api/homepage/summary')
def api_homepage_summary():
    """é¦–é¡µèšåˆæ•°æ®API - ä¸€æ¬¡è¿”å›æ‰€æœ‰é¦–é¡µéœ€è¦çš„æ•°æ®"""
    try:
        result = {
            'success': True,
            'timestamp': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        }
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # 1. ç»Ÿè®¡æ æ•°æ®ï¼ˆæœ¬è½®æ€¥æ¶¨æ€¥è·Œå’Œææ…ŒæŒ‡æ•°ï¼‰
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots")
        total_records = cursor.fetchone()[0]
        
        today = datetime.now(BEIJING_TZ).date().strftime('%Y-%m-%d')
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots WHERE snapshot_date = ?", (today,))
        today_records = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT snapshot_time, rush_up, rush_down
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 2
        """)
        latest_records = cursor.fetchall()
        
        last_update_time = '-'
        current_round_rush_up = 0
        current_round_rush_down = 0
        
        if latest_records and len(latest_records) >= 1:
            time_str = latest_records[0][0]
            if time_str and ' ' in time_str:
                last_update_time = time_str.split(' ')[1][:5]
            current_rush_up = latest_records[0][1]
            current_rush_down = latest_records[0][2]
            
            if len(latest_records) >= 2:
                prev_rush_up = latest_records[1][1]
                prev_rush_down = latest_records[1][2]
                current_round_rush_up = current_rush_up - prev_rush_up
                current_round_rush_down = current_rush_down - prev_rush_down
        
        cursor.execute("""
            SELECT panic_index, hour_24_people, total_position
            FROM panic_wash_index
            ORDER BY record_time DESC
            LIMIT 1
        """)
        panic_data = cursor.fetchone()
        
        panic_indicator = '-'
        panic_color = 'gray'
        panic_market_zone = '-'
        
        if panic_data:
            panic_indicator = panic_data[0]
            panic_people_wan = round(panic_data[1] / 10000, 2)
            panic_position_yi = round(panic_data[2] / 100000000, 2)
            
            if panic_indicator < 5:
                panic_color = 'ç»¿'
            elif panic_indicator < 10:
                panic_color = 'é»„'
            else:
                panic_color = 'çº¢'
            
            panic_market_zone = f"{panic_people_wan}ä¸‡äºº/{panic_position_yi}äº¿ç¾å…ƒ"
        
        result['stats'] = {
            'total_records': total_records,
            'today_records': today_records,
            'last_update_time': last_update_time,
            'current_round_rush_up': current_round_rush_up,
            'current_round_rush_down': current_round_rush_down,
            'panic_indicator': panic_indicator,
            'panic_color': panic_color,
            'panic_market_zone': panic_market_zone
        }
        
        # 2. æ¨¡å—ç»Ÿè®¡æ•°æ®
        cursor.execute("SELECT MIN(snapshot_date), MAX(snapshot_date) FROM crypto_snapshots")
        date_range = cursor.fetchone()
        data_days = 0
        if date_range and date_range[0] and date_range[1]:
            data_days = (datetime.strptime(date_range[1], '%Y-%m-%d') - 
                        datetime.strptime(date_range[0], '%Y-%m-%d')).days + 1
        
        cursor.execute("SELECT MAX(snapshot_time) FROM crypto_snapshots")
        last_snapshot = cursor.fetchone()
        last_update = last_snapshot[0] if last_snapshot else '-'
        
        result['modules_stats'] = {
            'query_module': {
                'total_records': total_records,
                'data_days': data_days,
                'last_update': last_update
            }
        }
        
        # 3. ä»·æ ¼çªç ´ç»Ÿè®¡ï¼ˆåˆ›æ–°é«˜/åˆ›æ–°ä½ï¼‰
        cursor.execute("""
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE DATE(event_time) = ?
            GROUP BY event_type
        """, (today,))
        breakthrough_today = dict(cursor.fetchall())
        
        result['price_breakthrough'] = {
            'today': {
                'new_high': breakthrough_today.get('new_high', 0),
                'new_low': breakthrough_today.get('new_low', 0)
            }
        }
        
        # 4. V1V2æˆäº¤ç³»ç»Ÿæ•°æ®ï¼ˆä»å®é™…APIè·å–æˆ–å ä½ï¼‰
        # æš‚æ—¶ä½¿ç”¨å ä½æ•°æ®ï¼Œåç»­å¯ä»¥è°ƒç”¨åŸæœ‰çš„v1v2 API
        result['v1v2_system'] = {
            'v1_count': 0,
            'v2_count': 0,
            'update_time': last_update
        }
        
        # 5. æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿæ•°æ®
        cursor.execute("""
            SELECT 
                symbol, 
                alert_scenario_1, alert_scenario_2, alert_scenario_3, alert_scenario_4,
                position_s2_r1, position_s1_r2, position_s1_r1
            FROM support_resistance_levels
            WHERE record_time = (SELECT MAX(record_time) FROM support_resistance_levels)
        """)
        sr_data = cursor.fetchall()
        
        scenario1_coins = []
        scenario2_coins = []
        scenario3_coins = []
        scenario4_coins = []
        
        for row in sr_data:
            symbol, s1, s2, s3, s4, pos_s2_r1, pos_s1_r2, pos_s1_r1 = row
            coin_symbol = symbol.replace('USDT', '')
            
            if s1:
                scenario1_coins.append({'symbol': coin_symbol, 'position': pos_s2_r1})
            if s2:
                scenario2_coins.append({'symbol': coin_symbol, 'position': pos_s1_r2})
            if s3:
                scenario3_coins.append({'symbol': coin_symbol, 'position': pos_s1_r2})
            if s4:
                scenario4_coins.append({'symbol': coin_symbol, 'position': pos_s1_r1})
        
        result['support_resistance'] = {
            'total_count': len(sr_data),
            'scenario1_coins': scenario1_coins,
            'scenario2_coins': scenario2_coins,
            'scenario3_coins': scenario3_coins,
            'scenario4_coins': scenario4_coins,
            'update_time': last_update
        }
        
        # 6. äº¤æ˜“ä¿¡å·ç³»ç»Ÿæ•°æ®
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œè¿”å›åŸºæœ¬è®¡æ•°
        result['trading_signals'] = {
            'buy_point_1_count': 0,
            'buy_point_2_count': 0,
            'total_coins': 27,
            'update_time': last_update
        }
        
        # 7. 1åˆ†é’Ÿæ¶¨è·Œé€Ÿæ•°æ®ï¼ˆå ä½ï¼Œéœ€è¦å®é™…æ•°æ®æºï¼‰
        result['price_speed'] = {
            'up_count': 0,
            'down_count': 0,
            'update_time': last_update
        }
        
        # 8. ç›‘æ§çŠ¶æ€
        cursor.execute("""
            SELECT snapshot_time 
            FROM crypto_snapshots 
            ORDER BY snapshot_date DESC, snapshot_time DESC 
            LIMIT 1
        """)
        latest_snapshot_row = cursor.fetchone()
        latest_snapshot_time = latest_snapshot_row[0] if latest_snapshot_row else None
        
        need_collection = False
        minutes_since_last = None
        
        if latest_snapshot_time:
            latest_dt = datetime.strptime(latest_snapshot_time, '%Y-%m-%d %H:%M:%S')
            latest_dt = BEIJING_TZ.localize(latest_dt)
            now = datetime.now(BEIJING_TZ)
            minutes_since_last = (now - latest_dt).total_seconds() / 60
            
            if minutes_since_last > 15:
                need_collection = True
        
        result['monitor_status'] = {
            'need_collection': need_collection,
            'latest_snapshot': latest_snapshot_time,
            'minutes_since_last': round(minutes_since_last, 1) if minutes_since_last else None
        }
        
        # 9. Google Driveæ£€æµ‹å™¨çŠ¶æ€ï¼ˆå ä½ï¼‰
        result['gdrive_detector'] = {
            'detector_running': False,
            'file_timestamp': None,
            'delay_minutes': None,
            'latest_file': None
        }
        
        conn.close()
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })

@app.route('/api/query')
def api_query():
    """æŸ¥è¯¢API"""
    query_time = request.args.get('time', '')
    if not query_time:
        return jsonify({'error': 'è¯·æä¾›æŸ¥è¯¢æ—¶é—´'})
    
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                snapshot_date, snapshot_time, rush_up, rush_down, diff, count, ratio, status,
                round_rush_up, round_rush_down, price_lowest, price_newhigh,
                count_score_display, count_score_type, rise_24h_count, fall_24h_count
            FROM crypto_snapshots
            WHERE snapshot_time LIKE ?
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 1
        """, (f"{query_time}%",))
        
        snapshot = cursor.fetchone()
        
        if not snapshot:
            conn.close()
            return jsonify({'error': f'æœªæ‰¾åˆ° {query_time} çš„æ•°æ®'})
        
        (snapshot_date, snapshot_time, rush_up, rush_down, diff, count, ratio, status,
         round_rush_up, round_rush_down, price_lowest, price_newhigh,
         count_score_display, count_score_type, rise_24h_count, fall_24h_count) = snapshot
        
        # snapshot_timeå·²ç»æ˜¯å®Œæ•´çš„æ—¥æœŸæ—¶é—´ï¼Œæ— éœ€æ‹¼æ¥
        # æ ¼å¼: '2025-12-09 22:40:00'
        
        cursor.execute("""
            SELECT 
                symbol, change, rush_up, rush_down, update_time,
                high_price, high_time, decline, change_24h, rank,
                current_price, priority_level, ratio1, ratio2
            FROM crypto_coin_data
            WHERE snapshot_time = ?
            ORDER BY index_order ASC
        """, (snapshot_time,))
        
        coins = []
        for row in cursor.fetchall():
            coins.append({
                'symbol': row[0],
                'change': row[1],
                'rush_up': row[2],
                'rush_down': row[3],
                'update_time': row[4],
                'high_price': row[5],
                'high_time': row[6],
                'decline': row[7],
                'change_24h': row[8],
                'rank': row[9],
                'current_price': row[10],
                'priority': row[11],
                'ratio1': row[12],
                'ratio2': row[13]
            })
        
        conn.close()
        
        return jsonify({
            'snapshot_time': snapshot_time,
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'count': count,
            'ratio': ratio,
            'status': status,
            'round_rush_up': round_rush_up,
            'round_rush_down': round_rush_down,
            'price_lowest': price_lowest,
            'price_newhigh': price_newhigh,
            'count_score_display': count_score_display,
            'count_score_type': count_score_type,
            'rise_24h_count': rise_24h_count,
            'fall_24h_count': fall_24h_count,
            'coins': coins
        })
    
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/api/latest')
def api_latest():
    """è·å–æœ€æ–°æ•°æ®API"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                snapshot_date, snapshot_time, rush_up, rush_down, diff, count, ratio, status,
                round_rush_up, round_rush_down, price_lowest, price_newhigh,
                count_score_display, count_score_type, rise_24h_count, fall_24h_count
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 1
        """)
        
        snapshot = cursor.fetchone()
        
        if not snapshot:
            conn.close()
            return jsonify({'error': 'æ•°æ®åº“ä¸­æš‚æ— æ•°æ®'})
        
        (snapshot_date, snapshot_time, rush_up, rush_down, diff, count, ratio, status,
         round_rush_up, round_rush_down, price_lowest, price_newhigh,
         count_score_display, count_score_type, rise_24h_count, fall_24h_count) = snapshot
        
        # snapshot_timeå·²ç»æ˜¯å®Œæ•´çš„æ—¥æœŸæ—¶é—´ï¼Œæ— éœ€æ‹¼æ¥
        # æ ¼å¼: '2025-12-09 22:40:00'
        
        cursor.execute("""
            SELECT 
                symbol, change, rush_up, rush_down, update_time,
                high_price, high_time, decline, change_24h, rank,
                current_price, priority_level, ratio1, ratio2
            FROM crypto_coin_data
            WHERE snapshot_time = ?
            ORDER BY index_order ASC
        """, (snapshot_time,))
        
        coins = []
        for row in cursor.fetchall():
            coins.append({
                'symbol': row[0],
                'change': row[1],
                'rush_up': row[2],
                'rush_down': row[3],
                'update_time': row[4],
                'high_price': row[5],
                'high_time': row[6],
                'decline': row[7],
                'change_24h': row[8],
                'rank': row[9],
                'current_price': row[10],
                'priority': row[11],
                'ratio1': row[12],
                'ratio2': row[13]
            })
        
        conn.close()
        
        return jsonify({
            'snapshot_time': snapshot_time,
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'count': count,
            'ratio': ratio,
            'status': status,
            'round_rush_up': round_rush_up,
            'round_rush_down': round_rush_down,
            'price_lowest': price_lowest,
            'price_newhigh': price_newhigh,
            'count_score_display': count_score_display,
            'count_score_type': count_score_type,
            'rise_24h_count': rise_24h_count,
            'fall_24h_count': fall_24h_count,
            'coins': coins
        })
    
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/api/chart')
def api_chart():
    """å›¾è¡¨æ•°æ®API - æ”¯æŒåˆ†é¡µçš„12å°æ—¶è¶‹åŠ¿å›¾æ•°æ®ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æ•°æ®ç‚¹ï¼‰"""
    try:
        from datetime import datetime, timedelta
        
        # è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', '0')  # é»˜è®¤ç¬¬0é¡µï¼ˆæœ€æ–°ï¼‰
        page = int(page)
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰å†å²æ•°æ®ç‚¹ï¼ŒæŒ‰æ—¶é—´å‡åºæ’åˆ—
        cursor.execute("""
            SELECT 
                snapshot_time, rush_up, rush_down, diff, count
            FROM crypto_snapshots
            ORDER BY snapshot_date ASC, snapshot_time ASC
        """)
        
        all_data = cursor.fetchall()
        conn.close()
        
        if not all_data:
            return jsonify({'error': 'æ— æ•°æ®'})
        
        # è½¬æ¢ä¸ºdatetimeå¯¹è±¡
        all_points = []
        for row in all_data:
            dt = datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S')
            all_points.append({
                'time': dt,
                'formatted_time': dt.strftime('%m-%d %H:%M'),
                'rush_up': row[1],
                'rush_down': row[2],
                'diff': row[3],
                'count': row[4]
            })
        
        # è®¡ç®—æ€»é¡µæ•°ï¼ˆæ¯é¡µ12å°æ—¶ï¼‰
        earliest = all_points[0]['time']
        latest = all_points[-1]['time']
        total_hours = (latest - earliest).total_seconds() / 3600
        total_pages = max(1, int(total_hours / 12) + 1)
        
        # ç¡®ä¿pageåœ¨æœ‰æ•ˆèŒƒå›´å†…
        if page < 0:
            page = 0
        if page >= total_pages:
            page = total_pages - 1
        
        # è®¡ç®—å½“å‰é¡µçš„æ—¶é—´èŒƒå›´ï¼ˆä»æœ€æ–°å¾€å‰æ¨ï¼‰
        # page=0 æ˜¯æœ€æ–°çš„12å°æ—¶ï¼Œpage=1 æ˜¯ä¹‹å‰çš„12å°æ—¶ï¼Œä»¥æ­¤ç±»æ¨
        page_end_time = latest - timedelta(hours=12 * page)
        page_start_time = page_end_time - timedelta(hours=12)
        
        # ç­›é€‰å½“å‰é¡µçš„æ•°æ®ç‚¹
        page_points = [
            p for p in all_points 
            if page_start_time <= p['time'] <= page_end_time
        ]
        
        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºæ•°ç»„
        if not page_points:
            return jsonify({
                'times': [],
                'rush_up': [],
                'rush_down': [],
                'diff': [],
                'count': [],
                'page': page,
                'total_pages': total_pages,
                'has_prev': page < total_pages - 1,
                'has_next': page > 0,
                'time_range': {
                    'start': page_start_time.strftime('%Y-%m-%d %H:%M'),
                    'end': page_end_time.strftime('%Y-%m-%d %H:%M')
                }
            })
        
        # æå–æ•°æ®
        times = [p['formatted_time'] for p in page_points]
        rush_up = [p['rush_up'] for p in page_points]
        rush_down = [p['rush_down'] for p in page_points]
        diff = [p['diff'] for p in page_points]
        count = [p['count'] for p in page_points]
        
        return jsonify({
            'times': times,
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'count': count,
            'page': page,
            'total_pages': total_pages,
            'has_prev': page < total_pages - 1,  # æœ‰ä¸Šä¸€é¡µï¼ˆæ›´æ—©çš„æ•°æ®ï¼‰
            'has_next': page > 0,  # æœ‰ä¸‹ä¸€é¡µï¼ˆæ›´æ–°çš„æ•°æ®ï¼‰
            'time_range': {
                'start': page_start_time.strftime('%Y-%m-%d %H:%M'),
                'end': page_end_time.strftime('%Y-%m-%d %H:%M')
            },
            'data_count': len(page_points)
        })
    
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/api/timeline')
def api_timeline():
    """è·å–æ‰€æœ‰å†å²æ•°æ®ç‚¹API - è¿”å›å®Œæ•´çš„ç»Ÿè®¡æ•°æ®"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æ‰€æœ‰å­—æ®µ - å€’åºæ’åˆ—ï¼ˆæ—¶é—´æ™šçš„åœ¨ä¸Šï¼Œæ—¶é—´æ—©çš„åœ¨ä¸‹ï¼‰
        cursor.execute("""
            SELECT 
                id, snapshot_time, snapshot_date,
                rush_up, rush_down, diff, count, ratio, status,
                round_rush_up, round_rush_down,
                price_lowest, price_newhigh, ratio_diff,
                init_rush_up, init_rush_down,
                count_score_display, count_score_type,
                rise_24h_count, fall_24h_count,
                green_count, percentage, filename
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
        """)
        
        snapshots = []
        for row in cursor.fetchall():
            snapshots.append({
                'id': row[0],
                'snapshot_time': row[1],
                'snapshot_date': row[2],
                # ä¸»è¦ç»Ÿè®¡
                'rush_up': row[3],
                'rush_down': row[4],
                'diff': row[5],
                'count': row[6],
                'ratio': row[7],
                'status': row[8],
                # æœ¬è½®æ•°æ®
                'round_rush_up': row[9],
                'round_rush_down': row[10],
                # æ¯”ä»·æ•°æ®
                'price_lowest': row[11],
                'price_newhigh': row[12],
                'ratio_diff': row[13],
                # åˆå§‹æ•°æ®
                'init_rush_up': row[14],
                'init_rush_down': row[15],
                # è®¡æ¬¡å¾—åˆ†
                'count_score_display': row[16],
                'count_score_type': row[17],
                # 24å°æ—¶æ¶¨è·Œ
                'rise_24h_count': row[18],
                'fall_24h_count': row[19],
                # å…¶ä»–
                'green_count': row[20],
                'percentage': row[21],
                'filename': row[22]
            })
        
        conn.close()
        
        return jsonify({
            'snapshots': snapshots,
            'total': len(snapshots)
        })
    
    except Exception as e:
        return jsonify({'error': str(e)})

# ==================== äº¤æ˜“ä¿¡å·ç›‘æ§ API ====================

@app.route('/signals')
def signals_page():
    """äº¤æ˜“ä¿¡å·ç›‘æ§é¡µé¢"""
    return render_template('signals.html')

@app.route('/popup-demo')
def popup_demo():
    """å¼¹çª—æ•ˆæœæ¼”ç¤ºé¡µé¢"""
    with open('popup_demo.html', 'r', encoding='utf-8') as f:
        return f.read()

@app.route('/api/signals/stats')
def api_signals_stats():
    """è·å–ä¿¡å·ç»Ÿè®¡æ•°æ®"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°è®°å½•
        cursor.execute('''
            SELECT record_time, long_signals, short_signals, 
                   total_signals, long_ratio, short_ratio
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        latest = cursor.fetchone()
        
        # è·å–æ€»è®°å½•æ•°
        cursor.execute('SELECT COUNT(*) FROM trading_signals')
        total_records = cursor.fetchone()[0]
        
        conn.close()
        
        if latest:
            return jsonify({
                'success': True,
                'data': {
                    'latest_time': latest[0],
                    'latest_long': latest[1],
                    'latest_short': latest[2],
                    'latest_total': latest[3],
                    'long_ratio': latest[4],
                    'short_ratio': latest[5],
                    'total_records': total_records
                }
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/signals/chart')
def api_signals_chart():
    """è·å–å›¾è¡¨æ•°æ®ï¼ˆæ”¯æŒåˆ†é¡µå’Œæ—¶é—´èŒƒå›´ï¼‰"""
    try:
        page = int(request.args.get('page', 0))
        time_range = request.args.get('range', '12h')
        
        # è®¡ç®—æ—¶é—´èŒƒå›´å¯¹åº”çš„æ•°æ®ç‚¹æ•°é‡ï¼ˆæ¯3åˆ†é’Ÿä¸€ä¸ªç‚¹ï¼‰
        range_minutes = {
            '1h': 60,
            '6h': 360,
            '12h': 720,
            '24h': 1440
        }
        
        minutes = range_minutes.get(time_range, 720)
        points_per_page = minutes // 3  # æ¯3åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹
        offset = page * points_per_page
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æ€»è®°å½•æ•°
        cursor.execute('SELECT COUNT(*) FROM trading_signals')
        total = cursor.fetchone()[0]
        total_pages = (total + points_per_page - 1) // points_per_page
        
        # è·å–åˆ†é¡µæ•°æ®
        cursor.execute('''
            SELECT record_time, long_signals, short_signals, total_signals
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT ? OFFSET ?
        ''', (points_per_page, offset))
        
        rows = cursor.fetchall()
        conn.close()
        
        # åè½¬é¡ºåºï¼Œä½¿æ—¶é—´ä»æ—©åˆ°æ™š
        rows.reverse()
        
        data = [{
            'time': row[0].split(' ')[1][:5],  # åªå–æ—¶åˆ†
            'long_signals': row[1],
            'short_signals': row[2],
            'total_signals': row[3]
        } for row in rows]
        
        return jsonify({
            'success': True,
            'data': data,
            'page': page,
            'total_pages': total_pages,
            'range': time_range
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/signals/history')
def api_signals_history():
    """è·å–å†å²è®°å½•åˆ—è¡¨"""
    try:
        limit = int(request.args.get('limit', 50))
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT record_time, long_signals, short_signals,
                   total_signals, long_ratio, short_ratio
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        data = [{
            'record_time': row[0],
            'long_signals': row[1],
            'short_signals': row[2],
            'total_signals': row[3],
            'long_ratio': row[4],
            'short_ratio': row[5]
        } for row in rows]
        
        return jsonify({
            'success': True,
            'data': data
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/liquidation/30days')
def api_liquidation_30days():
    """30æ—¥çˆ†ä»“æ•°æ®API"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT date, long_amount, short_amount, total_amount, updated_at
            FROM liquidation_30days
            ORDER BY date DESC
            LIMIT 30
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'date': row[0],
                'long_amount': round(row[1] / 100000000, 2),  # è½¬æ¢ä¸ºäº¿
                'short_amount': round(row[2] / 100000000, 2),
                'total_amount': round(row[3] / 100000000, 2),
                'updated_at': row[4]
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data)
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/panic/history')
def api_panic_history():
    """ææ…Œæ¸…æ´—æŒ‡æ•°å†å²æ•°æ®APIï¼ˆæ”¯æŒæ—¶é—´æŸ¥è¯¢ï¼‰"""
    try:
        limit = int(request.args.get('limit', 50))
        query_time = request.args.get('time', None)  # å¯é€‰çš„æ—¶é—´æŸ¥è¯¢å‚æ•°
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        if query_time:
            # æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼šæŸ¥è¯¢æŒ‡å®šæ—¶é—´å‰åçš„æ•°æ®
            half_limit = limit // 2
            
            # å…ˆæŸ¥è¯¢æŒ‡å®šæ—¶é—´ä¹‹å‰çš„è®°å½•ï¼ˆè¿‡æ»¤æ‰å¼‚å¸¸æ•°æ®ï¼‰
            cursor.execute('''
                SELECT record_time, panic_index, hour_24_people, total_position, hour_1_amount, hour_24_amount
                FROM panic_wash_index
                WHERE record_time <= ?
                  AND panic_index > 0 
                  AND hour_24_people > 0 
                  AND total_position > 1000000000
                  AND hour_1_amount > 100000
                  AND hour_24_amount > 1000000
                ORDER BY record_time DESC
                LIMIT ?
            ''', (query_time, half_limit))
            before_rows = cursor.fetchall()
            
            # å†æŸ¥è¯¢æŒ‡å®šæ—¶é—´ä¹‹åçš„è®°å½•ï¼ˆè¿‡æ»¤æ‰å¼‚å¸¸æ•°æ®ï¼‰
            cursor.execute('''
                SELECT record_time, panic_index, hour_24_people, total_position, hour_1_amount, hour_24_amount
                FROM panic_wash_index
                WHERE record_time > ?
                  AND panic_index > 0 
                  AND hour_24_people > 0 
                  AND total_position > 1000000000
                  AND hour_1_amount > 100000
                  AND hour_24_amount > 1000000
                ORDER BY record_time ASC
                LIMIT ?
            ''', (query_time, half_limit))
            after_rows = cursor.fetchall()
            
            # åˆå¹¶ç»“æœå¹¶æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            rows = list(before_rows) + list(reversed(after_rows))
        else:
            # é»˜è®¤æŸ¥è¯¢ï¼šæœ€æ–°çš„Næ¡è®°å½•ï¼ˆè¿‡æ»¤æ‰å¼‚å¸¸æ•°æ®ï¼Œæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            # total_position > 1000000000 è¡¨ç¤ºå¤§äº10äº¿ï¼ˆåŸå§‹å€¼ä»¥ç¾å…ƒè®¡ï¼‰
            # hour_1_amount > 100000 è¡¨ç¤ºå¤§äº10ä¸‡ï¼ˆåŸå§‹å€¼ä»¥ç¾å…ƒè®¡ï¼‰
            # hour_24_amount > 1000000 è¡¨ç¤ºå¤§äº100ä¸‡ï¼ˆåŸå§‹å€¼ä»¥ç¾å…ƒè®¡ï¼‰
            cursor.execute('''
                SELECT record_time, panic_index, hour_24_people, total_position, hour_1_amount, hour_24_amount
                FROM panic_wash_index
                WHERE panic_index > 0 
                  AND hour_24_people > 0 
                  AND total_position > 1000000000
                  AND hour_1_amount > 100000
                  AND hour_24_amount > 1000000
                ORDER BY record_time DESC
                LIMIT ?
            ''', (limit,))
            rows = cursor.fetchall()
        
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'record_time': row[0],
                'panic_index': row[1],
                'hour_24_people': round(row[2] / 10000, 2),  # è½¬æ¢ä¸ºä¸‡äºº
                'total_position': round(row[3] / 100000000, 2),  # è½¬æ¢ä¸ºäº¿ç¾å…ƒ
                'hour_1_amount': round(row[4] / 10000, 2),  # è½¬æ¢ä¸ºä¸‡ç¾å…ƒ
                'hour_24_amount': round(row[5] / 10000, 2)  # è½¬æ¢ä¸ºä¸‡ç¾å…ƒ
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'query_time': query_time  # è¿”å›æŸ¥è¯¢çš„æ—¶é—´
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/modules/stats')
def api_modules_stats():
    """è·å–æ‰€æœ‰æ¨¡å—çš„ç»Ÿè®¡ä¿¡æ¯"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # 1. å†å²æ•°æ®æŸ¥è¯¢æ¨¡å—ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots")
        query_total = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT snapshot_date) FROM crypto_snapshots")
        query_days = cursor.fetchone()[0]
        
        cursor.execute("SELECT MAX(snapshot_time) FROM crypto_snapshots")
        query_last_time = cursor.fetchone()[0] or '-'
        if query_last_time != '-':
            # å¤„ç†æ—¶é—´æ ¼å¼ï¼šå¯èƒ½æ˜¯ "HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM:SS"
            if ' ' in query_last_time:
                query_last_time = query_last_time.split(' ')[1][:5]  # å–HH:MM
            else:
                query_last_time = query_last_time[:5]  # å·²ç»æ˜¯HH:MM:SSï¼Œå–HH:MM
        
        # 2. äº¤æ˜“ä¿¡å·ç›‘æ§æ¨¡å—ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM trading_signals")
        signal_total = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT record_date) FROM trading_signals")
        signal_days = cursor.fetchone()[0]
        
        cursor.execute("SELECT MAX(record_time) FROM trading_signals")
        signal_last_time = cursor.fetchone()[0] or '-'
        if signal_last_time != '-':
            # å¤„ç†æ—¶é—´æ ¼å¼ï¼šå¯èƒ½æ˜¯ "HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM:SS"
            if ' ' in signal_last_time:
                signal_last_time = signal_last_time.split(' ')[1][:5]  # å–HH:MM
            else:
                signal_last_time = signal_last_time[:5]  # å·²ç»æ˜¯HH:MM:SSï¼Œå–HH:MM
        
        # 3. ææ…Œæ¸…æ´—æŒ‡æ•°æ¨¡å—ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM panic_wash_index")
        panic_total = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT DATE(record_time)) FROM panic_wash_index")
        panic_days = cursor.fetchone()[0]
        
        cursor.execute("SELECT MAX(record_time) FROM panic_wash_index")
        panic_last_time = cursor.fetchone()[0] or '-'
        if panic_last_time != '-':
            # å¤„ç†æ—¶é—´æ ¼å¼ï¼šå¯èƒ½æ˜¯ "HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM:SS"
            if ' ' in panic_last_time:
                panic_last_time = panic_last_time.split(' ')[1][:5]  # å–HH:MM
            else:
                panic_last_time = panic_last_time[:5]  # å·²ç»æ˜¯HH:MM:SSï¼Œå–HH:MM
        
        conn.close()
        
        return jsonify({
            'success': True,
            'query_module': {
                'total_records': query_total,
                'data_days': query_days,
                'last_update': query_last_time
            },
            'signal_module': {
                'total_records': signal_total,
                'data_days': signal_days,
                'last_update': signal_last_time
            },
            'panic_module': {
                'total_records': panic_total,
                'data_days': panic_days,
                'last_update': panic_last_time
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/price-comparison')
def price_comparison_page():
    """æ¯”ä»·ç³»ç»Ÿé¡µé¢"""
    return render_template('price_comparison.html')

@app.route('/api/price-comparison/list')
def api_price_comparison_list():
    """è·å–æ¯”ä»·ç³»ç»Ÿæ‰€æœ‰å¸ç§æ•°æ® - æŒ‰ç”¨æˆ·æŒ‡å®šé¡ºåºï¼Œä½¿ç”¨åŒ—äº¬æ—¶é—´"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT symbol, highest_price, highest_count, lowest_price, lowest_count,
                   highest_ratio, lowest_ratio, last_update_time
            FROM price_baseline
            ORDER BY display_order
        ''')
        
        rows = cursor.fetchall()
        data = []
        for row in rows:
            # ä» symbol æå–å¸ç§åç§° (ä¾‹å¦‚: BTC-USDT-SWAP -> BTC)
            symbol = row[0]
            coin_name = symbol.split('-')[0] if symbol else ''
            
            # è½¬æ¢æ—¶é—´ä¸ºåŒ—äº¬æ—¶é—´æ ¼å¼
            update_time = row[7]
            if update_time:
                try:
                    # å¦‚æœæ•°æ®åº“æ—¶é—´æ˜¯UTCï¼Œéœ€è¦è½¬æ¢
                    from datetime import datetime
                    import pytz
                    dt = datetime.strptime(update_time, '%Y-%m-%d %H:%M:%S')
                    # å‡è®¾æ•°æ®åº“å­˜çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼Œç›´æ¥ä½¿ç”¨
                    beijing_time = update_time
                except:
                    beijing_time = update_time
            else:
                beijing_time = None
            
            data.append({
                'coin_name': coin_name,
                'symbol': symbol,
                'highest_price': row[1],
                'highest_count': row[2],
                'lowest_price': row[3],
                'lowest_count': row[4],
                'highest_ratio': row[5],
                'lowest_ratio': row[6],
                'last_update_time': beijing_time
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': data,
            'total': len(data)
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/update', methods=['POST'])
def api_price_comparison_update():
    """æ›´æ–°å¸ç§ä»·æ ¼å¹¶è¿›è¡Œæ¯”ä»·åˆ¤æ–­
    
    é€»è¾‘:
    - æ–°ä»·æ ¼ > æœ€é«˜ä»·: æ›´æ–°æœ€é«˜ä»·ï¼Œæœ€é«˜è®¡æ¬¡æ¸…é›¶
    - æ–°ä»·æ ¼ < æœ€ä½ä»·: æ›´æ–°æœ€ä½ä»·ï¼Œæœ€ä½è®¡æ¬¡æ¸…é›¶  
    - æœ€ä½ä»· <= æ–°ä»·æ ¼ <= æœ€é«˜ä»·: ä¸¤ä¸ªè®¡æ¬¡éƒ½+1
    """
    try:
        data = request.get_json()
        coin_name = data.get('coin_name')
        new_price = float(data.get('price'))
        
        if not coin_name or new_price is None:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦å‚æ•°: coin_name æˆ– price'
            })
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–å½“å‰å¸ç§çš„æœ€é«˜ä»·å’Œæœ€ä½ä»·
        cursor.execute('''
            SELECT highest_price, highest_count, lowest_price, lowest_count
            FROM price_baseline
            WHERE symbol = ?
        ''', (coin_name,))
        
        row = cursor.fetchone()
        if not row:
            conn.close()
            return jsonify({
                'success': False,
                'error': f'å¸ç§ {coin_name} ä¸å­˜åœ¨'
            })
        
        highest_price, highest_count, lowest_price, lowest_count = row
        old_highest_price = highest_price
        old_lowest_price = lowest_price
        
        # ä»·æ ¼æ¯”è¾ƒé€»è¾‘
        action = ''
        if new_price > highest_price:
            # æ–°ä»·æ ¼åˆ›æ–°é«˜
            old_highest_price = highest_price
            highest_price = new_price
            highest_count = 0
            action = 'new_high'
        elif new_price < lowest_price:
            # æ–°ä»·æ ¼åˆ›æ–°ä½
            old_lowest_price = lowest_price
            lowest_price = new_price
            lowest_count = 0
            action = 'new_low'
        else:
            # ä»·æ ¼åœ¨åŒºé—´å†…
            highest_count += 1
            lowest_count += 1
            action = 'in_range'
        
        # è®¡ç®—å æ¯”
        # æœ€é«˜ä»·å æ¯” = (å½“å‰ä»· / æœ€é«˜ä»·) Ã— 100
        highest_ratio = round((new_price / highest_price) * 100, 2) if highest_price > 0 else 0
        # æœ€ä½ä»·å æ¯” = (å½“å‰ä»· / æœ€ä½ä»·) Ã— 100
        lowest_ratio = round((new_price / lowest_price) * 100, 2) if lowest_price > 0 else 0
        
        # æ›´æ–°æ•°æ®åº“ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
        from datetime import datetime
        import pytz
        beijing_tz = pytz.timezone('Asia/Shanghai')
        beijing_time = datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            UPDATE price_baseline
            SET highest_price = ?,
                highest_count = ?,
                lowest_price = ?,
                lowest_count = ?,
                highest_ratio = ?,
                lowest_ratio = ?,
                last_update_time = ?
            WHERE symbol = ?
        ''', (highest_price, highest_count, lowest_price, lowest_count, 
              highest_ratio, lowest_ratio, beijing_time, coin_name))
        
        # å¦‚æœå‘ç”Ÿåˆ›æ–°é«˜æˆ–åˆ›æ–°ä½ï¼Œè®°å½•äº‹ä»¶
        if action in ['new_high', 'new_low']:
            cursor.execute('''
                INSERT INTO price_breakthrough_events 
                (symbol, event_type, price, event_time)
                VALUES (?, ?, ?, ?)
            ''', (coin_name, action, new_price, beijing_time))
            
            # æ›´æ–°ç»Ÿè®¡è¡¨ç¼“å­˜ï¼ˆæ¸…é™¤ä»Šå¤©çš„ç¼“å­˜ï¼Œä¸‹æ¬¡æŸ¥è¯¢æ—¶ä¼šé‡æ–°è®¡ç®—ï¼‰
            today_date = beijing_tz.localize(datetime.now()).strftime('%Y-%m-%d')
            cursor.execute('''
                DELETE FROM price_comparison_stats
                WHERE stat_date = ?
            ''', (today_date,))
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'action': action,
            'data': {
                'coin_name': coin_name,
                'new_price': new_price,
                'highest_price': highest_price,
                'highest_count': highest_count,
                'lowest_price': lowest_price,
                'lowest_count': lowest_count
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/breakthrough-stats')
def api_breakthrough_stats():
    """è·å–åˆ›æ–°é«˜/ä½ç»Ÿè®¡
    
    è¿”å›:
    - å½“å¤©åˆ›æ–°é«˜æ¬¡æ•°ã€åˆ›æ–°ä½æ¬¡æ•°
    - 3å¤©å†…åˆ›æ–°é«˜æ¬¡æ•°ã€åˆ›æ–°ä½æ¬¡æ•°
    - 7å¤©å†…åˆ›æ–°é«˜æ¬¡æ•°ã€åˆ›æ–°ä½æ¬¡æ•°
    
    ä¼˜å…ˆä»ç»Ÿè®¡è¡¨è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™å®æ—¶è®¡ç®—å¹¶ä¿å­˜
    """
    try:
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        today_date = now.strftime('%Y-%m-%d')
        
        # å…ˆå°è¯•ä»ç»Ÿè®¡è¡¨è¯»å–ä»Šå¤©çš„æ•°æ®
        cursor.execute('''
            SELECT today_new_high, today_new_low, 
                   three_days_new_high, three_days_new_low,
                   seven_days_new_high, seven_days_new_low
            FROM price_comparison_stats
            WHERE stat_date = ?
        ''', (today_date,))
        
        cached_stats = cursor.fetchone()
        
        # å¦‚æœç¼“å­˜å­˜åœ¨ä¸”ä¸è¶…è¿‡5åˆ†é’Ÿï¼Œç›´æ¥è¿”å›
        if cached_stats:
            conn.close()
            return jsonify({
                'success': True,
                'data': {
                    'today': {
                        'new_high': cached_stats[0],
                        'new_low': cached_stats[1]
                    },
                    'three_days': {
                        'new_high': cached_stats[2],
                        'new_low': cached_stats[3]
                    },
                    'seven_days': {
                        'new_high': cached_stats[4],
                        'new_low': cached_stats[5]
                    }
                },
                'from_cache': True
            })
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œå®æ—¶è®¡ç®—
        # è®¡ç®—æ—¶é—´è¾¹ç•Œ
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        three_days_ago = now - timedelta(days=3)
        seven_days_ago = now - timedelta(days=7)
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
        three_days_ago_str = three_days_ago.strftime('%Y-%m-%d %H:%M:%S')
        seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d %H:%M:%S')
        
        # å½“å¤©ç»Ÿè®¡
        cursor.execute('''
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE event_time >= ?
            GROUP BY event_type
        ''', (today_start_str,))
        today_stats = dict(cursor.fetchall())
        
        # 3å¤©ç»Ÿè®¡
        cursor.execute('''
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE event_time >= ?
            GROUP BY event_type
        ''', (three_days_ago_str,))
        three_days_stats = dict(cursor.fetchall())
        
        # 7å¤©ç»Ÿè®¡
        cursor.execute('''
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE event_time >= ?
            GROUP BY event_type
        ''', (seven_days_ago_str,))
        seven_days_stats = dict(cursor.fetchall())
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°æ•°æ®åº“
        cursor.execute('''
            INSERT OR REPLACE INTO price_comparison_stats
            (stat_date, today_new_high, today_new_low, 
             three_days_new_high, three_days_new_low,
             seven_days_new_high, seven_days_new_low, record_time)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            today_date,
            today_stats.get('new_high', 0),
            today_stats.get('new_low', 0),
            three_days_stats.get('new_high', 0),
            three_days_stats.get('new_low', 0),
            seven_days_stats.get('new_high', 0),
            seven_days_stats.get('new_low', 0),
            now.strftime('%Y-%m-%d %H:%M:%S')
        ))
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'today': {
                    'new_high': today_stats.get('new_high', 0),
                    'new_low': today_stats.get('new_low', 0)
                },
                'three_days': {
                    'new_high': three_days_stats.get('new_high', 0),
                    'new_low': three_days_stats.get('new_low', 0)
                },
                'seven_days': {
                    'new_high': seven_days_stats.get('new_high', 0),
                    'new_low': seven_days_stats.get('new_low', 0)
                }
            },
            'from_cache': False
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/breakthrough-logs')
def api_breakthrough_logs():
    """è·å–åˆ›æ–°é«˜/ä½è¯¦ç»†æ—¥å¿—
    
    å‚æ•°:
    - limit: è¿”å›è®°å½•æ•°é‡ï¼Œé»˜è®¤50
    - days: æŸ¥è¯¢æœ€è¿‘Nå¤©çš„è®°å½•ï¼Œé»˜è®¤7å¤©
    - coin: ç­›é€‰ç‰¹å®šå¸ç§
    - type: ç­›é€‰ç±»å‹ (new_high/new_low)
    
    è¿”å›:
    - æ—¶é—´ã€å¸åã€äº‹ä»¶ç±»å‹(åˆ›æ–°é«˜/åˆ›æ–°ä½)ã€ä»·æ ¼ã€ä¹‹å‰æå€¼ä»·æ ¼
    """
    try:
        from datetime import datetime, timedelta
        import pytz
        
        # è·å–å‚æ•°
        limit = request.args.get('limit', 50, type=int)
        days = request.args.get('days', 7, type=int)
        coin_filter = request.args.get('coin', None)
        type_filter = request.args.get('type', None)
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        query = '''
            SELECT symbol, event_type, price, event_time
            FROM price_breakthrough_events
            WHERE 1=1
        '''
        params = []
        
        # æ—¶é—´è¿‡æ»¤
        if days > 0:
            beijing_tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(beijing_tz)
            cutoff_time = now - timedelta(days=days)
            cutoff_str = cutoff_time.strftime('%Y-%m-%d %H:%M:%S')
            query += ' AND event_time >= ?'
            params.append(cutoff_str)
        
        # å¸ç§è¿‡æ»¤
        if coin_filter:
            query += ' AND symbol = ?'
            params.append(coin_filter)
        
        # ç±»å‹è¿‡æ»¤
        if type_filter in ['new_high', 'new_low']:
            query += ' AND event_type = ?'
            params.append(type_filter)
        
        query += ' ORDER BY event_time DESC LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        results = cursor.fetchall()
        
        # æ ¼å¼åŒ–ç»“æœ
        logs = []
        for row in results:
            symbol, event_type, price, event_time = row
            # ä» symbol æå–å¸ç§åç§°
            coin_name = symbol.split('-')[0] if symbol else ''
            logs.append({
                'coin_name': coin_name,
                'symbol': symbol,
                'event_type': event_type,
                'event_label': 'åˆ›æ–°é«˜' if event_type == 'new_high' else 'åˆ›æ–°ä½',
                'price': price,
                'event_time': event_time
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': logs,
            'count': len(logs),
            'filters': {
                'days': days,
                'coin': coin_filter,
                'type': type_filter,
                'limit': limit
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/update-ratios')
def api_update_price_ratios():
    """æ‰¹é‡æ›´æ–°æ‰€æœ‰å¸ç§çš„ä»·æ ¼å æ¯”
    
    ä»æœ€æ–°å¿«ç…§æ•°æ®è·å–å½“å‰ä»·æ ¼ï¼Œè®¡ç®—å¹¶æ›´æ–°å æ¯”:
    - æœ€é«˜ä»·å æ¯” = (å½“å‰ä»· / æœ€é«˜ä»·) Ã— 100%
    - æœ€ä½ä»·å æ¯” = (å½“å‰ä»· / æœ€ä½ä»·) Ã— 100%
    """
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°å¿«ç…§æ—¶é—´
        cursor.execute('SELECT MAX(snapshot_time) FROM crypto_coin_data')
        latest_time = cursor.fetchone()[0]
        
        if not latest_time:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°å¿«ç…§æ•°æ®'
            })
        
        # è·å–æœ€æ–°å¿«ç…§çš„æ‰€æœ‰å¸ç§ä»·æ ¼
        cursor.execute('''
            SELECT symbol, current_price
            FROM crypto_coin_data
            WHERE snapshot_time = ?
        ''', (latest_time,))
        
        current_prices = {row[0]: row[1] for row in cursor.fetchall()}
        
        # è·å–æ‰€æœ‰å¸ç§çš„æœ€é«˜ä»·å’Œæœ€ä½ä»·
        cursor.execute('''
            SELECT symbol, highest_price, lowest_price
            FROM price_baseline
        ''')
        
        from datetime import datetime
        import pytz
        beijing_tz = pytz.timezone('Asia/Shanghai')
        current_time = datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        
        updated_count = 0
        update_details = []
        
        for row in cursor.fetchall():
            coin_name, highest_price, lowest_price = row
            
            # æŸ¥æ‰¾å½“å‰ä»·æ ¼
            current_price = current_prices.get(coin_name)
            
            if current_price is not None and current_price > 0:
                # è®¡ç®—å æ¯”
                highest_ratio = round((current_price / highest_price) * 100, 2) if highest_price > 0 else 0
                lowest_ratio = round((current_price / lowest_price) * 100, 2) if lowest_price > 0 else 0
                
                # æ›´æ–°æ•°æ®åº“
                cursor.execute('''
                    UPDATE price_baseline
                    SET highest_ratio = ?,
                        lowest_ratio = ?,
                        last_update_time = ?
                    WHERE symbol = ?
                ''', (highest_ratio, lowest_ratio, current_time, coin_name))
                
                updated_count += 1
                update_details.append({
                    'coin_name': coin_name,
                    'current_price': current_price,
                    'highest_ratio': highest_ratio,
                    'lowest_ratio': lowest_ratio
                })
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': f'æˆåŠŸæ›´æ–° {updated_count} ä¸ªå¸ç§çš„å æ¯”',
            'snapshot_time': latest_time,
            'updated_count': updated_count,
            'details': update_details[:10]  # åªè¿”å›å‰10ä¸ªä½œä¸ºç¤ºä¾‹
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/monitor/data-collection')
def api_monitor_data_collection():
    """ç›‘æ§æ•°æ®é‡‡é›†çŠ¶æ€"""
    try:
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # è·å–æœ€æ–°å¿«ç…§æ—¶é—´
        cursor.execute('SELECT MAX(snapshot_time) FROM crypto_snapshots')
        latest_snapshot = cursor.fetchone()[0]
        
        if not latest_snapshot:
            return jsonify({
                'success': False,
                'error': 'æ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•å¿«ç…§æ•°æ®',
                'status': 'no_data'
            })
        
        # è®¡ç®—æ—¶é—´å·®
        latest_time = datetime.strptime(latest_snapshot, '%Y-%m-%d %H:%M:%S')
        latest_time = beijing_tz.localize(latest_time)
        time_diff_minutes = (now - latest_time).total_seconds() / 60
        
        # è·å–ä»Šå¤©çš„é‡‡é›†æ¬¡æ•°
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT COUNT(*) FROM crypto_snapshots 
            WHERE snapshot_time >= ?
        ''', (today_start_str,))
        today_count = cursor.fetchone()[0]
        
        conn.close()
        
        # åˆ¤æ–­çŠ¶æ€
        status = 'normal'
        message = 'æ•°æ®é‡‡é›†æ­£å¸¸'
        alert_level = 'success'
        
        if time_diff_minutes > 20:
            status = 'critical'
            message = f'ä¸¥é‡: å·²ç» {time_diff_minutes:.1f} åˆ†é’Ÿæ²¡æœ‰æ–°æ•°æ®'
            alert_level = 'danger'
        elif time_diff_minutes > 15:
            status = 'warning'
            message = f'è­¦å‘Š: å·²ç» {time_diff_minutes:.1f} åˆ†é’Ÿæ²¡æœ‰æ–°æ•°æ®'
            alert_level = 'warning'
        
        # è®¡ç®—é¢„æœŸé‡‡é›†æ¬¡æ•°ï¼ˆæ¯10åˆ†é’Ÿä¸€æ¬¡ï¼‰
        expected_count = int((now.hour * 60 + now.minute) / 10)
        
        return jsonify({
            'success': True,
            'status': status,
            'message': message,
            'alert_level': alert_level,
            'data': {
                'current_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'latest_snapshot': latest_snapshot,
                'time_diff_minutes': round(time_diff_minutes, 1),
                'today_count': today_count,
                'expected_count': expected_count,
                'collection_rate': round((today_count / expected_count * 100) if expected_count > 0 else 0, 1)
            }
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/monitor')
def monitor_page():
    """æ•°æ®é‡‡é›†ç›‘æ§é¡µé¢ï¼ˆå¢å¼ºç‰ˆï¼‰- æ”¯æŒæ‰§è¡Œæ—¥å¿—ã€å¼€å…³æ§åˆ¶ã€åˆ·æ–°é—´éš”"""
    return render_template('unified_monitor_enhanced.html')

@app.route('/monitor-old')
def monitor_page_old():
    """åŸå§‹ç›‘æ§é¡µé¢ï¼ˆæ—§ç‰ˆï¼‰"""
    return render_template('monitor.html')

@app.route('/star-system')
def star_system_page():
    """æ˜Ÿæ˜Ÿç³»ç»Ÿé¡µé¢"""
    return render_template('star_system.html')

@app.route('/api/star-system/data')
def api_star_system_data():
    """è·å–æ˜Ÿæ˜Ÿç³»ç»Ÿæ‰€æœ‰æŒ‡æ ‡æ•°æ®"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from star_system import calculate_star_system
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        beijing_tz = pytz.timezone('Asia/Shanghai')
        
        # è·å–æœ€æ–°å¿«ç…§æ•°æ®
        cursor.execute('''
            SELECT rush_up, rush_down, diff, count, snapshot_time
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 1
        ''')
        snapshot = cursor.fetchone()
        
        if not snapshot:
            return jsonify({'success': False, 'error': 'æš‚æ— å¿«ç…§æ•°æ®'})
        
        rush_up, rush_down, diff, count, snapshot_time = snapshot
        
        # ç¡®ä¿æ•°å€¼ä¸ä¸ºNone
        rush_up = rush_up if rush_up is not None else 0
        rush_down = rush_down if rush_down is not None else 0
        diff = diff if diff is not None else 0
        count = count if count is not None else 0
        
        # è·å–å…¨ç½‘æŒä»“é‡ï¼ˆä»ææ…Œæ¸…æ´—æŒ‡æ•°è¡¨ï¼‰
        cursor.execute('''
            SELECT total_position
            FROM panic_wash_index
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        holdings_row = cursor.fetchone()
        holdings = holdings_row[0] if holdings_row and holdings_row[0] is not None else 10000000000  # é»˜è®¤100äº¿ï¼ˆå…ƒï¼‰
        
        # è·å–åšå¤šåšç©ºä¿¡å·ï¼ˆä»äº¤æ˜“ä¿¡å·è¡¨ï¼‰
        cursor.execute('''
            SELECT long_signals, short_signals
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        signals_row = cursor.fetchone()
        long_signals = signals_row[0] if signals_row and signals_row[0] is not None else 0
        short_signals = signals_row[1] if signals_row and signals_row[1] is not None else 0
        
        # è·å–ä»Šæ—¥åˆ›æ–°é«˜æ–°ä½æ¬¡æ•°
        today_start = datetime.now(beijing_tz).replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE event_time >= ?
            GROUP BY event_type
        ''', (today_start_str,))
        today_breakthrough = dict(cursor.fetchall())
        new_high_today = today_breakthrough.get('new_high', 0)
        new_low_today = today_breakthrough.get('new_low', 0)
        
        # è·å–å¸ç§ç»Ÿè®¡æ•°æ®ï¼ˆä»æœ€æ–°å¿«ç…§çš„è¯¦ç»†æ•°æ®ï¼‰
        cursor.execute('''
            SELECT symbol, rush_up, rush_down, priority_level
            FROM crypto_coin_data
            WHERE snapshot_time = ?
        ''', (snapshot_time,))
        coin_data = cursor.fetchall()
        
        # ç»Ÿè®¡ç‰¹æ®Šæƒ…å†µå¹¶è®°å½•å…·ä½“å¸ç§
        only_rush_up_coins = [c[0] for c in coin_data if c[1] > 0 and c[2] == 0]
        only_rush_up_count = len(only_rush_up_coins)
        
        rush_up_gt_down_coins = [c[0] for c in coin_data if c[1] > c[2]]
        rush_up_gt_down_count = len(rush_up_gt_down_coins)
        
        only_rush_down_coins = [c[0] for c in coin_data if c[1] == 0 and c[2] > 0]
        only_rush_down_count = len(only_rush_down_coins)
        
        rush_down_gt_up_coins = [c[0] for c in coin_data if c[2] > c[1]]
        rush_down_gt_up_count = len(rush_down_gt_up_coins)
        
        # ä¼˜å…ˆçº§â‰¥4 means ç­‰çº§1,2,3,4 (priority_level values: 'ç­‰çº§1', 'ç­‰çº§2', etc.)
        priority_high_coins = [c[0] for c in coin_data if c[3] in ['ç­‰çº§1', 'ç­‰çº§2', 'ç­‰çº§3', 'ç­‰çº§4']]
        priority_high_count = len(priority_high_coins)
        
        # ========== æ–°å¢åŠŸèƒ½3: ä½ç½®ç³»ç»Ÿå¹³å‡ä½ç½®ï¼ˆåœ¨conn.close()ä¹‹å‰æŸ¥è¯¢ï¼‰ ==========
        try:
            # è®¡ç®—48å°æ—¶å‰çš„åŒ—äº¬æ—¶é—´
            hours_ago_48 = datetime.now(beijing_tz) - timedelta(hours=48)
            hours_ago_48_str = hours_ago_48.strftime('%Y-%m-%d %H:%M:%S')
            
            cursor.execute("""
                SELECT 
                    AVG(position_4h) as avg_4h,
                    AVG(position_12h) as avg_12h,
                    AVG(position_24h) as avg_24h,
                    AVG(position_48h) as avg_48h
                FROM position_system
                WHERE record_time >= ?
            """, (hours_ago_48_str,))
            pos_row = cursor.fetchone()
            
            position_avg = {
                '4h': round(pos_row[0], 2) if pos_row and pos_row[0] else 0,
                '12h': round(pos_row[1], 2) if pos_row and pos_row[1] else 0,
                '24h': round(pos_row[2], 2) if pos_row and pos_row[2] else 0,
                '48h': round(pos_row[3], 2) if pos_row and pos_row[3] else 0
            }
        except Exception as e:
            position_avg = {'4h': 0, '12h': 0, '24h': 0, '48h': 0}
            print(f"ä½ç½®ç³»ç»Ÿå¹³å‡ä½ç½®æŸ¥è¯¢é”™è¯¯: {e}")
        
        # ========== æ–°å¢åŠŸèƒ½4: åˆ›æ–°é«˜/åˆ›æ–°ä½ç»Ÿè®¡ï¼ˆåœ¨conn.close()ä¹‹å‰æŸ¥è¯¢ï¼‰ ==========
        try:
            # å½“å¤©ç»Ÿè®¡ï¼ˆä»Šå¤©0ç‚¹åˆ°ç°åœ¨ï¼‰
            today_start = datetime.now(beijing_tz).replace(hour=0, minute=0, second=0, microsecond=0)
            today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
            
            # 3å¤©ç»Ÿè®¡
            three_days_ago = datetime.now(beijing_tz) - timedelta(days=3)
            three_days_ago_str = three_days_ago.strftime('%Y-%m-%d %H:%M:%S')
            
            # 7å¤©ç»Ÿè®¡
            seven_days_ago = datetime.now(beijing_tz) - timedelta(days=7)
            seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d %H:%M:%S')
            
            # æŸ¥è¯¢å½“å¤©åˆ›æ–°é«˜/åˆ›æ–°ä½
            cursor.execute("""
                SELECT 
                    SUM(CASE WHEN event_type = 'new_high' THEN 1 ELSE 0 END) as today_high,
                    SUM(CASE WHEN event_type = 'new_low' THEN 1 ELSE 0 END) as today_low
                FROM price_breakthrough_events
                WHERE event_time >= ?
            """, (today_start_str,))
            today_bt = cursor.fetchone()
            
            # æŸ¥è¯¢3å¤©åˆ›æ–°é«˜/åˆ›æ–°ä½
            cursor.execute("""
                SELECT 
                    SUM(CASE WHEN event_type = 'new_high' THEN 1 ELSE 0 END) as three_days_high,
                    SUM(CASE WHEN event_type = 'new_low' THEN 1 ELSE 0 END) as three_days_low
                FROM price_breakthrough_events
                WHERE event_time >= ?
            """, (three_days_ago_str,))
            three_days_bt = cursor.fetchone()
            
            # æŸ¥è¯¢7å¤©åˆ›æ–°é«˜/åˆ›æ–°ä½
            cursor.execute("""
                SELECT 
                    SUM(CASE WHEN event_type = 'new_high' THEN 1 ELSE 0 END) as seven_days_high,
                    SUM(CASE WHEN event_type = 'new_low' THEN 1 ELSE 0 END) as seven_days_low
                FROM price_breakthrough_events
                WHERE event_time >= ?
            """, (seven_days_ago_str,))
            seven_days_bt = cursor.fetchone()
            
            breakthrough_stats = {
                'today': {
                    'new_high': today_bt[0] if today_bt and today_bt[0] else 0,
                    'new_low': today_bt[1] if today_bt and today_bt[1] else 0
                },
                'three_days': {
                    'new_high': three_days_bt[0] if three_days_bt and three_days_bt[0] else 0,
                    'new_low': three_days_bt[1] if three_days_bt and three_days_bt[1] else 0
                },
                'seven_days': {
                    'new_high': seven_days_bt[0] if seven_days_bt and seven_days_bt[0] else 0,
                    'new_low': seven_days_bt[1] if seven_days_bt and seven_days_bt[1] else 0
                }
            }
        except Exception as e:
            breakthrough_stats = {
                'today': {'new_high': 0, 'new_low': 0},
                'three_days': {'new_high': 0, 'new_low': 0},
                'seven_days': {'new_high': 0, 'new_low': 0}
            }
            print(f"åˆ›æ–°é«˜/åˆ›æ–°ä½ç»Ÿè®¡æŸ¥è¯¢é”™è¯¯: {e}")
        
        conn.close()
        
        # å‡†å¤‡æ•°æ®ç»™æ˜Ÿæ˜Ÿç³»ç»Ÿè®¡ç®—
        data = {
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'holdings': holdings,
            'long_signals': long_signals,
            'short_signals': short_signals,
            'only_rush_up_count': only_rush_up_count,
            'rush_up_gt_down_count': rush_up_gt_down_count,
            'priority_high_count': priority_high_count,
            'only_rush_down_count': only_rush_down_count,
            'rush_down_gt_up_count': rush_down_gt_up_count,
            'new_low_today': new_low_today,
            'new_high_today': new_high_today,
            'count': count,
            'snapshot_time': snapshot_time
        }
        
        # è®¡ç®—æ˜Ÿæ˜Ÿç³»ç»Ÿ
        results = calculate_star_system(data)
        
        # ä¿å­˜åˆ°å†å²è®°å½•è¡¨ï¼ˆæ¯æ¬¡è°ƒç”¨APIæ—¶ä¿å­˜ï¼‰
        try:
            import json as json_lib
            cursor.execute('''
                INSERT INTO star_system_history 
                (timestamp, total_stars, solid_stars, hollow_stars, solid_percentage, hollow_percentage, raw_data)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                snapshot_time,
                results.get('total_stars', 0),
                results.get('solid_stars', 0),
                results.get('hollow_stars', 0),
                results.get('solid_percentage', 0),
                results.get('hollow_percentage', 0),
                json_lib.dumps(results, ensure_ascii=False)
            ))
            conn.commit()
        except Exception as save_err:
            print(f"ä¿å­˜å†å²æ•°æ®å¤±è´¥: {save_err}")
        
        # æ·»åŠ å¸ç§åˆ—è¡¨åˆ°ç»“æœä¸­
        coin_lists = {
            'only_rush_up_coins': only_rush_up_coins,
            'rush_up_gt_down_coins': rush_up_gt_down_coins,
            'priority_high_coins': priority_high_coins,
            'only_rush_down_coins': only_rush_down_coins,
            'rush_down_gt_up_coins': rush_down_gt_up_coins
        }
        
        # ========== æ–°å¢åŠŸèƒ½1: V1/V2å¸ç§ç»Ÿè®¡ ==========
        try:
            conn_v1v2 = sqlite3.connect('v1v2_data.db')
            cursor_v1v2 = conn_v1v2.cursor()
            
            coins_list = ['BTC', 'ETH', 'XRP', 'SOL', 'BNB', 'LTC', 'DOGE', 'SUI', 'TRX', 'TON', 
                         'ETC', 'BCH', 'HBAR', 'XLM', 'FIL', 'ADA', 'LINK', 'CRO', 'DOT', 'UNI',
                         'NEAR', 'APT', 'CFX', 'CRV', 'STX', 'LDO', 'TAO', 'AAVE']
            
            v1_coins_list = []
            v2_coins_list = []
            
            for coin in coins_list:
                try:
                    cursor_v1v2.execute(f"""
                        SELECT level FROM volume_{coin.lower()}
                        ORDER BY id DESC LIMIT 1
                    """)
                    row = cursor_v1v2.fetchone()
                    if row and row[0] == 'V1':
                        v1_coins_list.append(coin)
                    elif row and row[0] == 'V2':
                        v2_coins_list.append(coin)
                except:
                    pass
            
            conn_v1v2.close()
        except:
            v1_coins_list = []
            v2_coins_list = []
        
        # ========== æ–°å¢åŠŸèƒ½2: 1åˆ†é’Ÿæ¶¨è·Œé€Ÿé¢„è­¦ç»Ÿè®¡ ==========
        try:
            conn_ps = sqlite3.connect('price_speed_data.db')
            cursor_ps = conn_ps.cursor()
            
            # è·å–å„ç±»å‹é¢„è­¦çš„å¸ç§
            cursor_ps.execute("""
                SELECT alert_type, symbol
                FROM latest_price_speed
                WHERE alert_type != 'NORMAL'
            """)
            
            alert_coins = {
                'super_strong_up': [],
                'very_strong_up': [],
                'strong_up': [],
                'general_up': [],
                'super_strong_down': [],
                'very_strong_down': [],
                'strong_down': [],
                'general_down': []
            }
            
            for alert_type, symbol in cursor_ps.fetchall():
                if alert_type == 'SUPER_STRONG_UP':
                    alert_coins['super_strong_up'].append(symbol)
                elif alert_type == 'VERY_STRONG_UP':
                    alert_coins['very_strong_up'].append(symbol)
                elif alert_type == 'STRONG_UP':
                    alert_coins['strong_up'].append(symbol)
                elif alert_type == 'GENERAL_UP':
                    alert_coins['general_up'].append(symbol)
                elif alert_type == 'SUPER_STRONG_DOWN':
                    alert_coins['super_strong_down'].append(symbol)
                elif alert_type == 'VERY_STRONG_DOWN':
                    alert_coins['very_strong_down'].append(symbol)
                elif alert_type == 'STRONG_DOWN':
                    alert_coins['strong_down'].append(symbol)
                elif alert_type == 'GENERAL_DOWN':
                    alert_coins['general_down'].append(symbol)
            
            conn_ps.close()
        except:
            alert_coins = {
                'super_strong_up': [],
                'very_strong_up': [],
                'strong_up': [],
                'general_up': [],
                'super_strong_down': [],
                'very_strong_down': [],
                'strong_down': [],
                'general_down': []
            }
        
        return jsonify({
            'success': True,
            'data': results,
            'raw_data': data,
            'coin_lists': coin_lists,
            'update_time': snapshot_time,
            # æ–°å¢æ•°æ®
            'v1v2_data': {
                'v1_coins': v1_coins_list,
                'v1_count': len(v1_coins_list),
                'v2_coins': v2_coins_list,
                'v2_count': len(v2_coins_list)
            },
            'price_speed_alerts': {
                'up': {
                    'super_strong': {'count': len(alert_coins['super_strong_up']), 'coins': alert_coins['super_strong_up']},
                    'very_strong': {'count': len(alert_coins['very_strong_up']), 'coins': alert_coins['very_strong_up']},
                    'strong': {'count': len(alert_coins['strong_up']), 'coins': alert_coins['strong_up']},
                    'general': {'count': len(alert_coins['general_up']), 'coins': alert_coins['general_up']}
                },
                'down': {
                    'super_strong': {'count': len(alert_coins['super_strong_down']), 'coins': alert_coins['super_strong_down']},
                    'very_strong': {'count': len(alert_coins['very_strong_down']), 'coins': alert_coins['very_strong_down']},
                    'strong': {'count': len(alert_coins['strong_down']), 'coins': alert_coins['strong_down']},
                    'general': {'count': len(alert_coins['general_down']), 'coins': alert_coins['general_down']}
                }
            },
            'position_avg': position_avg,
            'breakthrough_stats': breakthrough_stats
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ==================== æ˜Ÿæ˜Ÿç³»ç»Ÿå†å²æ•°æ® API ====================
@app.route('/api/star-system/history')
def api_star_system_history():
    """è·å–æ˜Ÿæ˜Ÿç³»ç»Ÿå†å²æ•°æ®"""
    try:
        date = request.args.get('date')  # æ ¼å¼: YYYY-MM-DD
        limit = int(request.args.get('limit', 100))
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        if date:
            # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®
            start_time = f"{date} 00:00:00"
            end_time = f"{date} 23:59:59"
            cursor.execute('''
                SELECT id, timestamp, total_stars, solid_stars, hollow_stars, 
                       solid_percentage, hollow_percentage, raw_data
                FROM star_system_history
                WHERE timestamp BETWEEN ? AND ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (start_time, end_time, limit))
        else:
            # æŸ¥è¯¢æœ€è¿‘çš„è®°å½•
            cursor.execute('''
                SELECT id, timestamp, total_stars, solid_stars, hollow_stars, 
                       solid_percentage, hollow_percentage, raw_data
                FROM star_system_history
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
        
        rows = cursor.fetchall()
        
        history_data = []
        for row in rows:
            try:
                import json as json_lib
                raw_data = json_lib.loads(row[7]) if row[7] else {}
            except:
                raw_data = {}
            
            history_data.append({
                'id': row[0],
                'timestamp': row[1],
                'total_stars': row[2],
                'solid_stars': row[3],
                'hollow_stars': row[4],
                'solid_percentage': row[5],
                'hollow_percentage': row[6],
                'details': raw_data
            })
        
        # è·å–å¯ç”¨æ—¥æœŸåˆ—è¡¨
        cursor.execute('''
            SELECT DISTINCT DATE(timestamp) as date
            FROM star_system_history
            ORDER BY date DESC
            LIMIT 30
        ''')
        available_dates = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': history_data,
            'available_dates': available_dates,
            'total_records': len(history_data)
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ==================== æ•°æ®é‡‡é›†ç›‘æ§ API ====================
@app.route('/api/monitor/status')
def api_monitor_status():
    """è·å–æ•°æ®é‡‡é›†ç›‘æ§çŠ¶æ€"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'status'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        status = json.loads(result.stdout)
        return jsonify({
            'success': True,
            'status': status
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/history')
def api_monitor_history():
    """è·å–é‡‡é›†å†å²"""
    import subprocess
    try:
        hours = request.args.get('hours', '2')
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'history', hours],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        history = json.loads(result.stdout)
        return jsonify({
            'success': True,
            'history': history
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/trigger', methods=['POST'])
def api_monitor_trigger():
    """æ‰‹åŠ¨è§¦å‘æ•°æ®é‡‡é›†"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'force'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        collection_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': result.returncode == 0,
            'result': collection_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/check', methods=['POST'])
def api_monitor_check():
    """æ£€æŸ¥å¹¶è‡ªåŠ¨æ¢å¤æ•°æ®é‡‡é›†"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'check'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        check_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': True,
            'result': check_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ==================== å¤šæ¨¡å—ç›‘æ§ API ====================
@app.route('/api/monitor/all-modules')
def api_monitor_all_modules():
    """è·å–æ‰€æœ‰æ¨¡å—ç›‘æ§çŠ¶æ€"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'multi_module_monitor.py', 'status'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        # ä»stdoutæå–JSONéƒ¨åˆ†ï¼ˆè·³è¿‡å‰é¢çš„æ–‡æœ¬è¾“å‡ºï¼‰
        output = result.stdout
        # æ‰¾åˆ°JSONå¼€å§‹çš„ä½ç½®
        json_start = output.find('{')
        if json_start >= 0:
            json_str = output[json_start:]
            statuses = json.loads(json_str)
            return jsonify({
                'success': True,
                'modules': statuses
            })
        else:
            return jsonify({
                'success': False,
                'error': 'No JSON output found'
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/check-all', methods=['POST'])
def api_monitor_check_all():
    """æ£€æŸ¥å¹¶è‡ªåŠ¨æ¢å¤æ‰€æœ‰æ¨¡å—"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'multi_module_monitor.py', 'check', '--silent'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶ï¼ˆå¤šä¸ªæ¨¡å—å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
        )
        check_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': True,
            'result': check_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/force-update/<module_key>', methods=['POST'])
def api_monitor_force_update(module_key):
    """å¼ºåˆ¶æ›´æ–°æŒ‡å®šæ¨¡å—"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'multi_module_monitor.py', 'force', module_key],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        update_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': result.returncode == 0,
            'result': update_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ==================== å¾—åˆ†ç³»ç»Ÿ API ====================
from score_calculator import ScoreCalculator

@app.route('/control-center')
def control_center_page():
    """æ·±åº¦å›¾å¾—åˆ†é¡µé¢ï¼ˆæ§åˆ¶ä¸­å¿ƒï¼‰"""
    return render_template('control_center.html')

@app.route('/depth-score')
def depth_score_page():
    """æ·±åº¦å›¾å¾—åˆ†é¡µé¢"""
    return render_template('depth_score.html')

@app.route('/depth-chart')
def depth_chart_page():
    """æ·±åº¦å›¾å¯è§†åŒ–é¡µé¢"""
    return render_template('depth_chart.html')

@app.route('/score-overview')
def score_overview_page():
    """å¹³å‡åˆ†é¡µé¢"""
    return render_template('score_overview.html')

@app.route('/crypto-index')
def crypto_index_page():
    """OKEXåŠ å¯†æŒ‡æ•°é¡µé¢"""
    return render_template('crypto_index.html')

@app.route('/api/depth-scores')
def api_depth_scores():
    """è·å–æ·±åº¦å¾—åˆ†æ•°æ®"""
    try:
        timeframe = int(request.args.get('timeframe', 24))
        limit = int(request.args.get('limit', 50))
        
        calculator = ScoreCalculator()
        scores = calculator.calculate_all_coins_depth_scores(timeframe, limit)
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_score = sum(s['score'] for s in scores) / len(scores) if scores else 0
        
        return jsonify({
            'success': True,
            'data': {
                'scores': scores,
                'total_coins': len(scores),
                'average_score': round(avg_score, 2),
                'timeframe': f'{timeframe}h'
            }
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/depth-chart-data')
def api_depth_chart_data():
    """è·å–æ·±åº¦å›¾è¡¨æ•°æ®"""
    try:
        timeframe = int(request.args.get('timeframe', 24))
        top_n = int(request.args.get('top_n', 20))
        
        calculator = ScoreCalculator()
        chart_data = calculator.get_depth_chart_data(timeframe, top_n)
        
        return jsonify({
            'success': True,
            'data': chart_data
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/market-average-score')
def api_market_average_score():
    """è·å–å¸‚åœºå¹³å‡å¾—åˆ†"""
    try:
        timeframe = int(request.args.get('timeframe', 24))
        
        calculator = ScoreCalculator()
        market_score = calculator.calculate_average_market_score(timeframe)
        
        return jsonify({
            'success': True,
            'data': market_score
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okex-crypto-index')
def api_okex_crypto_index():
    """è·å–OKEXåŠ å¯†è´§å¸æŒ‡æ•°"""
    try:
        calculator = ScoreCalculator()
        index_data = calculator.calculate_okex_crypto_index()
        
        return jsonify({
            'success': True,
            'data': index_data
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ============================================================================
# OKEXåŠ å¯†æŒ‡æ•°é¡µé¢ä¸“ç”¨APIç«¯ç‚¹
# ============================================================================

@app.route('/api/index/start', methods=['POST'])
def api_index_start():
    """å¯åŠ¨æŒ‡æ•°ç›‘æ§"""
    return jsonify({
        'success': True,
        'message': 'æŒ‡æ•°ç›‘æ§å·²å¯åŠ¨'
    })

@app.route('/api/index/current')
def api_index_current():
    """è·å–å½“å‰æŒ‡æ•°å€¼ - åŸºäº27å¸ç§åŠ æƒæŒ‡æ•°"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„Kçº¿æ•°æ®
        cursor.execute('''
            SELECT timestamp, index_value, open_price, high_price, low_price, close_price
            FROM crypto_index_klines
            ORDER BY timestamp DESC
            LIMIT 1
        ''')
        
        row = cursor.fetchone()
        
        # è·å–æœ‰å¤šå°‘ä¸ªå¸ç§æœ‰æœ‰æ•ˆçš„åŸºå‡†ä»·æ ¼
        cursor.execute('SELECT COUNT(*) FROM crypto_index_base_prices WHERE base_price > 0')
        valid_components = cursor.fetchone()[0]
        
        conn.close()
        
        if not row:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æŒ‡æ•°æ•°æ®ï¼Œè¯·ç­‰å¾…æ•°æ®é‡‡é›†'
            })
        
        current_value = row[1]
        base_value = 1000.00
        change = current_value - base_value
        change_percent = (change / base_value) * 100
        
        # è·å–BTCçš„4ä¸ªå‘¨æœŸå¹³å‡ä½ç½®æ•°æ®
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        cursor.execute('''
            SELECT position_4h, position_12h, position_24h, position_48h
            FROM position_system
            WHERE symbol = 'BTC-USDT-SWAP'
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        position_row = cursor.fetchone()
        conn.close()
        
        # å‡†å¤‡å‘¨æœŸä½ç½®æ•°æ®
        period_positions = {}
        if position_row:
            period_positions = {
                'position_4h': round(position_row[0], 2) if position_row[0] else None,
                'position_12h': round(position_row[1], 2) if position_row[1] else None,
                'position_24h': round(position_row[2], 2) if position_row[2] else None,
                'position_48h': round(position_row[3], 2) if position_row[3] else None
            }
        
        return jsonify({
            'success': True,
            'data': {
                'value': current_value,
                'base_value': base_value,
                'change': round(change, 2),
                'change_percent': round(change_percent, 2),
                'valid_components': valid_components,
                'timestamp': row[0],
                'open': row[2],
                'high': row[3],
                'low': row[4],
                'close': row[5],
                'period_positions': period_positions
            }
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–æŒ‡æ•°å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/index/components')
def api_index_components():
    """è·å–æˆåˆ†è¯¦æƒ… - 27å¸ç§æƒé‡æ˜ç»†"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰å¸ç§çš„åŸºå‡†ä»·æ ¼å’Œæƒé‡
        cursor.execute('''
            SELECT coin_id, base_price, weight
            FROM crypto_index_base_prices
            ORDER BY weight DESC, coin_id
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        # å¸ç§åç§°æ˜ å°„
        coin_name_map = {
            'bitcoin': 'BTC', 'ethereum': 'ETH', 'ripple': 'XRP',
            'binancecoin': 'BNB', 'solana': 'SOL', 'litecoin': 'LTC',
            'dogecoin': 'DOGE', 'sui': 'SUI', 'tron': 'TRX',
            'the-open-network': 'TON', 'ethereum-classic': 'ETC',
            'bitcoin-cash': 'BCH', 'hedera-hashgraph': 'HBAR',
            'stellar': 'XLM', 'filecoin': 'FIL', 'chainlink': 'LINK',
            'crypto-com-chain': 'CRO', 'polkadot': 'DOT', 'aave': 'AAVE',
            'uniswap': 'UNI', 'near': 'NEAR', 'aptos': 'APT',
            'conflux-token': 'CFX', 'curve-dao-token': 'CRV',
            'stacks': 'STX', 'lido-dao': 'LDO', 'bittensor': 'TAO'
        }
        
        # è·å–å½“å‰ä»·æ ¼ï¼ˆä»CoinGeckoï¼‰- ç®€åŒ–ç‰ˆï¼Œä»…ç”¨åŸºå‡†ä»·æ ¼æ¨¡æ‹Ÿ
        import requests
        try:
            coin_ids = ','.join([r[0] for r in rows])
            response = requests.get(
                'https://api.coingecko.com/api/v3/simple/price',
                params={'ids': coin_ids, 'vs_currencies': 'usd'},
                timeout=5
            )
            current_prices = response.json() if response.status_code == 200 else {}
        except:
            current_prices = {}
        
        # æ„å»ºæˆåˆ†æ•°æ®ï¼ˆä»¥å¯¹è±¡å½¢å¼è¿”å›ï¼Œkeyä¸ºå¸ç§symbolï¼‰
        components = {}
        for row in rows:
            coin_id = row[0]
            symbol = coin_name_map.get(coin_id, coin_id.upper())
            base_price = row[1]
            weight = row[2]
            
            # è·å–å½“å‰ä»·æ ¼
            current_price = current_prices.get(coin_id, {}).get('usd', base_price)
            price_change = ((current_price - base_price) / base_price * 100) if base_price > 0 else 0
            weighted_contribution = price_change * weight
            
            components[symbol] = {
                'name': symbol,
                'coin_id': coin_id,
                'price': current_price,
                'base_price': base_price,
                'weight': weight,
                'weight_percent': f"{weight*100:.2f}%",
                'change_percent': round(price_change, 2),
                'weighted_contribution': round(weighted_contribution, 3)
            }
        
        return jsonify({
            'success': True,
            'total_coins': len(components),
            'data': components
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–æˆåˆ†å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/test-refresh')
def test_refresh():
    """æµ‹è¯•åˆ·æ–°é¡µé¢ - ç”¨äºéªŒè¯ç¼“å­˜é—®é¢˜"""
    return render_template('test_refresh.html')

@app.route('/test-btc-eth')
def test_btc_eth():
    """æµ‹è¯•BTCå’ŒETHæ•°æ®æ˜¾ç¤º"""
    return render_template('test_btc_eth.html')

@app.route('/api/index/history')
def api_index_history():
    """è·å–å†å²æ•°æ® - åŸºäºKçº¿æ•°æ®ï¼Œæ”¯æŒåˆ†é¡µï¼ˆ12å°æ—¶ä¸€é¡µï¼‰"""
    try:
        page = int(request.args.get('page', 1))  # å½“å‰é¡µï¼Œé»˜è®¤ç¬¬1é¡µ
        hours_per_page = 12  # æ¯é¡µ12å°æ—¶
        records_per_hour = 60  # æ¯å°æ—¶60æ¡ï¼ˆ1åˆ†é’ŸKçº¿ï¼‰
        page_size = hours_per_page * records_per_hour  # æ¯é¡µ720æ¡
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æ€»è®°å½•æ•°
        cursor.execute('SELECT COUNT(*) FROM crypto_index_klines')
        total_records = cursor.fetchone()[0]
        
        # è®¡ç®—æ€»é¡µæ•°
        total_pages = (total_records + page_size - 1) // page_size
        
        # ç¡®ä¿é¡µç æœ‰æ•ˆ
        if page < 1:
            page = 1
        if page > total_pages:
            page = total_pages
        
        # è®¡ç®—åç§»é‡ï¼ˆä»æœ€æ–°æ•°æ®å¼€å§‹å€’æ•°ï¼‰
        offset = (page - 1) * page_size
        
        # è·å–å½“å‰é¡µçš„Kçº¿æ•°æ®
        cursor.execute('''
            SELECT timestamp, index_value, close_price
            FROM crypto_index_klines
            ORDER BY timestamp DESC
            LIMIT ? OFFSET ?
        ''', (page_size, offset))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— å†å²æ•°æ®'
            })
        
        history = []
        base_value = 1000.00
        for row in rows:
            index_value = row[1]
            change_percent = ((index_value - base_value) / base_value * 100)
            history.append({
                'time': row[0],
                'value': index_value,
                'close': row[2],
                'change_percent': round(change_percent, 2)
            })
        
        history.reverse()  # æ—¶é—´æ­£åº
        
        return jsonify({
            'success': True,
            'total': len(history),
            'total_records': total_records,
            'total_pages': total_pages,
            'current_page': page,
            'page_size': page_size,
            'data': history
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/index/klines')
def api_index_klines():
    """è·å–Kçº¿æ•°æ® - 5åˆ†é’ŸKçº¿"""
    try:
        limit = int(request.args.get('limit', 100))
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€è¿‘çš„Kçº¿æ•°æ®
        cursor.execute('''
            SELECT timestamp, open_price, high_price, low_price, close_price, index_value
            FROM crypto_index_klines
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— Kçº¿æ•°æ®ï¼Œè¯·ç­‰å¾…æ•°æ®é‡‡é›†'
            })
        
        klines = []
        for row in rows:
            klines.append({
                'timestamp': row[0],
                'open': row[1],
                'high': row[2],
                'low': row[3],
                'close': row[4],
                'value': row[5]
            })
        
        klines.reverse()  # æ—¶é—´æ­£åº
        
        return jsonify({
            'success': True,
            'total': len(klines),
            'interval': '5m',
            'data': klines
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–Kçº¿å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

# ==================== ä½ç½®ç³»ç»Ÿ API ====================

@app.route('/position-system')
def position_system():
    """ä½ç½®ç³»ç»Ÿé¡µé¢"""
    return render_template('position_system.html')

@app.route('/api/position/latest')
def api_position_latest():
    """è·å–æœ€æ–°ä½ç½®æ•°æ®"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„è®°å½•æ—¶é—´
        cursor.execute('SELECT MAX(record_time) FROM position_system')
        latest_time = cursor.fetchone()[0]
        
        if not latest_time:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # è·å–è¯¥æ—¶é—´çš„æ‰€æœ‰å¸ç§æ•°æ®
        cursor.execute('''
            SELECT symbol, current_price,
                   position_4h, position_12h, position_24h, position_48h,
                   high_4h, low_4h, high_12h, low_12h, high_24h, low_24h, high_48h, low_48h
            FROM position_system
            WHERE record_time = ?
            ORDER BY symbol
        ''', (latest_time,))
        
        rows = cursor.fetchall()
        
        # æ„é€ è¿”å›æ•°æ®
        data_list = []
        symbol_set = set()
        for row in rows:
            symbol_set.add(row[0])
            data_list.append({
                'symbol': row[0],
                'current_price': row[1],
                'position_4h': row[2],
                'position_12h': row[3],
                'position_24h': row[4],
                'position_48h': row[5],
                'high_4h': row[6],
                'low_4h': row[7],
                'high_12h': row[8],
                'low_12h': row[9],
                'high_24h': row[10],
                'low_24h': row[11],
                'high_48h': row[12],
                'low_48h': row[13]
            })
        
        # æ£€æŸ¥BTCå’ŒETHæ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»æœ€è¿‘è®°å½•ä¸­è¡¥å……
        missing_coins = []
        if 'BTC-USDT-SWAP' not in symbol_set:
            missing_coins.append('BTC-USDT-SWAP')
        if 'ETH-USDT-SWAP' not in symbol_set:
            missing_coins.append('ETH-USDT-SWAP')
        
        if missing_coins:
            for coin in missing_coins:
                cursor.execute('''
                    SELECT symbol, current_price,
                           position_4h, position_12h, position_24h, position_48h,
                           high_4h, low_4h, high_12h, low_12h, high_24h, low_24h, high_48h, low_48h
                    FROM position_system
                    WHERE symbol = ?
                    ORDER BY record_time DESC
                    LIMIT 1
                ''', (coin,))
                coin_row = cursor.fetchone()
                if coin_row:
                    data_list.append({
                        'symbol': coin_row[0],
                        'current_price': coin_row[1],
                        'position_4h': coin_row[2],
                        'position_12h': coin_row[3],
                        'position_24h': coin_row[4],
                        'position_48h': coin_row[5],
                        'high_4h': coin_row[6],
                        'low_4h': coin_row[7],
                        'high_12h': coin_row[8],
                        'low_12h': coin_row[9],
                        'high_24h': coin_row[10],
                        'low_24h': coin_row[11],
                        'high_48h': coin_row[12],
                        'low_48h': coin_row[13]
                    })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'record_time': latest_time,
            'total_count': len(data_list),
            'data': data_list
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ•°æ®å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/summary')
def api_position_summary():
    """è·å–ä½ç½®ç»Ÿè®¡æ‘˜è¦"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„è®°å½•æ—¶é—´
        cursor.execute('SELECT MAX(record_time) FROM position_system')
        latest_time = cursor.fetchone()[0]
        
        if not latest_time:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # ç»Ÿè®¡å„å‘¨æœŸçš„å¹³å‡ä½ç½®
        cursor.execute('''
            SELECT 
                AVG(position_4h) as avg_4h,
                AVG(position_12h) as avg_12h,
                AVG(position_24h) as avg_24h,
                AVG(position_48h) as avg_48h,
                COUNT(*) as total_count
            FROM position_system
            WHERE record_time = ?
        ''', (latest_time,))
        
        row = cursor.fetchone()
        
        # ç»Ÿè®¡å„åŒºé—´çš„å¸ç§æ•°é‡ï¼ˆä»¥24hä¸ºä¾‹ï¼‰
        cursor.execute('''
            SELECT 
                SUM(CASE WHEN position_24h >= 80 THEN 1 ELSE 0 END) as high_zone,
                SUM(CASE WHEN position_24h >= 50 AND position_24h < 80 THEN 1 ELSE 0 END) as mid_high_zone,
                SUM(CASE WHEN position_24h >= 20 AND position_24h < 50 THEN 1 ELSE 0 END) as mid_low_zone,
                SUM(CASE WHEN position_24h < 20 THEN 1 ELSE 0 END) as low_zone
            FROM position_system
            WHERE record_time = ?
        ''', (latest_time,))
        
        zone_counts = cursor.fetchone()
        
        # æ–°å¢ï¼šç»Ÿè®¡å„å‘¨æœŸ>=95%çš„å¸ç§æ•°é‡
        cursor.execute('''
            SELECT 
                SUM(CASE WHEN position_4h >= 95 THEN 1 ELSE 0 END) as count_4h_ge95,
                SUM(CASE WHEN position_12h >= 95 THEN 1 ELSE 0 END) as count_12h_ge95,
                SUM(CASE WHEN position_24h >= 95 THEN 1 ELSE 0 END) as count_24h_ge95,
                SUM(CASE WHEN position_48h >= 95 THEN 1 ELSE 0 END) as count_48h_ge95
            FROM position_system
            WHERE record_time = ?
        ''', (latest_time,))
        
        ge95_counts = cursor.fetchone()
        conn.close()
        
        return jsonify({
            'success': True,
            'record_time': latest_time,
            'averages': {
                '4h': round(row[0], 2) if row[0] else 0,
                '12h': round(row[1], 2) if row[1] else 0,
                '24h': round(row[2], 2) if row[2] else 0,
                '48h': round(row[3], 2) if row[3] else 0
            },
            'total_count': row[4],
            'zone_distribution_24h': {
                'high': zone_counts[0] or 0,      # 80-100%
                'mid_high': zone_counts[1] or 0,  # 50-80%
                'mid_low': zone_counts[2] or 0,   # 20-50%
                'low': zone_counts[3] or 0        # 0-20%
            },
            'high_position_counts': {
                '4h': ge95_counts[0] or 0,   # 4å°æ—¶>=95%
                '12h': ge95_counts[1] or 0,  # 12å°æ—¶>=95%
                '24h': ge95_counts[2] or 0,  # 24å°æ—¶>=95%
                '48h': ge95_counts[3] or 0   # 48å°æ—¶>=95%
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/history/<symbol>')
def api_position_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²ä½ç½®æ•°æ®"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€è¿‘24å°æ—¶çš„æ•°æ®
        cursor.execute('''
            SELECT record_time, current_price,
                   position_4h, position_12h, position_24h, position_48h
            FROM position_system
            WHERE symbol = ?
            ORDER BY record_time DESC
            LIMIT 288
        ''', (symbol,))
        
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'time': row[0],
                'price': row[1],
                '4h': row[2],
                '12h': row[3],
                '24h': row[4],
                '48h': row[5]
            })
        
        history.reverse()  # æ—¶é—´æ­£åº
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'data': history
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/stats/latest')
def api_position_stats_latest():
    """è·å–æœ€æ–°çš„ä½ç½®ç»Ÿè®¡æ•°æ®ï¼ˆä½äº1%çš„å¸ç§æ•°é‡ï¼‰"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„ç»Ÿè®¡æ•°æ®
        cursor.execute('''
            SELECT record_time, count_below_1_4h, count_below_1_12h, 
                   count_below_1_24h, count_below_1_48h, total_coins
            FROM position_system_stats
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— ç»Ÿè®¡æ•°æ®'
            })
        
        return jsonify({
            'success': True,
            'record_time': row[0],
            'stats': {
                '4h': {'below_1': row[1], 'total': row[5]},
                '12h': {'below_1': row[2], 'total': row[5]},
                '24h': {'below_1': row[3], 'total': row[5]},
                '48h': {'below_1': row[4], 'total': row[5]}
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/stats/history')
def api_position_stats_history():
    """è·å–ç»Ÿè®¡æ•°æ®å†å²è®°å½•"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        limit = request.args.get('limit', default=100, type=int)
        start_time = request.args.get('start_time', default=None, type=str)
        end_time = request.args.get('end_time', default=None, type=str)
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = '''
            SELECT record_time, count_below_1_4h, count_below_1_12h, 
                   count_below_1_24h, count_below_1_48h, total_coins
            FROM position_system_stats
            WHERE 1=1
        '''
        params = []
        
        if start_time:
            query += ' AND record_time >= ?'
            params.append(start_time)
        
        if end_time:
            query += ' AND record_time <= ?'
            params.append(end_time)
        
        query += ' ORDER BY record_time DESC LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'time': row[0],
                '4h': {'below_1': row[1], 'total': row[5]},
                '12h': {'below_1': row[2], 'total': row[5]},
                '24h': {'below_1': row[3], 'total': row[5]},
                '48h': {'below_1': row[4], 'total': row[5]}
            })
        
        history.reverse()  # æ—¶é—´æ­£åº
        
        return jsonify({
            'success': True,
            'count': len(history),
            'data': history
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²ç»Ÿè®¡å¤±è´¥: {str(e)}'
        })

@app.route('/v1v2-volume')
def v1v2_volume():
    """V1V2æˆäº¤é‡ç³»ç»Ÿé¡µé¢"""
    return render_template('v1v2_volume.html')

@app.route('/v1v2-monitor')
def v1v2_monitor():
    """V1V2æˆäº¤é¢ç›‘æ§é¡µé¢"""
    return render_template('v1v2_monitor.html')

@app.route('/api/v1v2/latest')
def api_v1v2_latest():
    """è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°V1V2æ•°æ®"""
    try:
        import sqlite3
        from datetime import datetime
        
        conn = sqlite3.connect('v1v2_data.db')
        cursor = conn.cursor()
        
        # 27ä¸ªå¸ç§é…ç½®
        coins_config = {
            'BTC': {'v1': 200000, 'v2': 100000},
            'ETH': {'v1': 1300000, 'v2': 500000},
            'XRP': {'v1': 200000, 'v2': 87000},
            'SOL': {'v1': 351620, 'v2': 246380},
            'BNB': {'v1': 2388300, 'v2': 1737500},
            'LTC': {'v1': 50000, 'v2': 15000},
            'DOGE': {'v1': 150000, 'v2': 60000},
            'SUI': {'v1': 2000000, 'v2': 800000},
            'TRX': {'v1': 13280, 'v2': 6022},
            'TON': {'v1': 350000, 'v2': 200000},
            'ETC': {'v1': 12000, 'v2': 2000},
            'BCH': {'v1': 103500, 'v2': 50000},
            'HBAR': {'v1': 103500, 'v2': 40000},
            'XLM': {'v1': 103500, 'v2': 30000},
            'FIL': {'v1': 5003500, 'v2': 3700000},
            'ADA': {'v1': 67210, 'v2': 44230},
            'LINK': {'v1': 280000, 'v2': 200000},
            'CRO': {'v1': 100000, 'v2': 40000},
            'DOT': {'v1': 300000, 'v2': 250000},
            'UNI': {'v1': 140000, 'v2': 100000},
            'NEAR': {'v1': 100000, 'v2': 50000},
            'APT': {'v1': 300000, 'v2': 200000},
            'CFX': {'v1': 300000, 'v2': 250000},
            'CRV': {'v1': 1500000, 'v2': 1000000},
            'STX': {'v1': 50000, 'v2': 30000},
            'LDO': {'v1': 1000000, 'v2': 600000},
            'TAO': {'v1': 300000, 'v2': 180000}
        }
        
        result = []
        update_time = None
        
        for symbol, thresholds in coins_config.items():
            table_name = f'volume_{symbol.lower()}'
            
            try:
                # è·å–æœ€æ–°ä¸€æ¡è®°å½•ï¼ˆæŒ‰IDé™åºï¼Œç¡®ä¿è·å–æœ€æ–°æ’å…¥çš„æ•°æ®ï¼‰
                cursor.execute(f'''
                    SELECT volume, collect_time, level, timestamp
                    FROM {table_name}
                    ORDER BY id DESC
                    LIMIT 1
                ''')
                
                row = cursor.fetchone()
                
                if row:
                    result.append({
                        'symbol': symbol,
                        'volume': row[0],
                        'collect_time': row[1],
                        'level': row[2],
                        'v1': thresholds['v1'],
                        'v2': thresholds['v2']
                    })
                    
                    if not update_time:
                        update_time = row[1]
                        
            except sqlite3.OperationalError:
                # è¡¨ä¸å­˜åœ¨,è·³è¿‡
                continue
        
        conn.close()
        
        # æŒ‰çº§åˆ«æ’åº: V1 > V2 > NONE
        level_order = {'V1': 0, 'V2': 1, 'NONE': 2}
        result.sort(key=lambda x: (level_order.get(x['level'], 3), -x['volume']))
        
        return jsonify({
            'success': True,
            'count': len(result),
            'data': result,
            'update_time': update_time
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ•°æ®å¤±è´¥: {str(e)}'
        })

@app.route('/v1v2-settings')
def v1v2_settings():
    """V1V2é˜ˆå€¼è®¾ç½®é¡µé¢"""
    return render_template('v1v2_settings.html')

@app.route('/api/v1v2/settings', methods=['GET', 'POST'])
def api_v1v2_settings():
    """è·å–æˆ–æ›´æ–°V1V2é˜ˆå€¼è®¾ç½®"""
    import json
    import os
    
    SETTINGS_FILE = 'v1v2_settings.json'
    
    # é»˜è®¤é…ç½®
    DEFAULT_SETTINGS = {
        'BTC': {'v1': 200000, 'v2': 100000},
        'ETH': {'v1': 1300000, 'v2': 500000},
        'XRP': {'v1': 200000, 'v2': 87000},
        'SOL': {'v1': 351620, 'v2': 246380},
        'BNB': {'v1': 2388300, 'v2': 1737500},
        'LTC': {'v1': 50000, 'v2': 15000},
        'DOGE': {'v1': 150000, 'v2': 60000},
        'SUI': {'v1': 2000000, 'v2': 800000},
        'TRX': {'v1': 13280, 'v2': 6022},
        'TON': {'v1': 350000, 'v2': 200000},
        'ETC': {'v1': 12000, 'v2': 2000},
        'BCH': {'v1': 103500, 'v2': 50000},
        'HBAR': {'v1': 103500, 'v2': 40000},
        'XLM': {'v1': 103500, 'v2': 30000},
        'FIL': {'v1': 5003500, 'v2': 3700000},
        'ADA': {'v1': 67210, 'v2': 44230},
        'LINK': {'v1': 280000, 'v2': 200000},
        'CRO': {'v1': 100000, 'v2': 40000},
        'DOT': {'v1': 300000, 'v2': 250000},
        'UNI': {'v1': 140000, 'v2': 100000},
        'NEAR': {'v1': 100000, 'v2': 50000},
        'APT': {'v1': 300000, 'v2': 200000},
        'CFX': {'v1': 300000, 'v2': 250000},
        'CRV': {'v1': 1500000, 'v2': 1000000},
        'STX': {'v1': 50000, 'v2': 30000},
        'LDO': {'v1': 1000000, 'v2': 600000},
        'TAO': {'v1': 300000, 'v2': 180000}
    }
    
    if request.method == 'GET':
        # è¯»å–è®¾ç½®
        try:
            if os.path.exists(SETTINGS_FILE):
                with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
                    settings = json.load(f)
            else:
                settings = DEFAULT_SETTINGS
                # ä¿å­˜é»˜è®¤è®¾ç½®
                with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(settings, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'settings': settings
            })
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'è¯»å–è®¾ç½®å¤±è´¥: {str(e)}'
            })
    
    elif request.method == 'POST':
        # æ›´æ–°è®¾ç½®
        try:
            data = request.get_json()
            new_settings = data.get('settings', {})
            
            # éªŒè¯æ•°æ®
            for symbol, config in new_settings.items():
                if 'v1' not in config or 'v2' not in config:
                    return jsonify({
                        'success': False,
                        'message': f'å¸ç§ {symbol} é…ç½®ä¸å®Œæ•´'
                    })
                
                # ç¡®ä¿V1 > V2
                if config['v1'] <= config['v2']:
                    return jsonify({
                        'success': False,
                        'message': f'å¸ç§ {symbol}: V1é˜ˆå€¼å¿…é¡»å¤§äºV2é˜ˆå€¼'
                    })
            
            # ä¿å­˜è®¾ç½®
            with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
                json.dump(new_settings, f, indent=2, ensure_ascii=False)
            
            # è§¦å‘é‡‡é›†å™¨é‡æ–°åŠ è½½é…ç½®ï¼ˆé€šè¿‡åˆ›å»ºæ ‡è®°æ–‡ä»¶ï¼‰
            with open('.v1v2_settings_updated', 'w') as f:
                f.write(str(int(time.time())))
            
            return jsonify({
                'success': True,
                'message': 'è®¾ç½®å·²ä¿å­˜ï¼Œé‡‡é›†å™¨å°†åœ¨ä¸‹æ¬¡é‡‡é›†æ—¶ä½¿ç”¨æ–°é…ç½®'
            })
            
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'ä¿å­˜è®¾ç½®å¤±è´¥: {str(e)}'
            })

@app.route('/api/v1v2/statistics')
def api_v1v2_statistics():
    """è·å–V1V2ä¿¡å·ç»Ÿè®¡æ•°æ®ï¼ˆ1h/3h/12h/1day/3day/7dayï¼‰"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('v1v2_data.db', timeout=30.0)
        conn.execute('PRAGMA journal_mode=WAL')
        conn.execute('PRAGMA busy_timeout=30000')
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰å¸ç§è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'volume_%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        # å®šä¹‰æ—¶é—´èŒƒå›´
        now = datetime.now()
        time_ranges = {
            '1h': now - timedelta(hours=1),
            '3h': now - timedelta(hours=3),
            '12h': now - timedelta(hours=12),
            '1day': now - timedelta(days=1),
            '3day': now - timedelta(days=3),
            '7day': now - timedelta(days=7)
        }
        
        statistics = []
        
        for table_name in tables:
            symbol = table_name.replace('volume_', '').upper()
            
            try:
                coin_stats = {
                    'symbol': symbol,
                    '1h': {'v1': 0, 'v2': 0, 'total': 0},
                    '3h': {'v1': 0, 'v2': 0, 'total': 0},
                    '12h': {'v1': 0, 'v2': 0, 'total': 0},
                    '1day': {'v1': 0, 'v2': 0, 'total': 0},
                    '3day': {'v1': 0, 'v2': 0, 'total': 0},
                    '7day': {'v1': 0, 'v2': 0, 'total': 0}
                }
                
                # å¯¹æ¯ä¸ªæ—¶é—´èŒƒå›´è¿›è¡Œç»Ÿè®¡
                for period, start_time in time_ranges.items():
                    start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # ç»Ÿè®¡V1å’ŒV2çš„æ¬¡æ•°ï¼ˆåªç»Ÿè®¡V1å’ŒV2ï¼‰
                    cursor.execute(f"""
                        SELECT level, COUNT(*) 
                        FROM {table_name} 
                        WHERE collect_time >= ? AND level IN ('V1', 'V2')
                        GROUP BY level
                    """, (start_time_str,))
                    
                    counts = dict(cursor.fetchall())
                    v1_count = counts.get('V1', 0)
                    v2_count = counts.get('V2', 0)
                    
                    coin_stats[period]['v1'] = v1_count
                    coin_stats[period]['v2'] = v2_count
                    coin_stats[period]['total'] = v1_count + v2_count
                
                statistics.append(coin_stats)
                
            except sqlite3.OperationalError:
                # è¡¨ä¸å­˜åœ¨æˆ–å‡ºé”™ï¼Œè·³è¿‡
                continue
        
        conn.close()
        
        # æŒ‰7å¤©æ€»ä¿¡å·æ•°æ’åº
        statistics.sort(key=lambda x: x['7day']['total'], reverse=True)
        
        return jsonify({
            'success': True,
            'data': {
                'statistics': statistics,
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'total_coins': len(statistics)
            }
        })
        
    except Exception as e:
        import traceback
        print(f"âŒ V1V2ç»Ÿè®¡APIé”™è¯¯: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}'
        }), 500

@app.route('/price-speed-monitor')
def price_speed_monitor():
    """1åˆ†é’Ÿæ¶¨è·Œé€Ÿç›‘æ§é¡µé¢"""
    return render_template('price_speed_monitor.html')

@app.route('/api/price-speed/latest')
def api_price_speed_latest():
    """è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°æ¶¨è·Œé€Ÿæ•°æ®"""
    try:
        import sqlite3
        from datetime import datetime
        import pytz
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        conn = sqlite3.connect('price_speed_data.db')
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°æ•°æ®
        cursor.execute('''
            SELECT symbol, current_price, previous_price, change_percent, 
                   alert_level, alert_type, timestamp
            FROM latest_price_speed
            ORDER BY symbol
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'symbol': row[0],
                'current_price': row[1],
                'previous_price': row[2],
                'change_percent': row[3],
                'alert_level': row[4],
                'alert_type': row[5],
                'timestamp': row[6]
            })
        
        return jsonify({
            'success': True,
            'count': len(data),
            'data': data,
            'update_time': datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ¶¨è·Œé€Ÿæ•°æ®å¤±è´¥: {str(e)}',
            'data': []
        })

@app.route('/api/price-speed/history/<symbol>')
def api_price_speed_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²æ¶¨è·Œé€Ÿæ•°æ®"""
    try:
        import sqlite3
        
        # è·å–æŸ¥è¯¢å‚æ•°
        limit = request.args.get('limit', 100, type=int)
        
        conn = sqlite3.connect('price_speed_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT current_price, previous_price, change_percent, 
                   alert_level, alert_type, timestamp
            FROM price_speed_alerts
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (symbol, limit))
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'current_price': row[0],
                'previous_price': row[1],
                'change_percent': row[2],
                'alert_level': row[3],
                'alert_type': row[4],
                'timestamp': row[5]
            })
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'count': len(data),
            'data': data
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}',
            'data': []
        })

# ============================================================================
# Google Drive TXTæ£€æµ‹å™¨ API
# ============================================================================

@app.route('/gdrive-detector')
def gdrive_detector_page():
    """Google Driveæ£€æµ‹å™¨é¡µé¢"""
    return render_template('gdrive_detector.html')

@app.route('/test-gdrive-status')
def test_gdrive_status():
    """Google DriveçŠ¶æ€æµ‹è¯•é¡µé¢"""
    return render_template('test_gdrive_status.html')

@app.route('/gdrive-detector-fresh')
def gdrive_detector_fresh():
    """Google Driveæ£€æµ‹å™¨é¡µé¢ï¼ˆæ— ç¼“å­˜ç‰ˆæœ¬ï¼‰"""
    import time
    return render_template('gdrive_detector_fresh.html', timestamp=int(time.time()))

@app.route('/opening-logic')
def opening_logic_page():
    """å¼€ä»“é€»è¾‘ç³»ç»Ÿé¡µé¢"""
    from flask import make_response
    response = make_response(render_template('opening_logic.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/opening-logic/suggestion')
def opening_logic_suggestion():
    """è·å–å¼€ä»“å»ºè®®API"""
    try:
        from opening_logic import get_opening_suggestion
        result = get_opening_suggestion()
        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/gdrive-detector/status')
def gdrive_detector_status():
    """è·å–Google Driveæ£€æµ‹å™¨çŠ¶æ€"""
    try:
        import subprocess
        import re
        import requests
        from datetime import datetime
        import pytz
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # æ£€æŸ¥æ£€æµ‹å™¨è¿›ç¨‹æ˜¯å¦è¿è¡Œ
        result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)
        detector_running = ('gdrive_txt_detector.py' in result.stdout or 
                          'gdrive_final_detector.py' in result.stdout or
                          'gdrive_smart_detector.py' in result.stdout)
        
        # ä»æ•°æ®åº“è¯»å–æœ€æ–°æ•°æ®æ—¶é—´æˆ³
        file_timestamp = None
        delay_minutes = None
        
        try:
            import sqlite3
            db_path = '/home/user/webapp/crypto_data.db'
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT snapshot_time FROM crypto_snapshots ORDER BY created_at DESC LIMIT 1")
            result = cursor.fetchone()
            conn.close()
            
            if result:
                file_timestamp = result[0]
                # è®¡ç®—å»¶è¿Ÿ - æ•°æ®åº“æ—¶é—´æ˜¯åŒ—äº¬æ—¶é—´
                try:
                    last_time = datetime.strptime(file_timestamp, '%Y-%m-%d %H:%M:%S')
                except ValueError:
                    last_time = datetime.strptime(file_timestamp, '%Y-%m-%d %H:%M:%S.%f')
                
                # æ•°æ®åº“å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼Œç›´æ¥ä¸åŒ—äº¬æ—¶é—´æ¯”è¾ƒ
                last_time_beijing = beijing_tz.localize(last_time)
                delay_seconds = (now - last_time_beijing).total_seconds()
                delay_minutes = delay_seconds / 60
        except:
            pass
        
        # è¯»å–æ—¥å¿—è·å–æ£€æŸ¥æ¬¡æ•°
        check_count = 0
        last_check_time = None
        try:
            with open('/home/user/webapp/gdrive_final_detector.log', 'r') as f:
                lines = f.readlines()
                for line in lines:
                    if 'æ£€æŸ¥ #' in line:
                        match = re.search(r'æ£€æŸ¥ #(\d+)', line)
                        if match:
                            check_count = int(match.group(1))
                    if re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', line):
                        # æå–æ—¶é—´æˆ³
                        match = re.search(r'(2025-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                        if match:
                            last_check_time = match.group(1)
        except:
            pass
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ‰€æœ‰æ–‡ä»¶å¤¹ID
        root_folder_odd = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"  # é»˜è®¤å€¼
        root_folder_even = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"  # é»˜è®¤å€¼
        folder_id = None  # å­è´¦å·æ–‡ä»¶å¤¹IDï¼ˆä»Šæ—¥æ–‡ä»¶å¤¹ï¼‰
        
        try:
            import json
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # è¯»å–å•æ•°/åŒæ•°çˆ¶æ–‡ä»¶å¤¹ID
                if 'root_folder_odd' in config:
                    root_folder_odd = config['root_folder_odd']
                if 'root_folder_even' in config:
                    root_folder_even = config['root_folder_even']
                # ğŸ†• è¯»å–å­è´¦å·æ–‡ä»¶å¤¹IDï¼ˆä»Šæ—¥æ–‡ä»¶å¤¹ï¼‰
                if 'folder_id' in config:
                    folder_id = config['folder_id']
        except:
            pass
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰å­è´¦å·æ–‡ä»¶å¤¹IDï¼Œå°è¯•ä»æ—¥å¿—è¯»å–
        if not folder_id:
            try:
                with open('/home/user/webapp/gdrive_final_detector.log', 'r') as f:
                    lines = f.readlines()
                    for line in reversed(lines[-100:]):  # åªçœ‹æœ€è¿‘100è¡Œ
                        # æå–æ–‡ä»¶å¤¹IDï¼ˆå­è´¦å·ï¼‰
                        if 'ä»Šæ—¥æ–‡ä»¶å¤¹' in line or 'å­æ–‡ä»¶å¤¹' in line:
                            match = re.search(r'([A-Za-z0-9_-]{20,})', line)
                            if match and match.group(1) != root_folder_odd and match.group(1) != root_folder_even:
                                folder_id = match.group(1)
                                break
            except:
                pass
        
        return jsonify({
            'success': True,
            'data': {
                'detector_running': detector_running,
                'file_timestamp': file_timestamp,
                'delay_minutes': delay_minutes,
                'check_count': check_count,
                'last_check_time': last_check_time,
                'current_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'folder_id': folder_id,
                'root_folder_odd': root_folder_odd,
                'root_folder_even': root_folder_even,
                'today_date': now.strftime('%Yå¹´%mæœˆ%dæ—¥')
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'data': None
        })

@app.route('/api/gdrive-detector/txt-files')
def gdrive_detector_txt_files():
    """è·å–ä»Šå¤©çš„TXTæ–‡ä»¶åˆ—è¡¨"""
    try:
        import requests
        import re
        from datetime import datetime
        import pytz
        import json
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        today = datetime.now(beijing_tz).strftime('%Y-%m-%d')
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–ä»Šå¤©çš„æ–‡ä»¶å¤¹ID
        folder_id = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"  # é»˜è®¤å€¼
        try:
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('current_date') == today and 'folder_id' in config:
                    folder_id = config['folder_id']
        except:
            pass
        
        url = f"https://drive.google.com/embeddedfolderview?id={folder_id}"
        
        response = requests.get(url, timeout=10)
        content = response.text
        
        # æŸ¥æ‰¾ä»Šå¤©æ‰€æœ‰çš„TXTæ–‡ä»¶
        pattern = rf'>{today}_(\d{{4}})\.txt<'
        matches = re.findall(pattern, content)
        
        # æ’åºï¼ˆä»æ–°åˆ°æ—§ï¼‰
        times_sorted = sorted(matches, reverse=True)
        filenames = [f"{today}_{time}.txt" for time in times_sorted]
        
        return jsonify({
            'success': True,
            'files': filenames,
            'count': len(filenames),
            'date': today,
            'folder_id': folder_id
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'files': [],
            'count': 0
        })

@app.route('/api/gdrive-detector/logs')
def gdrive_detector_logs():
    """è·å–æ£€æµ‹å™¨æ—¥å¿—"""
    try:
        lines = request.args.get('lines', 50, type=int)
        
        # å°è¯•å¤šä¸ªæ—¥å¿—æ–‡ä»¶
        log_files = [
            '/home/user/webapp/gdrive_final_detector.log',
            '/home/user/webapp/gdrive_txt_detector.log',
            '/home/user/webapp/gdrive_smart_detector.log'
        ]
        
        log_content = None
        total_lines = 0
        
        for log_file in log_files:
            try:
                with open(log_file, 'r') as f:
                    all_lines = f.readlines()
                    log_content = ''.join(all_lines[-lines:] if len(all_lines) > lines else all_lines)
                    total_lines = len(all_lines)
                    break
            except FileNotFoundError:
                continue
        
        if log_content is not None:
            return jsonify({
                'success': True,
                'logs': log_content,
                'total_lines': total_lines
            })
        else:
            return jsonify({
                'success': True,
                'logs': 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨',
                'total_lines': 0
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'logs': ''
        })

@app.route('/api/gdrive-detector/config', methods=['GET'])
def gdrive_detector_get_config():
    """è·å–Google Driveé…ç½®"""
    try:
        import json
        config_file = '/home/user/webapp/daily_folder_config.json'
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/gdrive-detector/config', methods=['POST'])
def gdrive_detector_update_config():
    """æ›´æ–°Google Driveé…ç½®ï¼ˆçˆ¶æ–‡ä»¶å¤¹å…±äº«é“¾æ¥ï¼‰"""
    try:
        import json
        import re
        import requests
        from datetime import datetime
        import pytz
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        data = request.get_json()
        parent_folder_url = data.get('parent_folder_url', '')
        
        # ä»URLä¸­æå–æ–‡ä»¶å¤¹ID
        match = re.search(r'folders/([A-Za-z0-9_-]+)', parent_folder_url)
        if not match:
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„Google Driveæ–‡ä»¶å¤¹é“¾æ¥'
            })
        
        parent_folder_id = match.group(1)
        
        # è·å–çˆ¶æ–‡ä»¶å¤¹å†…çš„ä»Šæ—¥æ–‡ä»¶å¤¹
        today_str = now.strftime('%Y-%m-%d')
        url = f"https://drive.google.com/embeddedfolderview?id={parent_folder_id}"
        response = requests.get(url, timeout=10)
        content = response.text
        
        # æŸ¥æ‰¾ä»Šæ—¥æ—¥æœŸæ–‡ä»¶å¤¹
        folder_pattern = rf'>{today_str}<'
        if today_str not in content:
            return jsonify({
                'success': False,
                'message': f'çˆ¶æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»Šæ—¥æ–‡ä»¶å¤¹: {today_str}'
            })
        
        # æå–ä»Šæ—¥æ–‡ä»¶å¤¹ID
        # æŸ¥æ‰¾åŒ…å«ä»Šæ—¥æ—¥æœŸçš„æ–‡ä»¶å¤¹é“¾æ¥
        folder_id_pattern = rf'"([A-Za-z0-9_-]{{20,}})"[^>]*>{today_str}<'
        folder_match = re.search(folder_id_pattern, content)
        
        if not folder_match:
            # å°è¯•å¦ä¸€ç§æ¨¡å¼
            folder_id_pattern = rf'https://drive\.google\.com/drive/folders/([A-Za-z0-9_-]+)[^>]*>{today_str}<'
            folder_match = re.search(folder_id_pattern, content)
        
        if not folder_match:
            return jsonify({
                'success': False,
                'message': f'æ— æ³•ä»çˆ¶æ–‡ä»¶å¤¹ä¸­æå–ä»Šæ—¥æ–‡ä»¶å¤¹ID: {today_str}'
            })
        
        today_folder_id = folder_match.group(1)
        
        # éªŒè¯ä»Šæ—¥æ–‡ä»¶å¤¹æ˜¯å¦åŒ…å«TXTæ–‡ä»¶
        txt_url = f"https://drive.google.com/embeddedfolderview?id={today_folder_id}"
        txt_response = requests.get(txt_url, timeout=10)
        txt_content = txt_response.text
        
        # æŸ¥æ‰¾TXTæ–‡ä»¶
        txt_pattern = rf'>{today_str}_(\d{{4}})\.txt<'
        txt_matches = re.findall(txt_pattern, txt_content)
        
        if not txt_matches:
            return jsonify({
                'success': False,
                'message': f'ä»Šæ—¥æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°TXTæ–‡ä»¶'
            })
        
        # è·å–æœ€æ–°çš„TXTæ–‡ä»¶
        latest_txt_time = sorted(txt_matches, reverse=True)[0]
        latest_txt = f"{today_str}_{latest_txt_time}.txt"
        
        # æ›´æ–°é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except:
            config = {}
        
        # åˆ¤æ–­ä»Šå¤©æ˜¯å•æ•°è¿˜æ˜¯åŒæ•°æ—¥æœŸ
        day_of_month = now.day
        is_odd_day = day_of_month % 2 == 1
        
        # æ›´æ–°é…ç½®
        config['parent_folder_url'] = parent_folder_url
        config['parent_folder_id'] = parent_folder_id
        config['current_date'] = today_str
        config['data_date'] = today_str
        config['folder_id'] = today_folder_id
        config['folder_name'] = today_str
        config['latest_txt'] = latest_txt
        config['txt_count'] = len(txt_matches)
        config['last_update'] = now.strftime('%Y-%m-%d %H:%M:%S')
        config['update_reason'] = 'é€šè¿‡é…ç½®é¡µé¢æ›´æ–°çˆ¶æ–‡ä»¶å¤¹'
        config['last_manual_update'] = now.strftime('%Y-%m-%d %H:%M:%S')
        
        # æ ¹æ®å•åŒæ•°æ›´æ–°å¯¹åº”çš„çˆ¶æ–‡ä»¶å¤¹ID
        if is_odd_day:
            config['root_folder_odd'] = parent_folder_id
        else:
            config['root_folder_even'] = parent_folder_id
        
        # ä¿å­˜é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': 'é…ç½®æ›´æ–°æˆåŠŸ',
            'data': {
                'parent_folder_id': parent_folder_id,
                'today_folder_id': today_folder_id,
                'today_date': today_str,
                'txt_count': len(txt_matches),
                'latest_txt': latest_txt,
                'is_odd_day': is_odd_day
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/gdrive-detector/trigger-update', methods=['POST'])
def gdrive_detector_trigger_update():
    """è§¦å‘æ‰‹åŠ¨æ›´æ–°æ£€æµ‹"""
    try:
        import subprocess
        import time
        
        # è¿è¡Œæ£€æµ‹è„šæœ¬ä¸€æ¬¡
        result = subprocess.run(
            ['python3', '/home/user/webapp/gdrive_final_detector.py'],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        return jsonify({
            'success': True,
            'message': 'æ£€æµ‹å·²æ‰§è¡Œ',
            'output': result.stdout[:500] if result.stdout else '',
            'error': result.stderr[:500] if result.stderr else ''
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'message': 'æ£€æµ‹è¶…æ—¶ï¼ˆ30ç§’ï¼‰'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/gdrive-config')
def gdrive_config_page():
    """Google Driveé…ç½®é¡µé¢"""
    return render_template('gdrive_config.html')

# ==================== ç»Ÿä¸€ç›‘æ§é¡µé¢ ====================
@app.route('/unified-monitor')
def unified_monitor():
    """ç»Ÿä¸€é‡‡é›†ç›‘æ§é¡µé¢"""
    return render_template('unified_monitor.html')

@app.route('/unified-monitor-enhanced')
def monitor_enhanced():
    """ç»Ÿä¸€é‡‡é›†ç›‘æ§é¡µé¢ï¼ˆå¢å¼ºç‰ˆï¼‰- å¸¦æ‰§è¡Œæ—¥å¿—å’Œå¼€å…³æ§åˆ¶"""
    return render_template('unified_monitor_enhanced.html')

# ==================== ç»¼åˆé‡‡é›†å™¨ç›‘æ§ API ====================
@app.route('/api/collectors/status')
def api_collectors_status():
    """è·å–æ‰€æœ‰é‡‡é›†å™¨çš„è¿è¡ŒçŠ¶æ€"""
    try:
        import subprocess
        result = subprocess.run(
            ['python3', 'get_all_collectors_status.py'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        status_list = json.loads(result.stdout)
        
        # ç»Ÿè®¡çŠ¶æ€
        total = len(status_list)
        normal = sum(1 for s in status_list if s['status'] == 'normal')
        warning = sum(1 for s in status_list if s['status'] == 'warning')
        error = sum(1 for s in status_list if s['status'] in ['error', 'stopped', 'no_data'])
        
        return jsonify({
            'success': True,
            'collectors': status_list,
            'summary': {
                'total': total,
                'normal': normal,
                'warning': warning,
                'error': error
            },
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/favicon.ico')
def favicon():
    """å¤„ç†faviconè¯·æ±‚ï¼Œé¿å…404é”™è¯¯"""
    return '', 204  # è¿”å›æ— å†…å®¹çŠ¶æ€ç 

# ============================================================================
# å¸ç§é€‰æ‹©å’Œè¯„åˆ†ç³»ç»Ÿ
# ============================================================================

@app.route('/coin-pool')
def coin_pool_page():
    """å¸ç§æ± é¡µé¢ - ä»æ˜Ÿæ˜Ÿç³»ç»Ÿç­›é€‰çš„ä¼˜è´¨å¸ç§æ± """
    response = make_response(render_template('coin_pool.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

# ============================================================================
# æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ
# ============================================================================

@app.route('/support-resistance')
def support_resistance_page():
    """æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿé¡µé¢"""
    response = make_response(render_template('support_resistance.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/trading-signals')
def trading_signals_page():
    """å†³ç­–-äº¤æ˜“ä¿¡å·ç³»ç»Ÿé¡µé¢"""
    response = make_response(render_template('trading_signals.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

def track_trading_signal(symbol, buy_point_type, suggested_position):
    """è·Ÿè¸ªäº¤æ˜“ä¿¡å·çš„é¦–æ¬¡è§¦å‘æ—¶é—´"""
    from datetime import datetime
    import pytz
    import sqlite3
    
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(beijing_tz)
    
    signal_key = f"{symbol}_{buy_point_type}"
    
    # ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥
    conn_track = sqlite3.connect('databases/crypto_data.db')
    conn_track.row_factory = sqlite3.Row
    cursor_track = conn_track.cursor()
    
    try:
        # æ£€æŸ¥è¯¥ä¿¡å·æ˜¯å¦å·²å­˜åœ¨
        cursor_track.execute('''
            SELECT id, first_triggered_at, suggested_position 
            FROM trading_signal_history 
            WHERE signal_key = ? AND is_active = 1
        ''', (signal_key,))
        
        existing = cursor_track.fetchone()
        
        if existing:
            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
            cursor_track.execute('''
                UPDATE trading_signal_history 
                SET last_updated_at = ?, suggested_position = ?
                WHERE id = ?
            ''', (now.strftime('%Y-%m-%d %H:%M:%S'), suggested_position, existing['id']))
            conn_track.commit()
            return {
                'first_triggered_at': existing['first_triggered_at'],
                'initial_position': str(int(float(existing['suggested_position'].replace('%', '')) * 0.3)) + '%'
            }
        else:
            # æ’å…¥æ–°ä¿¡å·
            cursor_track.execute('''
                INSERT INTO trading_signal_history 
                (signal_key, symbol, buy_point_type, suggested_position, 
                 first_triggered_at, last_updated_at, is_active)
                VALUES (?, ?, ?, ?, ?, ?, 1)
            ''', (signal_key, symbol, buy_point_type, suggested_position,
                  now.strftime('%Y-%m-%d %H:%M:%S'), 
                  now.strftime('%Y-%m-%d %H:%M:%S')))
            conn_track.commit()
            return {
                'first_triggered_at': now.strftime('%Y-%m-%d %H:%M:%S'),
                'initial_position': str(int(float(suggested_position.replace('%', '')) * 0.3)) + '%'
            }
    finally:
        conn_track.close()

def check_no_new_low_5min(symbol):
    """æ£€æŸ¥åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½"""
    import sqlite3
    from datetime import datetime, timedelta
    
    conn = sqlite3.connect('databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€æ ¼å¼ï¼šFIL -> FIL-USDT-SWAP
        symbol_full = f"{symbol}-USDT-SWAP" if not symbol.endswith('-USDT-SWAP') else symbol
        symbol_short = symbol.replace('-USDT-SWAP', '')
        
        # è·å–æœ€è¿‘çš„åˆ›æ–°ä½äº‹ä»¶
        cursor.execute('''
            SELECT event_time, price
            FROM price_breakthrough_events
            WHERE symbol = ? AND event_type = 'new_low'
            ORDER BY event_time DESC
            LIMIT 1
        ''', (symbol_short,))
        
        last_new_low = cursor.fetchone()
        if not last_new_low:
            return False
        
        new_low_time = datetime.strptime(last_new_low[0], '%Y-%m-%d %H:%M:%S')
        new_low_price = last_new_low[1]
        
        # è·å–åˆ›æ–°ä½ä¹‹åçš„5ä¸ª5åˆ†é’ŸKçº¿
        cursor.execute('''
            SELECT low, timestamp
            FROM okex_kline_ohlc
            WHERE symbol = ?
              AND timeframe = '5m'
              AND datetime(timestamp/1000, 'unixepoch') > datetime(?)
            ORDER BY timestamp ASC
            LIMIT 5
        ''', (symbol_full, new_low_time.strftime('%Y-%m-%d %H:%M:%S')))
        
        klines_after = cursor.fetchall()
        
        # éœ€è¦æœ‰5æ ¹Kçº¿
        if len(klines_after) < 5:
            return False
        
        # æ£€æŸ¥è¿™5æ ¹Kçº¿æ˜¯å¦éƒ½æ²¡æœ‰åˆ›æ–°ä½
        for low, ts in klines_after:
            if low < new_low_price:
                return False
        
        return True
    finally:
        conn.close()

def get_1h_rsi(symbol):
    """è·å–1å°æ—¶RSI"""
    import sqlite3
    
    conn = sqlite3.connect('databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€æ ¼å¼
        symbol_full = f"{symbol}-USDT-SWAP" if not symbol.endswith('-USDT-SWAP') else symbol
        
        cursor.execute('''
            SELECT rsi_14
            FROM okex_technical_indicators
            WHERE symbol = ? AND timeframe IN ('1h', '1H')
            ORDER BY record_time DESC
            LIMIT 1
        ''', (symbol_full,))
        
        result = cursor.fetchone()
        return result[0] if result else None
    finally:
        conn.close()

def check_consecutive_oscillation_5min(symbol):
    """æ£€æŸ¥5åˆ†é’Ÿå‘¨æœŸè¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œåœ¨0%åˆ°+0.25%ä¹‹é—´ï¼ˆä¸åŒ…æ‹¬è´Ÿæ¶¨è·Œï¼‰"""
    import sqlite3
    
    conn = sqlite3.connect('databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€æ ¼å¼
        symbol_full = f"{symbol}-USDT-SWAP" if not symbol.endswith('-USDT-SWAP') else symbol
        
        # è·å–æœ€è¿‘3æ ¹5åˆ†é’ŸKçº¿
        cursor.execute('''
            SELECT open, high, low, close
            FROM okex_kline_ohlc
            WHERE symbol = ?
              AND timeframe = '5m'
            ORDER BY timestamp DESC
            LIMIT 3
        ''', (symbol_full,))
        
        klines = cursor.fetchall()
        
        if len(klines) < 3:
            return False
        
        # æ£€æŸ¥æ¯æ ¹Kçº¿
        for open_price, high, low, close in klines:
            if open_price == 0:
                return False
            
            # éœ‡è¡å¹…åº¦ = (æœ€é«˜-æœ€ä½) / å¼€ç›˜ * 100
            oscillation = ((high - low) / open_price) * 100 if open_price > 0 else 999
            
            # æ¶¨è·Œå¹… = (æ”¶ç›˜-å¼€ç›˜) / å¼€ç›˜ * 100ï¼ˆä¿ç•™æ­£è´Ÿï¼Œä¸å–ç»å¯¹å€¼ï¼‰
            change = ((close - open_price) / open_price) * 100
            
            # ä»»ä½•ä¸€æ ¹ä¸æ»¡è¶³æ¡ä»¶å°±è¿”å›False
            # æ¶¨è·Œå¹…å¿…é¡»åœ¨ 0% åˆ° +0.25% ä¹‹é—´ï¼Œéœ‡è¡å¹…åº¦ <= 0.50%
            if change < 0 or change > 0.25 or oscillation > 0.5:
                return False
        
        return True
    finally:
        conn.close()

def deactivate_missing_signals(active_signal_keys):
    """å°†ä¸å†æ»¡è¶³æ¡ä»¶çš„ä¿¡å·æ ‡è®°ä¸ºå¤±æ•ˆ"""
    from datetime import datetime
    import pytz
    import sqlite3
    
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(beijing_tz)
    
    conn = sqlite3.connect('databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # è·å–æ‰€æœ‰å½“å‰æ´»è·ƒçš„ä¿¡å·
        cursor.execute('SELECT signal_key FROM trading_signal_history WHERE is_active = 1')
        all_active = [row[0] for row in cursor.fetchall()]
        
        # æ‰¾å‡ºä¸åœ¨å½“å‰ä¿¡å·åˆ—è¡¨ä¸­çš„ä¿¡å·ï¼ˆå³æ¡ä»¶ä¸å†æ»¡è¶³çš„ä¿¡å·ï¼‰
        signals_to_deactivate = [sig for sig in all_active if sig not in active_signal_keys]
        
        # æ ‡è®°è¿™äº›ä¿¡å·ä¸ºå¤±æ•ˆ
        for signal_key in signals_to_deactivate:
            cursor.execute('''
                UPDATE trading_signal_history 
                SET is_active = 0, last_updated_at = ?
                WHERE signal_key = ? AND is_active = 1
            ''', (now.strftime('%Y-%m-%d %H:%M:%S'), signal_key))
        
        conn.commit()
        return len(signals_to_deactivate)
    finally:
        conn.close()

@app.route('/api/trading-signals/analyze')
def api_trading_signals_analyze():
    """åˆ†æäº¤æ˜“ä¿¡å· - åšå¤šä¹°ç‚¹1/2/3"""
    try:
        from datetime import datetime, timedelta
        import pytz
        from opening_logic import get_opening_suggestion
        
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # 0. è·å–å¼€ä»“é€»è¾‘å»ºè®®ï¼ˆç”¨äºä¹°ç‚¹3ä»“ä½è®¡ç®—ï¼‰
        try:
            opening_logic_data = get_opening_suggestion()
            opening_position = opening_logic_data.get('position_info', {})
            opening_can_long = opening_logic_data.get('can_long', False)
            opening_position_percent = opening_position.get('position_percent', 0)
        except Exception as e:
            print(f"è·å–å¼€ä»“é€»è¾‘å¤±è´¥: {e}")
            opening_can_long = False
            opening_position_percent = 0
        
        # 1. è·å–æ”¯æ’‘å‹åŠ›çº¿æ•°æ®
        cursor.execute('''
            SELECT symbol, current_price, support_line_1, support_line_2, resistance_line_1,
                   distance_to_support_1, distance_to_support_2, distance_to_resistance_1,
                   position_s2_r1, record_time
            FROM support_resistance_levels
            WHERE id IN (
                SELECT MAX(id) 
                FROM support_resistance_levels 
                GROUP BY symbol
            )
        ''')
        sr_data = {row['symbol']: dict(row) for row in cursor.fetchall()}
        
        # 2. è·å–ä»·æ ¼çªç ´æ•°æ®(åˆ›æ–°ä½ç»Ÿè®¡ - æœ€è¿‘7å¤©)
        seven_days_ago = now - timedelta(days=7)
        cursor.execute('''
            SELECT symbol, COUNT(*) as count
            FROM price_breakthrough_events
            WHERE event_type = 'new_low'
              AND event_time >= ?
            GROUP BY symbol
        ''', (seven_days_ago.strftime('%Y-%m-%d %H:%M:%S'),))
        breakthrough_data = {row['symbol']: row['count'] for row in cursor.fetchall()}
        
        # 3. è·å–æœ€æ–°å¿«ç…§æ•°æ®(æ€¥æ¶¨æ€¥è·Œã€è®¡æ¬¡å¾—åˆ†)
        cursor.execute('''
            SELECT c.symbol, c.rush_up, c.rush_down, c.current_price,
                   s.count_score_display, s.count_score_type
            FROM crypto_coin_data c
            JOIN crypto_snapshots s ON c.snapshot_id = s.id
            WHERE c.id IN (
                SELECT MAX(id) 
                FROM crypto_coin_data 
                GROUP BY symbol
            )
        ''')
        coin_data = {row['symbol']: dict(row) for row in cursor.fetchall()}
        
        # 3.5 è·å–Kçº¿æŒ‡æ ‡æ•°æ® (5åˆ†é’ŸRSIã€SARä½ç½®ã€SARè±¡é™)
        cursor.execute('''
            SELECT symbol, rsi_14, sar_position, sar_quadrant, sar_count_label
            FROM okex_technical_indicators
            WHERE timeframe = '5m'
              AND (symbol, record_time) IN (
                SELECT symbol, MAX(record_time)
                FROM okex_technical_indicators
                WHERE timeframe = '5m'
                GROUP BY symbol
            )
        ''')
        kline_indicators = {}
        for row in cursor.fetchall():
            # ç»Ÿä¸€æ ¼å¼ï¼šFIL-USDT-SWAP -> FIL
            symbol_short = row['symbol'].replace('-USDT-SWAP', '')
            kline_indicators[symbol_short] = {
                'rsi_5m': row['rsi_14'],
                'sar_position': row['sar_position'],  # 'bullish' æˆ– 'bearish'
                'sar_quadrant': row['sar_quadrant'],  # 1-4è±¡é™
                'sar_count_label': row['sar_count_label']  # ä¾‹å¦‚ "å¤šå¤´12"
            }
        
        # 4. è·å–ä½ç½®ç³»ç»Ÿæ•°æ®ï¼ˆBTC/ETHçš„4h/12h/24h/48hå‘¨æœŸä½ç½®ï¼‰
        cursor.execute('''
            SELECT symbol, position_4h, position_12h, position_24h, position_48h
            FROM position_system
            WHERE symbol IN ('BTC', 'ETH')
              AND id IN (
                SELECT MAX(id) 
                FROM position_system 
                GROUP BY symbol
            )
        ''')
        position_data = {}
        for row in cursor.fetchall():
            symbol = row['symbol']
            positions = [
                row['position_4h'], row['position_12h'], 
                row['position_24h'], row['position_48h']
            ]
            # ç»Ÿè®¡æœ‰å¤šå°‘ä¸ªå‘¨æœŸä½ç½® < 10%
            low_position_count = sum(1 for p in positions if p is not None and p < 10)
            position_data[symbol] = low_position_count
        
        conn.close()
        
        # æ£€æŸ¥BTCå’ŒETHæ˜¯å¦è‡³å°‘æœ‰5ä¸ªå‘¨æœŸ < 10%
        # ç”±äºåªæœ‰4ä¸ªå‘¨æœŸï¼Œæˆ‘ä»¬æ”¹ä¸ºæ£€æŸ¥BTCå’ŒETHåŠ èµ·æ¥æ˜¯å¦æœ‰5ä¸ªä»¥ä¸Š
        btc_low = position_data.get('BTC', 0)
        eth_low = position_data.get('ETH', 0)
        total_low_positions = btc_low + eth_low
        condition6_pass = total_low_positions >= 5
        
        # 5. ç»Ÿè®¡æ¥è¿‘æ”¯æ’‘çº¿çš„å¸ç§æ•°é‡ï¼ˆç”¨äºä¹°ç‚¹3æ¡ä»¶6ï¼‰
        # æ¥è¿‘æ”¯æ’‘1ï¼šè·ç¦»æ”¯æ’‘çº¿1 <= æŸä¸ªé˜ˆå€¼ï¼ˆä¾‹å¦‚10%ï¼‰
        # æ¥è¿‘æ”¯æ’‘2ï¼šè·ç¦»æ”¯æ’‘çº¿2 <= æŸä¸ªé˜ˆå€¼ï¼ˆä¾‹å¦‚10%ï¼‰
        near_support_1_count = 0
        near_support_2_count = 0
        
        for symbol, sr in sr_data.items():
            dist_s1 = sr.get('distance_to_support_1')
            dist_s2 = sr.get('distance_to_support_2')
            
            # ç»Ÿè®¡æ¥è¿‘æ”¯æ’‘1çš„å¸ç§ï¼ˆè·ç¦» <= 10%ï¼‰
            if dist_s1 is not None and dist_s1 <= 10:
                near_support_1_count += 1
            
            # ç»Ÿè®¡æ¥è¿‘æ”¯æ’‘2çš„å¸ç§ï¼ˆè·ç¦» <= 10%ï¼‰
            if dist_s2 is not None and dist_s2 <= 10:
                near_support_2_count += 1
        
        # ä¹°ç‚¹3æ¡ä»¶6ï¼šæ¥è¿‘æ”¯æ’‘1çš„å¸ç§æ•° >= 8 æˆ– æ¥è¿‘æ”¯æ’‘2çš„å¸ç§æ•° >= 8
        condition6_support_system = near_support_1_count >= 8 or near_support_2_count >= 8
        
        # 6. åˆ†æä¿¡å·
        signals = []
        buy_point_1_count = 0
        buy_point_2_count = 0
        buy_point_3_count = 0
        
        for symbol, sr in sr_data.items():
            coin_name = symbol.replace('USDT', '')
            coin = coin_data.get(coin_name, {})
            kline = kline_indicators.get(coin_name, {})
            
            # è·å–åˆ›æ–°ä½æ¬¡æ•°
            new_lows = breakthrough_data.get(coin_name, 0)
            
            # è·å–è®¡æ¬¡å¾—åˆ†
            score_display = coin.get('count_score_display', '---')
            score_type = coin.get('count_score_type', 'ä¸­æ€§')
            
            # è·å–æ€¥æ¶¨æ€¥è·Œ
            rush_up = coin.get('rush_up', 0) or 0
            rush_down = coin.get('rush_down', 0) or 0
            rush_diff = rush_up - rush_down
            
            # è·å–Kçº¿æŒ‡æ ‡æ•°æ®
            rsi_5m = kline.get('rsi_5m')
            sar_position = kline.get('sar_position')  # 'bullish' / 'bearish'
            sar_quadrant = kline.get('sar_quadrant')  # 1-4
            sar_count_label = kline.get('sar_count_label', '')
            
            # è§£æç©ºå¤´/å¤šå¤´æ•°é‡ï¼ˆä» "ç©ºå¤´20" æˆ– "å¤šå¤´12" ä¸­æå–æ•°å­—ï¼‰
            sar_count = 0
            if sar_count_label:
                import re
                match = re.search(r'(\d+)', sar_count_label)
                if match:
                    sar_count = int(match.group(1))
            
            # é€šç”¨æ¡ä»¶åˆ¤æ–­
            condition1 = new_lows < 3  # åˆ›æ–°ä½ < 3 ã€ä¹°ç‚¹1/2/3é€‚ç”¨ã€‘
            condition2 = 'â˜…' in score_display or 'â­' in score_display  # è®¡æ¬¡å¾—åˆ†æ˜¯æ˜Ÿæ˜Ÿ ã€ä¹°ç‚¹1/2é€‚ç”¨ã€‘
            condition3 = rush_diff > 0  # æ€¥æ¶¨ - æ€¥è·Œ > 0 ã€ä¹°ç‚¹1/2é€‚ç”¨ã€‘
            condition4 = rsi_5m is not None and rsi_5m < 20  # 5åˆ†é’ŸRSI < 20 ã€ä¹°ç‚¹1é€‚ç”¨ã€‘ï¼ˆä¿®æ”¹ä¸ºä½¿ç”¨5åˆ†é’ŸRSIï¼‰
            condition5 = rush_diff > -15  # æ€¥æ¶¨ - æ€¥è·Œ > -15 ã€ä¹°ç‚¹3é€‚ç”¨ã€‘
            condition6 = condition6_pass  # BTC/ETHè‡³å°‘5ä¸ªå‘¨æœŸ < 10% ã€ä¹°ç‚¹3é€‚ç”¨ã€‘
            
            # æ–°å¢æ¡ä»¶ï¼ˆåŸºäºKçº¿æŒ‡æ ‡ï¼‰
            condition_sar_bearish = sar_position == 'bearish'  # ç©ºå¤´è¶‹åŠ¿
            condition_sar_count = sar_count > 20  # ç©ºå¤´æ•°é‡>20
            condition_sar_quadrant3 = sar_quadrant == 3  # SARç¬¬ä¸‰è±¡é™
            condition_rsi_low = rsi_5m is not None and rsi_5m < 30  # 5åˆ†é’ŸRSI<30 ã€ä¹°ç‚¹2é€‚ç”¨ã€‘
            
            # ä¹°ç‚¹3ä¸“ç”¨æ¡ä»¶æ£€æŸ¥
            condition_no_new_low_5m = check_no_new_low_5min(coin_name)  # åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½
            rsi_1h = get_1h_rsi(coin_name)  # è·å–1å°æ—¶RSI
            condition_rsi_1h_low = rsi_1h is not None and rsi_1h < 15  # 1å°æ—¶RSI<15
            condition_oscillation_3 = check_consecutive_oscillation_5min(coin_name)  # è¿ç»­3ä¸ªéœ‡è¡
            
            # è·å–è·ç¦»æ”¯æ’‘çº¿1çš„è·ç¦»ï¼ˆç”¨äºä¹°ç‚¹1ï¼‰
            distance = sr.get('distance_to_support_1')
            
            # åˆ¤æ–­å„ä¸ªä¹°ç‚¹
            buy_point_1 = False
            buy_point_2 = False
            buy_point_3 = False
            
            # ä¹°ç‚¹1: è¾¾åˆ°æ”¯æ’‘çº¿1 (è·ç¦» < 5%) + æ¡ä»¶1234
            if (distance is not None and distance <= 5 and 
                condition1 and condition2 and condition3 and condition4):
                buy_point_1 = True
                buy_point_1_count += 1
            
            # ä¹°ç‚¹2: å›è°ƒä¹°å…¥
            # æ¡ä»¶ï¼šæ¡ä»¶123 + ç©ºå¤´>20 + 5åˆ†é’ŸSARç¬¬ä¸‰è±¡é™ + 5åˆ†é’ŸRSI<30
            if (condition1 and condition2 and condition3 and 
                condition_sar_count and condition_sar_quadrant3 and condition_rsi_low):
                buy_point_2 = True
                buy_point_2_count += 1
            
            # ä¹°ç‚¹3: ç©ºè½¬å¤šä¹°å…¥ï¼ˆé‡æ–°å®šä¹‰æ¡ä»¶ï¼‰
            # 6ä¸ªå¿…é¡»æ¡ä»¶ï¼š
            # 1. åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½
            # 2. 1å°æ—¶RSI < 15
            # 3. 5åˆ†é’Ÿå‘¨æœŸè¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œ<0.25%
            # 4. SARç©ºå¤´æ•°é‡ > 20
            # 5. 5åˆ†é’ŸSARåœ¨ç¬¬ä¸‰è±¡é™
            # 6. æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿï¼šæ¥è¿‘æ”¯æ’‘1çš„å¸ç§æ•° >= 8 æˆ– æ¥è¿‘æ”¯æ’‘2çš„å¸ç§æ•° >= 8
            if (condition_no_new_low_5m and 
                condition_rsi_1h_low and 
                condition_oscillation_3 and 
                condition_sar_count and 
                condition_sar_quadrant3 and 
                condition6_support_system):  # ä½¿ç”¨å…¨å±€æ¡ä»¶
                buy_point_3 = True
                buy_point_3_count += 1
            
            # åªä¿ç•™æœ‰ä¿¡å·çš„å¸ç§
            if buy_point_1 or buy_point_2 or buy_point_3:
                # è¯¦ç»†çš„æ¡ä»¶åˆ¤æ–­ç»“æœ - ç”¨äºé€æ˜åŒ–æ˜¾ç¤º
                detailed_conditions = {
                    'buy_point_1_conditions': {
                        'distance_to_support': {'value': distance, 'threshold': 'â‰¤ 5%', 'pass': distance is not None and distance <= 5, 'desc': 'è·ç¦»æ”¯æ’‘çº¿1'},
                        'condition1': {'value': new_lows, 'threshold': '< 3', 'pass': condition1, 'desc': '7å¤©åˆ›æ–°ä½æ¬¡æ•°'},
                        'condition2': {'value': score_display, 'threshold': 'åŒ…å«â˜…æˆ–â­', 'pass': condition2, 'desc': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤º'},
                        'condition3': {'value': round(rush_diff, 2), 'threshold': '> 0', 'pass': condition3, 'desc': 'æ€¥æ¶¨-æ€¥è·Œ'},
                        'condition4': {'value': round(rsi_5m, 2) if rsi_5m else None, 'threshold': '< 20', 'pass': condition4, 'desc': '5åˆ†é’ŸRSI'}
                    },
                    'buy_point_2_conditions': {
                        'condition1': {'value': new_lows, 'threshold': '< 3', 'pass': condition1, 'desc': '7å¤©åˆ›æ–°ä½æ¬¡æ•°'},
                        'condition2': {'value': score_display, 'threshold': 'åŒ…å«â˜…æˆ–â­', 'pass': condition2, 'desc': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤º'},
                        'condition3': {'value': round(rush_diff, 2), 'threshold': '> 0', 'pass': condition3, 'desc': 'æ€¥æ¶¨-æ€¥è·Œ'},
                        'sar_count': {'value': sar_count, 'threshold': '> 20', 'pass': condition_sar_count, 'desc': 'SARç©ºå¤´æ•°é‡'},
                        'sar_quadrant': {'value': sar_quadrant, 'threshold': '= 3', 'pass': condition_sar_quadrant3, 'desc': 'SARç¬¬ä¸‰è±¡é™'},
                        'rsi_5m': {'value': round(rsi_5m, 2) if rsi_5m else None, 'threshold': '< 30', 'pass': condition_rsi_low, 'desc': '5åˆ†é’ŸRSI'}
                    },
                    'buy_point_3_conditions': {
                        'no_new_low_5m': {'value': 'æ˜¯' if condition_no_new_low_5m else 'å¦', 'threshold': 'æ˜¯', 'pass': condition_no_new_low_5m, 'desc': 'åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½'},
                        'rsi_1h': {'value': round(rsi_1h, 2) if rsi_1h else None, 'threshold': '< 15', 'pass': condition_rsi_1h_low, 'desc': '1å°æ—¶RSI'},
                        'oscillation_3': {'value': 'æ˜¯' if condition_oscillation_3 else 'å¦', 'threshold': 'æ˜¯', 'pass': condition_oscillation_3, 'desc': 'è¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œ<0.25%'},
                        'sar_count': {'value': sar_count, 'threshold': '> 20', 'pass': condition_sar_count, 'desc': 'SARç©ºå¤´æ•°é‡'},
                        'sar_quadrant': {'value': sar_quadrant, 'threshold': '= 3', 'pass': condition_sar_quadrant3, 'desc': '5åˆ†é’ŸSARç¬¬ä¸‰è±¡é™'},
                        'support_system': {'value': f'æ¥è¿‘æ”¯æ’‘1: {near_support_1_count}ä¸ª, æ¥è¿‘æ”¯æ’‘2: {near_support_2_count}ä¸ª', 'threshold': 'æ¥è¿‘æ”¯æ’‘1 â‰¥ 8ä¸ª æˆ– æ¥è¿‘æ”¯æ’‘2 â‰¥ 8ä¸ª', 'pass': condition6_support_system, 'desc': 'æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ'}
                    }
                }
                
                # ç¡®å®šä¹°ç‚¹ç±»å‹å’Œå»ºè®®ä»“ä½
                buy_point_type = None
                suggested_position = None
                position_calculation_note = None
                buy_times = None  # åˆ†æ‰¹ä¹°å…¥æ¬¡æ•°
                
                if buy_point_1:
                    buy_point_type = 'buy_point_1'
                    suggested_position = '30%'
                    buy_times = 3  # ä¹°ç‚¹1åˆ†3æ¬¡ä¹°å…¥
                    position_calculation_note = 'ä¹°ç‚¹1å›ºå®šä»“ä½ï¼Œåˆ†3æ¬¡ä¹°å…¥'
                    
                elif buy_point_3:
                    buy_point_type = 'buy_point_3'
                    buy_times = 2  # ä¹°ç‚¹3åˆ†2æ¬¡ä¹°å…¥
                    # ä¹°ç‚¹3ç‰¹æ®Šä»“ä½é€»è¾‘
                    if opening_can_long and opening_position_percent > 0:
                        # æƒ…å†µ2ï¼šå¼€ä»“é€»è¾‘å…è®¸å¼€ä»“
                        # ä¹°ç‚¹3ä»“ä½ = å¼€ä»“é€»è¾‘å»ºè®® + 20%ï¼Œæœ€é«˜70%
                        bp3_position = min(opening_position_percent + 20, 70)
                        suggested_position = f'{int(bp3_position)}%'
                        position_calculation_note = f'å¼€ä»“é€»è¾‘{int(opening_position_percent)}% + ä¹°ç‚¹3åŠ æˆ20% = {int(bp3_position)}% (ä¸Šé™70%)ï¼Œåˆ†2æ¬¡ä¹°å…¥'
                    else:
                        # æƒ…å†µ1ï¼šå¼€ä»“é€»è¾‘ä¸å…è®¸å¼€ä»“
                        # ä¹°ç‚¹3å¯é¢å¤–å¼€20%
                        suggested_position = '20%'
                        position_calculation_note = 'å¼€ä»“é€»è¾‘ä¸å…è®¸ï¼Œä¹°ç‚¹3å¯é¢å¤–å¼€20%ï¼Œåˆ†2æ¬¡ä¹°å…¥'
                        
                elif buy_point_2:
                    buy_point_type = 'buy_point_2'
                    suggested_position = '20%'
                    buy_times = 2  # ä¹°ç‚¹2åˆ†2æ¬¡ä¹°å…¥
                    position_calculation_note = 'ä¹°ç‚¹2å›ºå®šä»“ä½ï¼Œåˆ†2æ¬¡ä¹°å…¥'
                
                # è·Ÿè¸ªä¿¡å·å†å²ï¼Œè·å–é¦–æ¬¡è§¦å‘æ—¶é—´å’Œé¦–æ¬¡å¼€ä»“å»ºè®®
                tracking_info = track_trading_signal(coin_name, buy_point_type, suggested_position)
                
                signals.append({
                    'symbol': coin_name,
                    'current_price': sr.get('current_price', 0),
                    'support_line_1': sr.get('support_line_1'),
                    'distance_to_support_1': distance,
                    'buy_point_1': buy_point_1,
                    'buy_point_2': buy_point_2,
                    'buy_point_3': buy_point_3,
                    'suggested_position': suggested_position,
                    'buy_times': buy_times,  # æ–°å¢ï¼šåˆ†æ‰¹ä¹°å…¥æ¬¡æ•°
                    'position_calculation_note': position_calculation_note,  # æ–°å¢ï¼šä»“ä½è®¡ç®—è¯´æ˜
                    'opening_logic_position': f'{int(opening_position_percent)}%' if opening_can_long else 'ä¸å…è®¸',  # æ–°å¢ï¼šå¼€ä»“é€»è¾‘å»ºè®®
                    'first_triggered_at': tracking_info['first_triggered_at'],  # æ–°å¢ï¼šé¦–æ¬¡è§¦å‘æ—¶é—´
                    'initial_position': tracking_info['initial_position'],  # æ–°å¢ï¼šé¦–æ¬¡å¼€ä»“å»ºè®®(æ€»ä»“ä½çš„30%)
                    'conditions': {
                        'condition1_pass': condition1,
                        'condition2_pass': condition2,
                        'condition3_pass': condition3,
                        'new_lows': new_lows,
                        'score_display': score_display,
                        'rush_diff': round(rush_diff, 2)
                    },
                    'kline_indicators': {
                        'rsi_5m': round(rsi_5m, 2) if rsi_5m else None,
                        'sar_position': sar_position,
                        'sar_quadrant': sar_quadrant,
                        'sar_count': sar_count,
                        'sar_count_label': sar_count_label
                    },
                    'detailed_conditions': detailed_conditions  # æ–°å¢ï¼šè¯¦ç»†æ¡ä»¶åˆ¤æ–­ç»“æœ
                })
        
        # æŒ‰ä¹°ç‚¹1 > ä¹°ç‚¹3 > ä¹°ç‚¹2 ä¼˜å…ˆçº§æ’åºï¼ŒåŒä¼˜å…ˆçº§æŒ‰è·æ”¯æ’‘çº¿è·ç¦»æ’åº
        def sort_key(x):
            priority = 0
            if x['buy_point_1']:
                priority = 3
            elif x['buy_point_3']:
                priority = 2
            elif x['buy_point_2']:
                priority = 1
            distance = x['distance_to_support_1'] if x['distance_to_support_1'] is not None else 999
            return (-priority, distance)
        
        signals.sort(key=sort_key)
        
        # æ”¶é›†å½“å‰æ‰€æœ‰æ´»è·ƒä¿¡å·çš„signal_key
        active_signal_keys = []
        for signal in signals:
            coin_name = signal['symbol']
            if signal['buy_point_1']:
                active_signal_keys.append(f"{coin_name}_buy_point_1")
            elif signal['buy_point_3']:
                active_signal_keys.append(f"{coin_name}_buy_point_3")
            elif signal['buy_point_2']:
                active_signal_keys.append(f"{coin_name}_buy_point_2")
        
        # å°†ä¸å†æ»¡è¶³æ¡ä»¶çš„ä¿¡å·æ ‡è®°ä¸ºå¤±æ•ˆ
        deactivated_count = deactivate_missing_signals(active_signal_keys)
        
        # ä¹°ç‚¹è§„åˆ™è¯´æ˜ - é€æ˜åŒ–å±•ç¤º
        buy_point_rules = {
            'buy_point_1': {
                'name': 'ä¹°ç‚¹1 - æ”¯æ’‘çº¿ä¹°å…¥',
                'suggested_position': '30%',
                'buy_times': 3,  # åˆ†3æ¬¡ä¹°å…¥
                'conditions': [
                    {'id': 'è·ç¦»æ”¯æ’‘çº¿', 'rule': 'è·ç¦»æ”¯æ’‘çº¿1 â‰¤ 5%', 'priority': 'high'},
                    {'id': 'åˆ›æ–°ä½', 'rule': '7å¤©åˆ›æ–°ä½æ¬¡æ•° < 3', 'priority': 'high'},
                    {'id': 'è®¡æ¬¡å¾—åˆ†', 'rule': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤ºåŒ…å«â˜…æˆ–â­', 'priority': 'medium'},
                    {'id': 'æ€¥æ¶¨æ€¥è·Œ', 'rule': 'æ€¥æ¶¨ - æ€¥è·Œ > 0', 'priority': 'medium'},
                    {'id': 'RSI 5m', 'rule': '5åˆ†é’ŸRSI < 20', 'priority': 'high'}
                ],
                'description': 'ä»·æ ¼æ¥è¿‘æ”¯æ’‘çº¿æ—¶çš„ä¹°å…¥æœºä¼šï¼Œé£é™©è¾ƒä½ï¼Œå»ºè®®åˆ†3æ¬¡ä¹°å…¥'
            },
            'buy_point_2': {
                'name': 'ä¹°ç‚¹2 - å›è°ƒä¹°å…¥',
                'suggested_position': '20%',
                'buy_times': 2,  # åˆ†2æ¬¡ä¹°å…¥
                'conditions': [
                    {'id': 'åˆ›æ–°ä½', 'rule': '7å¤©åˆ›æ–°ä½æ¬¡æ•° < 3', 'priority': 'high'},
                    {'id': 'è®¡æ¬¡å¾—åˆ†', 'rule': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤ºåŒ…å«â˜…æˆ–â­', 'priority': 'medium'},
                    {'id': 'æ€¥æ¶¨æ€¥è·Œ', 'rule': 'æ€¥æ¶¨ - æ€¥è·Œ > 0', 'priority': 'medium'},
                    {'id': 'SARç©ºå¤´æ•°', 'rule': 'SARç©ºå¤´æ•°é‡ > 20', 'priority': 'high'},
                    {'id': 'SARè±¡é™', 'rule': 'SARåœ¨ç¬¬ä¸‰è±¡é™', 'priority': 'high'},
                    {'id': 'RSI 5m', 'rule': '5åˆ†é’ŸRSI < 30', 'priority': 'high'}
                ],
                'description': 'å¸‚åœºå›è°ƒæ—¶çš„ä¹°å…¥æœºä¼šï¼Œéœ€è¦æŠ€æœ¯æŒ‡æ ‡ç¡®è®¤ï¼Œå»ºè®®åˆ†2æ¬¡ä¹°å…¥'
            },
            'buy_point_3': {
                'name': 'ä¹°ç‚¹3 - ç©ºè½¬å¤šä¹°å…¥',
                'suggested_position': 'æœ€å¤š20% (å¦‚æ— å¼€ä»“é€»è¾‘å»ºè®®)',
                'buy_times': 2,  # åˆ†2æ¬¡ä¹°å…¥
                'conditions': [
                    {'id': '5åˆ†é’Ÿä¸åˆ›æ–°ä½', 'rule': 'åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½', 'priority': 'high'},
                    {'id': '1h RSI', 'rule': '1å°æ—¶RSI < 15', 'priority': 'high'},
                    {'id': 'è¿ç»­éœ‡è¡', 'rule': '5åˆ†é’Ÿå‘¨æœŸè¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œ<0.25%', 'priority': 'high'},
                    {'id': 'SARç©ºå¤´æ•°', 'rule': 'SARç©ºå¤´æŒç»­æ•°é‡ > 20', 'priority': 'high'},
                    {'id': 'SARè±¡é™', 'rule': '5åˆ†é’ŸSARåœ¨ç¬¬ä¸‰è±¡é™', 'priority': 'high'},
                    {'id': 'æ”¯æ’‘å‹åŠ›çº¿', 'rule': 'æ¥è¿‘æ”¯æ’‘1çš„å¸ç§æ•° â‰¥ 8ä¸ª æˆ– æ¥è¿‘æ”¯æ’‘2çš„å¸ç§æ•° â‰¥ 8ä¸ª', 'priority': 'high'}
                ],
                'description': 'æåº¦è¶…å–åçš„ç©ºè½¬å¤šä¹°å…¥æœºä¼šï¼Œä¸¥æ ¼æ¡ä»¶ç­›é€‰ï¼ˆéœ€å¸‚åœºæ•´ä½“æ¥è¿‘æ”¯æ’‘çº¿ï¼‰ï¼Œå»ºè®®åˆ†2æ¬¡ä¹°å…¥'
            }
        }
        
        return jsonify({
            'success': True,
            'data': {
                'signals': signals,
                'buy_point_1_count': buy_point_1_count,
                'buy_point_2_count': buy_point_2_count,
                'buy_point_3_count': buy_point_3_count,
                'total_coins': len(sr_data),
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'buy_point_rules': buy_point_rules,  # æ–°å¢ï¼šä¹°ç‚¹è§„åˆ™è¯´æ˜
                'opening_logic_info': {  # æ–°å¢ï¼šå¼€ä»“é€»è¾‘ä¿¡æ¯
                    'can_long': opening_can_long,
                    'position_percent': opening_position_percent,
                    'suggestion': f'{int(opening_position_percent)}%' if opening_can_long else 'ä¸å…è®¸å¼€ä»“'
                },
                'notes': {
                    'buy_point_1': 'âœ… æ”¯æ’‘çº¿ä¹°å…¥ (è·ç¦»<5%) + åˆ›æ–°ä½<3 + è®¡æ¬¡å¾—åˆ†â­/â˜… + æ€¥æ¶¨>æ€¥è·Œ + 5åˆ†é’ŸRSI<20 - å·²æ›´æ–°ä½¿ç”¨5åˆ†é’ŸRSI',
                    'buy_point_2': 'âœ… å›è°ƒä¹°å…¥ (æ¡ä»¶1-3 + ç©ºå¤´>20 + 5åˆ†é’ŸSARç¬¬ä¸‰è±¡é™ + 5åˆ†é’ŸRSI<30) - å·²é›†æˆKçº¿æŒ‡æ ‡',
                    'buy_point_3': 'âœ… ç©ºè½¬å¤šä¹°å…¥ (5ä¸ª5åˆ†é’Ÿä¸åˆ›æ–°ä½ + 1h RSI<15 + è¿ç»­3ä¸ªéœ‡è¡ + SARç©ºå¤´>20 + SARç¬¬3è±¡é™) - ä¸¥æ ¼æ¡ä»¶',
                    'buy_point_3_position': 'ğŸ“Š ä¹°ç‚¹3ä»“ä½è§„åˆ™ï¼šè‹¥å¼€ä»“é€»è¾‘å…è®¸ï¼Œåˆ™ä¸º å¼€ä»“é€»è¾‘ä»“ä½+20% (ä¸Šé™70%)ï¼›è‹¥å¼€ä»“é€»è¾‘ä¸å…è®¸ï¼Œåˆ™é¢å¤–å¼€20%',
                    'data_integration': 'âœ… å·²é›†æˆkline-indicatorsæ•°æ®ï¼š5åˆ†é’ŸRSIã€SARä½ç½®ã€SARè±¡é™ã€SARè®¡æ•°',
                    'data_limitation': 'âš ï¸ ä»éœ€è¡¥å……ï¼šè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½ã€è¿ç»­3ä¸ªéœ‡è¡æ¡ä»¶'
                }
            }
        })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/trading-signals/buy-points')
def api_trading_signals_buy_points():
    """è·å–å½“å‰æ‰€æœ‰ä¹°ç‚¹ä¿¡å·ï¼ˆç®€åŒ–ç‰ˆAPIï¼‰"""
    try:
        import sqlite3
        from datetime import datetime
        import pytz
        
        # è°ƒç”¨ç°æœ‰çš„åˆ†æå‡½æ•°
        response = api_trading_signals_analyze()
        
        # å¦‚æœè¿”å›çš„æ˜¯Responseå¯¹è±¡ï¼Œè·å–å…¶JSONæ•°æ®
        if hasattr(response, 'get_json'):
            data = response.get_json()
        else:
            import json
            data = json.loads(response[0])
        
        if not data.get('success'):
            return jsonify({
                'success': False,
                'message': 'è·å–ä¹°ç‚¹æ•°æ®å¤±è´¥',
                'error': data.get('error', 'Unknown error')
            }), 500
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # æå–ä¹°ç‚¹ä¿¡å·
        signals_data = data.get('data', {})
        buy_signals = signals_data.get('signals', [])
        
        # æŒ‰ä¹°ç‚¹ç±»å‹åˆ†ç»„
        buy_point_1 = [s for s in buy_signals if s.get('buy_point') == 1]
        buy_point_2 = [s for s in buy_signals if s.get('buy_point') == 2]
        buy_point_3 = [s for s in buy_signals if s.get('buy_point') == 3]
        
        # ç®€åŒ–ä¿¡å·æ•°æ®
        def simplify_signal(signal):
            return {
                'symbol': signal.get('symbol'),
                'buy_point': signal.get('buy_point'),
                'current_price': signal.get('current_price'),
                'suggested_position': signal.get('suggested_position'),
                'buy_times': signal.get('buy_times'),
                'distance_to_support': signal.get('distance_to_support_1'),
                'conditions_met': signal.get('conditions_met'),
                'score_display': signal.get('score_display'),
                'sar_position': signal.get('sar_position'),
                'rsi_5m': signal.get('rsi_5m'),
                'rsi_1h': signal.get('rsi_1h'),
                'recommended': signal.get('recommended', False)
            }
        
        result = {
            'success': True,
            'timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'total_signals': len(buy_signals),
                'buy_point_1_count': len(buy_point_1),
                'buy_point_2_count': len(buy_point_2),
                'buy_point_3_count': len(buy_point_3)
            },
            'buy_points': {
                'buy_point_1': [simplify_signal(s) for s in buy_point_1],
                'buy_point_2': [simplify_signal(s) for s in buy_point_2],
                'buy_point_3': [simplify_signal(s) for s in buy_point_3]
            },
            'all_signals': [simplify_signal(s) for s in buy_signals],
            'rules': signals_data.get('buy_point_rules', {})
        }
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        print(f"è·å–ä¹°ç‚¹ä¿¡å·å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': 'è·å–ä¹°ç‚¹ä¿¡å·å¤±è´¥',
            'error': str(e)
        }), 500

@app.route('/api/trading-signals/history')
def api_trading_signals_history():
    """è·å–å†å²ä¿¡å·ï¼ˆå·²å¤±æ•ˆçš„ä¿¡å·ï¼‰"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # è·å–æœ€è¿‘7å¤©å†…å¤±æ•ˆçš„ä¿¡å·
        seven_days_ago = now - timedelta(days=7)
        
        cursor.execute('''
            SELECT signal_key, symbol, buy_point_type, suggested_position,
                   first_triggered_at, last_updated_at
            FROM trading_signal_history
            WHERE is_active = 0
              AND last_updated_at >= ?
            ORDER BY last_updated_at DESC
            LIMIT 50
        ''', (seven_days_ago.strftime('%Y-%m-%d %H:%M:%S'),))
        
        history_signals = []
        for row in cursor.fetchall():
            # è®¡ç®—ä¿¡å·æŒç»­æ—¶é—´
            first_time = datetime.strptime(row['first_triggered_at'], '%Y-%m-%d %H:%M:%S')
            last_time = datetime.strptime(row['last_updated_at'], '%Y-%m-%d %H:%M:%S')
            duration_minutes = int((last_time - first_time).total_seconds() / 60)
            
            buy_point_name = {
                'buy_point_1': 'ä¹°ç‚¹1',
                'buy_point_2': 'ä¹°ç‚¹2',
                'buy_point_3': 'ä¹°ç‚¹3'
            }.get(row['buy_point_type'], 'æœªçŸ¥')
            
            history_signals.append({
                'symbol': row['symbol'],
                'buy_point_type': buy_point_name,
                'suggested_position': row['suggested_position'],
                'initial_position': str(int(float(row['suggested_position'].replace('%', '')) * 0.3)) + '%',
                'first_triggered_at': row['first_triggered_at'],
                'last_updated_at': row['last_updated_at'],
                'duration_minutes': duration_minutes
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'history_signals': history_signals,
                'total_count': len(history_signals),
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S')
            }
        })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/support-resistance/latest')
def api_support_resistance_latest():
    """è·å–æœ€æ–°çš„æ”¯æ’‘å‹åŠ›çº¿æ•°æ®"""
    try:
        conn = sqlite3.connect('support_resistance.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„å¿«ç…§æ•°æ®
        cursor.execute('''
            SELECT 
                snapshot_time,
                scenario_1_coins,
                scenario_2_coins,
                scenario_3_coins,
                scenario_4_coins
            FROM support_resistance_snapshots
            ORDER BY created_at DESC
            LIMIT 1
        ''')
        
        snapshot_row = cursor.fetchone()
        
        import json
        
        # è·å–å®æ—¶æ•°æ®çš„æœ€æ–°æ›´æ–°æ—¶é—´ï¼ˆä¸ä¾èµ–å¿«ç…§ï¼‰
        cursor.execute('''
            SELECT MAX(record_time) as latest_time
            FROM support_resistance_levels
        ''')
        latest_row = cursor.fetchone()
        update_time = latest_row['latest_time'] if latest_row and latest_row['latest_time'] else None
        
        if not update_time:
            conn.close()
            return jsonify({
                'success': False,
                'message': 'No data available'
            })
        
        # è·å–æ‰€æœ‰ç›‘æ§çš„å¸ç§ï¼ˆ27ä¸ªï¼‰
        MONITORED_SYMBOLS = [
            'BTC-USDT-SWAP', 'ETH-USDT-SWAP', 'XRP-USDT-SWAP', 'BNB-USDT-SWAP',
            'SOL-USDT-SWAP', 'LTC-USDT-SWAP', 'DOGE-USDT-SWAP', 'SUI-USDT-SWAP',
            'TRX-USDT-SWAP', 'TON-USDT-SWAP', 'ETC-USDT-SWAP', 'BCH-USDT-SWAP',
            'HBAR-USDT-SWAP', 'XLM-USDT-SWAP', 'FIL-USDT-SWAP', 'LINK-USDT-SWAP',
            'CRO-USDT-SWAP', 'DOT-USDT-SWAP', 'AAVE-USDT-SWAP', 'UNI-USDT-SWAP',
            'NEAR-USDT-SWAP', 'APT-USDT-SWAP', 'CFX-USDT-SWAP', 'CRV-USDT-SWAP',
            'STX-USDT-SWAP', 'LDO-USDT-SWAP', 'TAO-USDT-SWAP'
        ]
        
        # è·å–æ¯ä¸ªå¸ç§çš„æœ€æ–°ä»·æ ¼
        placeholders = ','.join(['?' for _ in MONITORED_SYMBOLS])
        cursor.execute(f'''
            SELECT symbol, close as current_price, timestamp
            FROM okex_kline_ohlc
            WHERE timeframe = '5m'
            AND symbol IN ({placeholders})
            AND (symbol, timestamp) IN (
                SELECT symbol, MAX(timestamp)
                FROM okex_kline_ohlc
                WHERE timeframe = '5m'
                AND symbol IN ({placeholders})
                GROUP BY symbol
            )
            ORDER BY symbol
        ''', MONITORED_SYMBOLS + MONITORED_SYMBOLS)
        
        price_rows = cursor.fetchall()
        price_dict = {row['symbol']: row['current_price'] for row in price_rows}
        
        # è§£æ4ç§æƒ…å†µçš„å¸ç§æ•°æ®ï¼Œæ„å»ºalertå­—å…¸
        alert_dict = {}
        if snapshot_row:  # åªæœ‰å½“å¿«ç…§å­˜åœ¨æ—¶æ‰è§£æ
            for scenario_num in range(1, 5):
                coins_json = snapshot_row[f'scenario_{scenario_num}_coins']
                if coins_json:
                    try:
                        coins = json.loads(coins_json)
                        for coin in coins:
                            symbol = coin['symbol']
                            if symbol not in alert_dict:
                                alert_dict[symbol] = {
                                    'support_1': 0,
                                    'support_2': 0,
                                    'resistance_1': 0,
                                    'resistance_2': 0,
                                    'position_s2_r1': None,
                                    'position_s1_r2': None,
                                    'position_s1_r2_upper': None,
                                    'position_s1_r1': None,
                                    'alert_scenario_1': False,
                                    'alert_scenario_2': False,
                                    'alert_scenario_3': False,
                                    'alert_scenario_4': False
                                }
                            
                            # ä»å½“å‰å¸ç§æ•°æ®ä¸­æ›´æ–°æ”¯æ’‘/å‹åŠ›çº¿å€¼ï¼ˆåˆå¹¶æ‰€æœ‰åœºæ™¯çš„æ•°æ®ï¼‰
                            if 'support_1' in coin and coin['support_1']:
                                alert_dict[symbol]['support_1'] = coin['support_1']
                            if 'support_2' in coin and coin['support_2']:
                                alert_dict[symbol]['support_2'] = coin['support_2']
                            if 'resistance_1' in coin and coin['resistance_1']:
                                alert_dict[symbol]['resistance_1'] = coin['resistance_1']
                            if 'resistance_2' in coin and coin['resistance_2']:
                                alert_dict[symbol]['resistance_2'] = coin['resistance_2']
                            
                            # è®¾ç½®å¯¹åº”æƒ…å†µçš„alertå’Œposition
                            if scenario_num == 1:
                                alert_dict[symbol]['alert_scenario_1'] = True
                                alert_dict[symbol]['position_s2_r1'] = coin.get('position', 0)
                            elif scenario_num == 2:
                                alert_dict[symbol]['alert_scenario_2'] = True
                                alert_dict[symbol]['position_s1_r2'] = coin.get('position', 0)
                            elif scenario_num == 3:
                                alert_dict[symbol]['alert_scenario_3'] = True
                                alert_dict[symbol]['position_s1_r2_upper'] = coin.get('position', 0)
                            elif scenario_num == 4:
                                alert_dict[symbol]['alert_scenario_4'] = True
                                alert_dict[symbol]['position_s1_r1'] = coin.get('position', 0)
                    except:
                        pass
        
        # è·å–æ‰€æœ‰å¸ç§çš„æ”¯æ’‘/å‹åŠ›çº¿æ•°æ®ï¼ˆä»support_resistance_levelsè¡¨ï¼‰
        # å°†å¸ç§æ ¼å¼ä» 'BTC-USDT-SWAP' è½¬æ¢ä¸º 'BTCUSDT'
        symbols_for_levels = [s.replace('-USDT-SWAP', 'USDT') for s in MONITORED_SYMBOLS]
        placeholders_levels = ','.join(['?' for _ in symbols_for_levels])
        
        # Get the latest record for each symbol using a subquery
        cursor.execute(f'''
            SELECT srl.symbol, srl.current_price, srl.support_line_1, srl.support_line_2, 
                   srl.resistance_line_1, srl.resistance_line_2,
                   srl.position_7d, srl.position_48h,
                   srl.alert_7d_low, srl.alert_7d_high,
                   srl.alert_48h_low, srl.alert_48h_high,
                   srl.support_1_days, srl.support_2_hours,
                   srl.resistance_1_days, srl.resistance_2_hours,
                   srl.baseline_price_24h, srl.price_change_24h, srl.change_percent_24h
            FROM support_resistance_levels srl
            INNER JOIN (
                SELECT symbol, MAX(record_time) as max_time
                FROM support_resistance_levels
                WHERE symbol IN ({placeholders_levels})
                GROUP BY symbol
            ) latest ON srl.symbol = latest.symbol AND srl.record_time = latest.max_time
        ''', symbols_for_levels)
        
        sr_levels_rows = cursor.fetchall()
        sr_levels_dict = {}
        for row in sr_levels_rows:
            symbol = row['symbol']  # å·²ç»æ˜¯ BTCUSDT æ ¼å¼
            sr_levels_dict[symbol] = {
                'current_price': row['current_price'] or 0,  # ä»æ•°æ®åº“è¯»å–current_price
                'support_1': row['support_line_1'] or 0,
                'support_2': row['support_line_2'] or 0,
                'resistance_1': row['resistance_line_1'] or 0,
                'resistance_2': row['resistance_line_2'] or 0,
                'position_7d': row['position_7d'] or 0,
                'position_48h': row['position_48h'] or 0,
                'alert_7d_low': row['alert_7d_low'] or False,
                'alert_7d_high': row['alert_7d_high'] or False,
                'alert_48h_low': row['alert_48h_low'] or False,
                'alert_48h_high': row['alert_48h_high'] or False,
                'support_1_days': row['support_1_days'] or 0,
                'support_2_hours': row['support_2_hours'] or 0,
                'resistance_1_days': row['resistance_1_days'] or 0,
                'resistance_2_hours': row['support_2_hours'] or 0,
                'baseline_price_24h': row['baseline_price_24h'] or 0,
                'price_change_24h': row['price_change_24h'] or 0,
                'change_percent_24h': row['change_percent_24h'] or 0
            }
        
        # æ„å»ºç»“æœï¼šæ‰€æœ‰27ä¸ªå¸ç§
        result_data = []
        for symbol in MONITORED_SYMBOLS:
            alert_info = alert_dict.get(symbol, {})
            symbol_usdt = symbol.replace('-USDT-SWAP', 'USDT')
            
            # ä¼˜å…ˆä½¿ç”¨alert_infoä¸­çš„æ”¯æ’‘/å‹åŠ›çº¿æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨sr_levels_dictä¸­çš„æ•°æ®
            sr_data = sr_levels_dict.get(symbol_usdt, {})
            # ä½¿ç”¨æ•°æ®åº“ä¸­çš„current_priceï¼Œè€Œä¸æ˜¯å®æ—¶æŸ¥è¯¢çš„ä»·æ ¼ï¼ˆä¿æŒæ•°æ®ä¸€è‡´æ€§ï¼‰
            current_price = sr_data.get('current_price', 0) or price_dict.get(symbol, 0)
            support_1 = alert_info.get('support_1', 0) or sr_data.get('support_1', 0)
            support_2 = alert_info.get('support_2', 0) or sr_data.get('support_2', 0)
            resistance_1 = alert_info.get('resistance_1', 0) or sr_data.get('resistance_1', 0)
            resistance_2 = alert_info.get('resistance_2', 0) or sr_data.get('resistance_2', 0)
            
            # è®¡ç®—è·ç¦»ç™¾åˆ†æ¯”ï¼ˆä½¿ç”¨å®æ—¶ä»·æ ¼ï¼‰
            distance_to_support_1 = ((current_price - support_1) / support_1) * 100 if support_1 > 0 else 0
            distance_to_support_2 = ((current_price - support_2) / support_2) * 100 if support_2 > 0 else 0
            distance_to_resistance_1 = ((resistance_1 - current_price) / current_price) * 100 if current_price > 0 else 0
            distance_to_resistance_2 = ((resistance_2 - current_price) / current_price) * 100 if current_price > 0 else 0
            
            coin_data = {
                'symbol': symbol_usdt,
                'current_price': current_price,
                'support_line_1': support_1,
                'support_line_2': support_2,
                'resistance_line_1': resistance_1,
                'resistance_line_2': resistance_2,
                'distance_to_support_1': distance_to_support_1,
                'distance_to_support_2': distance_to_support_2,
                'distance_to_resistance_1': distance_to_resistance_1,
                'distance_to_resistance_2': distance_to_resistance_2,
                'position_7d': sr_data.get('position_7d', 0),  # 7å¤©ä½ç½®ç™¾åˆ†æ¯”
                'position_48h': sr_data.get('position_48h', 0),  # 48å°æ—¶ä½ç½®ç™¾åˆ†æ¯”
                'support_1_days': sr_data.get('support_1_days', 0),  # 7å¤©æœ€ä½ä»·å‘ç”Ÿåœ¨Nå¤©å‰
                'support_2_hours': sr_data.get('support_2_hours', 0),  # 48hæœ€ä½ä»·å‘ç”Ÿåœ¨Nå°æ—¶å‰
                'resistance_1_days': sr_data.get('resistance_1_days', 0),  # 7å¤©æœ€é«˜ä»·å‘ç”Ÿåœ¨Nå¤©å‰
                'resistance_2_hours': sr_data.get('resistance_2_hours', 0),  # 48hæœ€é«˜ä»·å‘ç”Ÿåœ¨Nå°æ—¶å‰
                'alert_7d_low': sr_data.get('alert_7d_low', False),  # 7å¤©ä½ä½é¢„è­¦
                'alert_7d_high': sr_data.get('alert_7d_high', False),  # 7å¤©é«˜ä½é¢„è­¦
                'alert_48h_low': sr_data.get('alert_48h_low', False),  # 48hä½ä½é¢„è­¦
                'alert_48h_high': sr_data.get('alert_48h_high', False),  # 48hé«˜ä½é¢„è­¦
                'baseline_price_24h': sr_data.get('baseline_price_24h', 0),  # ä»Šæ—¥åŸºå‡†ä»·æ ¼ï¼ˆåŒ—äº¬æ—¶é—´0ç‚¹ï¼‰
                'price_change_24h': sr_data.get('price_change_24h', 0),  # 24å°æ—¶æ¶¨è·Œé¢
                'change_percent_24h': sr_data.get('change_percent_24h', 0),  # 24å°æ—¶æ¶¨è·Œå¹…%
                'position_s2_r1': alert_info.get('position_s2_r1'),
                'position_s1_r2': alert_info.get('position_s1_r2'),
                'position_s1_r2_upper': alert_info.get('position_s1_r2_upper'),
                'position_s1_r1': alert_info.get('position_s1_r1'),
                'alert_scenario_1': alert_info.get('alert_scenario_1', False),
                'alert_scenario_2': alert_info.get('alert_scenario_2', False),
                'alert_scenario_3': alert_info.get('alert_scenario_3', False),
                'alert_scenario_4': alert_info.get('alert_scenario_4', False),
                'alert_triggered': any([
                    alert_info.get('alert_scenario_1', False),
                    alert_info.get('alert_scenario_2', False),
                    alert_info.get('alert_scenario_3', False),
                    alert_info.get('alert_scenario_4', False)
                ]),
                'record_time': update_time
            }
            result_data.append(coin_data)
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': result_data,
            'count': len(result_data),
            'update_time': update_time
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/support-resistance/history/<symbol>')
def api_support_resistance_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²æ”¯æ’‘å‹åŠ›çº¿æ•°æ®"""
    try:
        hours = request.args.get('hours', 24, type=int)
        
        conn = sqlite3.connect('support_resistance.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT 
                symbol,
                current_price,
                support_line_1,
                support_line_2,
                resistance_line_1,
                resistance_line_2,
                distance_to_support_1,
                distance_to_support_2,
                distance_to_resistance_1,
                distance_to_resistance_2,
                record_time
            FROM support_resistance_levels
            WHERE symbol = ?
            AND datetime(record_time) >= datetime('now', '+8 hours', ? || ' hours')
            ORDER BY record_time DESC
        ''', (symbol, -hours))
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'symbol': row['symbol'],
                'current_price': row['current_price'],
                'support_line_1': row['support_line_1'],
                'support_line_2': row['support_line_2'],
                'resistance_line_1': row['resistance_line_1'],
                'resistance_line_2': row['resistance_line_2'],
                'distance_to_support_1': row['distance_to_support_1'],
                'distance_to_support_2': row['distance_to_support_2'],
                'distance_to_resistance_1': row['distance_to_resistance_1'],
                'distance_to_resistance_2': row['distance_to_resistance_2'],
                'record_time': row['record_time']
            })
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'data': data,
            'count': len(data)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/support-resistance/snapshots')
def api_support_resistance_snapshots():
    """è·å–æ”¯æ’‘å‹åŠ›çº¿å¿«ç…§å†å²æ•°æ®ï¼ˆç”¨äºæ—¶é—´è½´å’Œè¶‹åŠ¿å›¾ï¼‰"""
    try:
        import json
        from datetime import datetime, timedelta
        import pytz
        
        date = request.args.get('date')  # æ ¼å¼: 2025-12-13
        start_hour = request.args.get('start_hour', type=int)  # 0-23
        end_hour = request.args.get('end_hour', type=int)  # 0-23
        start_time = request.args.get('start_time')  # æ ¼å¼: 2025-12-13 00:00:00
        end_time = request.args.get('end_time')  # æ ¼å¼: 2025-12-13 12:00:00
        get_all = request.args.get('all', 'false').lower() == 'true'  # è·å–æ‰€æœ‰å†å²æ•°æ®
        
        conn = sqlite3.connect('support_resistance.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        if get_all:
            # è·å–æ‰€æœ‰å†å²æ•°æ®ï¼ˆç”¨äºå…¨å±€è¶‹åŠ¿å›¾ï¼‰
            cursor.execute('''
                SELECT 
                    snapshot_time, snapshot_date,
                    scenario_1_count, scenario_2_count, scenario_3_count, scenario_4_count,
                    scenario_1_coins, scenario_2_coins, scenario_3_coins, scenario_4_coins,
                    total_coins
                FROM support_resistance_snapshots
                ORDER BY snapshot_time ASC
            ''')
        elif start_time and end_time:
            # è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®ï¼ˆç”¨äºç¿»é¡µæŸ¥çœ‹ï¼‰
            cursor.execute('''
                SELECT 
                    snapshot_time, snapshot_date,
                    scenario_1_count, scenario_2_count, scenario_3_count, scenario_4_count,
                    scenario_1_coins, scenario_2_coins, scenario_3_coins, scenario_4_coins,
                    total_coins
                FROM support_resistance_snapshots
                WHERE snapshot_time >= ? AND snapshot_time < ?
                ORDER BY snapshot_time ASC
            ''', (start_time, end_time))
        elif date and start_hour is not None and end_hour is not None:
            # ğŸ†• æ”¯æŒæŒ‰å°æ—¶èŒƒå›´æŸ¥è¯¢ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
            # æ³¨æ„ï¼šæ•°æ®åº“å­˜å‚¨çš„å·²ç»æ˜¯åŒ—äº¬æ—¶é—´ï¼Œç›´æ¥ä½¿ç”¨å³å¯
            
            # æ„é€ åŒ—äº¬æ—¶é—´èŒƒå›´å­—ç¬¦ä¸²
            beijing_start_str = f"{date} {start_hour:02d}:00:00"
            
            # å¤„ç† end_hour = 24 çš„æƒ…å†µï¼ˆ24:00 = æ¬¡æ—¥ 00:00ï¼‰
            if end_hour >= 24:
                from datetime import timedelta
                beijing_start_dt = datetime.strptime(beijing_start_str, "%Y-%m-%d %H:%M:%S")
                beijing_end_dt = beijing_start_dt + timedelta(hours=(end_hour - start_hour))
                beijing_end_str = beijing_end_dt.strftime("%Y-%m-%d %H:%M:%S")
            else:
                beijing_end_str = f"{date} {end_hour:02d}:00:00"
            
            cursor.execute('''
                SELECT 
                    snapshot_time, snapshot_date,
                    scenario_1_count, scenario_2_count, scenario_3_count, scenario_4_count,
                    scenario_1_coins, scenario_2_coins, scenario_3_coins, scenario_4_coins,
                    total_coins
                FROM support_resistance_snapshots
                WHERE snapshot_time >= ? AND snapshot_time < ?
                ORDER BY snapshot_time ASC
            ''', (beijing_start_str, beijing_end_str))
        elif date:
            # è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æ•°æ®
            cursor.execute('''
                SELECT 
                    snapshot_time, snapshot_date,
                    scenario_1_count, scenario_2_count, scenario_3_count, scenario_4_count,
                    scenario_1_coins, scenario_2_coins, scenario_3_coins, scenario_4_coins,
                    total_coins
                FROM support_resistance_snapshots
                WHERE snapshot_date = ?
                ORDER BY snapshot_time ASC
            ''', (date,))
        else:
            # è·å–æœ€è¿‘12å°æ—¶çš„æ•°æ®
            cursor.execute('''
                SELECT 
                    snapshot_time, snapshot_date,
                    scenario_1_count, scenario_2_count, scenario_3_count, scenario_4_count,
                    scenario_1_coins, scenario_2_coins, scenario_3_coins, scenario_4_coins,
                    total_coins
                FROM support_resistance_snapshots
                WHERE snapshot_time >= datetime('now', '-12 hours')
                ORDER BY snapshot_time ASC
            ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        # æ•°æ®åº“ä¸­å­˜å‚¨çš„å·²ç»æ˜¯åŒ—äº¬æ—¶é—´ï¼Œç›´æ¥ä½¿ç”¨
        data = []
        for row in rows:
            data.append({
                'snapshot_time': row['snapshot_time'],  # æ•°æ®åº“å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´
                'snapshot_date': row['snapshot_date'],
                'scenario_1_count': row['scenario_1_count'],
                'scenario_2_count': row['scenario_2_count'],
                'scenario_3_count': row['scenario_3_count'],
                'scenario_4_count': row['scenario_4_count'],
                'scenario_1_coins': json.loads(row['scenario_1_coins']) if row['scenario_1_coins'] else [],
                'scenario_2_coins': json.loads(row['scenario_2_coins']) if row['scenario_2_coins'] else [],
                'scenario_3_coins': json.loads(row['scenario_3_coins']) if row['scenario_3_coins'] else [],
                'scenario_4_coins': json.loads(row['scenario_4_coins']) if row['scenario_4_coins'] else [],
                'total_coins': row['total_coins']
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data),
            'date': date,
            'start_time': start_time,
            'end_time': end_time
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/support-resistance/latest-signal')
def api_support_resistance_latest_signal():
    """è·å–æœ€æ–°å¿«ç…§æ•°æ®å¹¶æ£€æµ‹æ˜¯å¦è§¦å‘ä¿¡å·"""
    try:
        import json
        from datetime import datetime
        import pytz
        
        conn = sqlite3.connect('support_resistance.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„å®æ—¶æ•°æ®æ—¶é—´ï¼ˆä»support_resistance_levelsè¡¨ï¼‰
        cursor.execute('''
            SELECT MAX(record_time) as latest_time
            FROM support_resistance_levels
        ''')
        
        time_row = cursor.fetchone()
        latest_time = time_row['latest_time'] if time_row else None
        
        # è·å–æœ€æ–°çš„å¿«ç…§ï¼ˆå¦‚æœæœ‰ï¼‰
        cursor.execute('''
            SELECT 
                snapshot_time, snapshot_date,
                scenario_1_count, scenario_2_count, scenario_3_count, scenario_4_count,
                scenario_1_coins, scenario_2_coins, scenario_3_coins, scenario_4_coins,
                total_coins
            FROM support_resistance_snapshots
            ORDER BY snapshot_time DESC
            LIMIT 1
        ''')
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— å¿«ç…§æ•°æ®'
            })
        
        # ä½¿ç”¨å®æ—¶æ•°æ®çš„æœ€æ–°æ—¶é—´ï¼Œè€Œä¸æ˜¯å¿«ç…§æ—¶é—´
        snapshot_time_str = latest_time if latest_time else row['snapshot_time']
        
        scenario_1 = row['scenario_1_count'] or 0
        scenario_2 = row['scenario_2_count'] or 0
        scenario_3 = row['scenario_3_count'] or 0
        scenario_4 = row['scenario_4_count'] or 0
        
        # æ£€æµ‹ä¿¡å·
        # æŠ„åº•ä¿¡å·ï¼šæƒ…å†µ1 >= 8 AND æƒ…å†µ2 >= 8ï¼ˆä¸¤ä¸ªæ¡ä»¶éƒ½è¦æ»¡è¶³ï¼‰
        buy_signal = scenario_1 >= 8 and scenario_2 >= 8
        
        # é€ƒé¡¶ä¿¡å·ï¼š(æƒ…å†µ3 + æƒ…å†µ4) >= 8ï¼ˆæ€»å’Œæ»¡è¶³å³å¯ï¼‰
        sell_signal = (scenario_3 + scenario_4) >= 8
        
        result = {
            'success': True,
            'snapshot_time': snapshot_time_str,  # ç›´æ¥ä½¿ç”¨æ•°æ®åº“ä¸­çš„åŒ—äº¬æ—¶é—´
            'snapshot_date': row['snapshot_date'],
            'scenario_1_count': scenario_1,
            'scenario_2_count': scenario_2,
            'scenario_3_count': scenario_3,
            'scenario_4_count': scenario_4,
            'scenario_1_coins': json.loads(row['scenario_1_coins']) if row['scenario_1_coins'] else [],
            'scenario_2_coins': json.loads(row['scenario_2_coins']) if row['scenario_2_coins'] else [],
            'scenario_3_coins': json.loads(row['scenario_3_coins']) if row['scenario_3_coins'] else [],
            'scenario_4_coins': json.loads(row['scenario_4_coins']) if row['scenario_4_coins'] else [],
            'total_coins': row['total_coins'],
            'signals': {
                'buy': buy_signal,
                'sell': sell_signal,
                'buy_count': scenario_1 + scenario_2 if buy_signal else 0,
                'sell_count': scenario_3 + scenario_4 if sell_signal else 0
            }
        }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/support-resistance/dates')
def api_support_resistance_dates():
    """è·å–æœ‰å¿«ç…§æ•°æ®çš„æ‰€æœ‰æ—¥æœŸåˆ—è¡¨"""
    try:
        conn = sqlite3.connect('support_resistance.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT DISTINCT snapshot_date
            FROM support_resistance_snapshots
            ORDER BY snapshot_date DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        dates = [row[0] for row in rows]
        
        return jsonify({
            'success': True,
            'dates': dates,
            'count': len(dates)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

# =====================================================
# é€ƒé¡¶ä¿¡å·ç³»ç»Ÿ APIè·¯ç”±
# =====================================================

@app.route('/escape-top-signals')
def escape_top_signals_page():
    """é€ƒé¡¶ä¿¡å·ç›‘æ§é¡µé¢"""
    response = make_response(render_template('escape_top_signals.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/escape-top-signals/latest')
def api_escape_top_signals_latest():
    """è·å–æœ€æ–°çš„é€ƒé¡¶ä¿¡å·æ•°æ® - ç›´æ¥ä»support_resistance_levelsæŸ¥è¯¢"""
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=30.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ç›´æ¥ä»support_resistance_levelsè¡¨æŸ¥è¯¢24å°æ—¶å†…æœ‰é€ƒé¡¶å€¾å‘çš„æ•°æ®
        cursor.execute('''
            SELECT 
                symbol,
                record_time as signal_time,
                current_price,
                resistance_line_1,
                resistance_line_2,
                distance_to_resistance_1 as distance_to_r1,
                distance_to_resistance_2 as distance_to_r2,
                alert_scenario_3 as scenario_3_count,
                alert_scenario_4 as scenario_4_count,
                (alert_scenario_3 + alert_scenario_4) as total_escape_score,
                CASE WHEN (alert_scenario_3 + alert_scenario_4) >= 8 THEN 1 ELSE 0 END as is_escape_signal,
                position_48h,
                position_7d,
                price_change_24h,
                change_percent_24h,
                alert_triggered
            FROM support_resistance_levels
            WHERE datetime(record_time) >= datetime('now', '-24 hours')
              AND (alert_scenario_3 > 0 OR alert_scenario_4 > 0)
            ORDER BY record_time DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        signals = []
        for row in rows:
            signals.append({
                'symbol': row['symbol'],
                'signal_time': row['signal_time'],
                'current_price': row['current_price'],
                'resistance_line_1': row['resistance_line_1'],
                'resistance_line_2': row['resistance_line_2'],
                'distance_to_r1': row['distance_to_r1'],
                'distance_to_r2': row['distance_to_r2'],
                'scenario_3_count': row['scenario_3_count'],
                'scenario_4_count': row['scenario_4_count'],
                'total_escape_score': row['total_escape_score'],
                'is_escape_signal': row['is_escape_signal'],
                'position_48h': row['position_48h'],
                'position_7d': row['position_7d'],
                'price_change_24h': row['price_change_24h'],
                'change_percent_24h': row['change_percent_24h'],
                'alert_triggered': row['alert_triggered']
            })
        
        return jsonify({
            'success': True,
            'data': signals,
            'count': len(signals)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'data': []
        })

@app.route('/api/escape-top-signals/history/<symbol>')
def api_escape_top_signals_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²é€ƒé¡¶ä¿¡å·"""
    try:
        hours = request.args.get('hours', 24, type=int)
        
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT 
                signal_time,
                current_price,
                total_escape_score,
                is_escape_signal,
                position_48h,
                position_7d
            FROM escape_top_signals_24h
            WHERE symbol = ?
              AND datetime(signal_time) >= datetime('now', ? || ' hours')
            ORDER BY signal_time ASC
        ''', (symbol, f'-{hours}'))
        
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'signal_time': row['signal_time'],
                'current_price': row['current_price'],
                'total_escape_score': row['total_escape_score'],
                'is_escape_signal': row['is_escape_signal'],
                'position_48h': row['position_48h'],
                'position_7d': row['position_7d']
            })
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'data': history,
            'count': len(history)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'data': []
        })

@app.route('/api/escape-top-signals/stats')
def api_escape_top_signals_stats():
    """è·å–é€ƒé¡¶ä¿¡å·ç»Ÿè®¡æ•°æ® - è¿”å›çœŸå®çš„é€ƒé¡¶äº‹ä»¶æ¬¡æ•°"""
    try:
        hours = request.args.get('hours', 24, type=int)
        
        conn = sqlite3.connect('crypto_data.db', timeout=30.0)
        cursor = conn.cursor()
        
        # é€ƒé¡¶äº‹ä»¶æ¬¡æ•°ï¼ˆç»Ÿè®¡ä¸åŒæ—¶é—´ç‚¹çš„é€ƒé¡¶äº‹ä»¶æ•°é‡ï¼‰
        # æ¡ä»¶ï¼šalert_triggered=1 ä¸” (æƒ…å†µ3+æƒ…å†µ4)>=8 ä¸” æƒ…å†µ3>=1 ä¸” æƒ…å†µ4>=1
        cursor.execute('''
            SELECT COUNT(DISTINCT strftime('%Y-%m-%d %H:%M', record_time)) as event_count
            FROM support_resistance_levels
            WHERE datetime(record_time) >= datetime('now', ? || ' hours')
              AND alert_triggered = 1
              AND (alert_scenario_3 + alert_scenario_4) >= 8
              AND alert_scenario_3 >= 1
              AND alert_scenario_4 >= 1
        ''', (f'-{hours}',))
        total_escape_events = cursor.fetchone()[0]
        
        # è§¦å‘ä¿¡å·çš„å¸ç§æ•°
        cursor.execute('''
            SELECT COUNT(DISTINCT symbol) as coin_count
            FROM support_resistance_levels
            WHERE datetime(record_time) >= datetime('now', ? || ' hours')
              AND alert_triggered = 1
              AND (alert_scenario_3 + alert_scenario_4) >= 8
              AND alert_scenario_3 >= 1
              AND alert_scenario_4 >= 1
        ''', (f'-{hours}',))
        coin_count = cursor.fetchone()[0]
        
        # å¹³å‡é€ƒé¡¶åˆ†æ•°
        cursor.execute('''
            SELECT AVG(alert_scenario_3 + alert_scenario_4) as avg_score
            FROM support_resistance_levels
            WHERE datetime(record_time) >= datetime('now', ? || ' hours')
              AND (alert_scenario_3 > 0 OR alert_scenario_4 > 0)
        ''', (f'-{hours}',))
        avg_score = cursor.fetchone()[0] or 0
        
        # æŒ‰å¸ç§ç»Ÿè®¡
        cursor.execute('''
            SELECT 
                symbol,
                COUNT(*) as signal_count,
                AVG(alert_scenario_3 + alert_scenario_4) as avg_score,
                MAX(alert_scenario_3 + alert_scenario_4) as max_score
            FROM support_resistance_levels
            WHERE datetime(record_time) >= datetime('now', ? || ' hours')
              AND (alert_scenario_3 > 0 OR alert_scenario_4 > 0)
            GROUP BY symbol
            ORDER BY signal_count DESC
        ''', (f'-{hours}',))
        
        by_symbol = []
        for row in cursor.fetchall():
            by_symbol.append({
                'symbol': row[0],
                'signal_count': row[1],
                'avg_score': round(row[2], 2),
                'max_score': row[3]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'stats': {
                'total_signals': total_escape_events,  # çœŸå®çš„é€ƒé¡¶äº‹ä»¶æ¬¡æ•°
                'active_coins': coin_count,
                'avg_escape_score': round(avg_score, 2),
                'by_symbol': by_symbol
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/escape-top-signals/history-timeseries')
def api_escape_top_signals_history_timeseries():
    """è·å–é€ƒé¡¶ä¿¡å·çš„å†å²æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ¯5åˆ†é’Ÿç»Ÿè®¡ä¸€æ¬¡ï¼‰- åŒ—äº¬æ—¶é—´"""
    try:
        hours = request.args.get('hours', 24, type=int)
        
        conn = sqlite3.connect('crypto_data.db', timeout=30.0)
        cursor = conn.cursor()
        
        # æŒ‰5åˆ†é’Ÿé—´éš”ç»Ÿè®¡é€ƒé¡¶ä¿¡å·æ•°é‡ï¼ˆUTCè½¬åŒ—äº¬æ—¶é—´+8å°æ—¶ï¼‰
        cursor.execute('''
            SELECT 
                datetime(
                    strftime('%Y-%m-%d %H:', datetime(record_time, '+8 hours')) || 
                    printf('%02d', (CAST(strftime('%M', datetime(record_time, '+8 hours')) AS INTEGER) / 5) * 5) ||
                    ':00'
                ) as time_slot,
                COUNT(DISTINCT symbol) as unique_symbols
            FROM support_resistance_levels
            WHERE datetime(record_time) >= datetime('now', ? || ' hours')
              AND (alert_scenario_3 > 0 OR alert_scenario_4 > 0)
            GROUP BY time_slot
            ORDER BY time_slot ASC
        ''', (f'-{hours}',))
        
        timeseries = []
        for row in cursor.fetchall():
            timeseries.append({
                'time': row[0],  # å·²ç»åŒ…å«å®Œæ•´æ—¶é—´æ ¼å¼
                'count': row[1]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': timeseries,
            'count': len(timeseries),
            'timezone': 'åŒ—äº¬æ—¶é—´ (UTC+8)'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'data': []
        })

@app.route('/api/escape-event-stats/timeseries')
def api_escape_event_stats_timeseries():
    """è·å–é€ƒé¡¶äº‹ä»¶ç»Ÿè®¡çš„æ—¶é—´åºåˆ—æ•°æ®ï¼ˆä»JSONæ–‡ä»¶è¯»å–ï¼‰"""
    try:
        hours = request.args.get('hours', 24, type=int)
        
        # ä»JSONæ–‡ä»¶è¯»å–æ•°æ®
        import json
        import os
        from datetime import datetime, timedelta
        
        data_file = 'escape_event_stats.json'
        timeseries = []
        
        if os.path.exists(data_file):
            with open(data_file, 'r') as f:
                data = json.load(f)
                
            # è¿‡æ»¤æŒ‡å®šå°æ—¶æ•°çš„æ•°æ®
            cutoff_time = (datetime.now() - timedelta(hours=hours)).strftime('%Y-%m-%d %H:%M:00')
            timeseries = [item for item in data if item['time'] >= cutoff_time]
        
        return jsonify({
            'success': True,
            'data': timeseries,
            'count': len(timeseries),
            'timezone': 'åŒ—äº¬æ—¶é—´ (UTC+8)'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'data': []
        })

# =====================================================
# OKEx Kçº¿æŒ‡æ ‡ç³»ç»Ÿ APIè·¯ç”±
# =====================================================

@app.route('/kline-indicators')
def kline_indicators_page():
    """Kçº¿æŒ‡æ ‡ç³»ç»Ÿç›‘æ§é¡µé¢"""
    return render_template('kline_indicators.html')

@app.route('/api/kline-indicators/latest')
def api_kline_indicators_latest():
    """
    è·å–æœ€æ–°çš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    
    å‚æ•°ï¼š
        - symbol: å¸ç§ï¼ˆå¯é€‰ï¼Œå¦‚BTC-USDT-SWAPï¼‰
        - timeframe: æ—¶é—´å‘¨æœŸï¼ˆå¯é€‰ï¼Œ5mæˆ–1hï¼‰
    """
    try:
        symbol = request.args.get('symbol')
        timeframe = request.args.get('timeframe')
        
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []
        
        if symbol:
            conditions.append('symbol = ?')
            params.append(symbol)
        if timeframe:
            conditions.append('timeframe = ?')
            params.append(timeframe)
        
        # æ„å»ºWHEREå­å¥
        if conditions:
            where_clause = f"WHERE {' AND '.join(conditions)} AND"
        else:
            where_clause = "WHERE"
        
        # è·å–æ¯ä¸ªå¸ç§+æ—¶é—´å‘¨æœŸçš„æœ€æ–°æ•°æ®
        cursor.execute(f'''
            SELECT 
                symbol, timeframe, current_price, rsi_14, 
                sar, sar_position, sar_quadrant, sar_count_label,
                bb_upper, bb_middle, bb_lower, record_time
            FROM okex_technical_indicators
            {where_clause} id IN (
                SELECT MAX(id)
                FROM okex_technical_indicators
                GROUP BY symbol, timeframe
            )
            ORDER BY symbol, timeframe
        ''', params)
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'symbol': row['symbol'],
                'timeframe': row['timeframe'],
                'current_price': row['current_price'],
                'rsi_14': row['rsi_14'],
                'sar': row['sar'],
                'sar_position': row['sar_position'],
                'sar_quadrant': row['sar_quadrant'],
                'sar_count_label': row['sar_count_label'],
                'bb_upper': row['bb_upper'],
                'bb_middle': row['bb_middle'],
                'bb_lower': row['bb_lower'],
                'record_time': row['record_time']
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data),
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/kline-indicators/collector-status')
def api_kline_indicators_status():
    """è·å–é‡‡é›†å™¨è¿è¡ŒçŠ¶æ€"""
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°é‡‡é›†æ—¶é—´
        cursor.execute('''
            SELECT MAX(record_time) as last_collection
            FROM okex_technical_indicators
        ''')
        row = cursor.fetchone()
        last_collection = row['last_collection'] if row else None
        
        # ç»Ÿè®¡æ•°æ®é‡
        cursor.execute('SELECT COUNT(*) as count_indicators FROM okex_technical_indicators')
        count_indicators = cursor.fetchone()['count_indicators']
        
        # ç»Ÿè®¡ä¸åŒæ—¶é—´å‘¨æœŸçš„æ•°é‡
        cursor.execute('''
            SELECT 
                SUM(CASE WHEN timeframe = '5m' THEN 1 ELSE 0 END) as count_5m,
                SUM(CASE WHEN timeframe = '1H' THEN 1 ELSE 0 END) as count_1h
            FROM okex_technical_indicators
        ''')
        row = cursor.fetchone()
        count_5m = row['count_5m'] or 0
        count_1h = row['count_1h'] or 0
        
        conn.close()
        
        # è®¡ç®—çŠ¶æ€ï¼ˆæ•°æ®åº“å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼‰
        if last_collection:
            # æ•°æ®åº“ä¸­çš„æ—¶é—´æ˜¯åŒ—äº¬æ—¶é—´ï¼Œéœ€è¦ä¸åŒ—äº¬æ—¶é—´æ¯”è¾ƒ
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            last_time = datetime.strptime(last_collection, '%Y-%m-%d %H:%M:%S')
            now_beijing = datetime.now(beijing_tz).replace(tzinfo=None)
            delta_minutes = (now_beijing - last_time).total_seconds() / 60
            status = 'running' if delta_minutes < 10 else 'stopped'
        else:
            status = 'not_started'
            delta_minutes = None
        
        return jsonify({
            'success': True,
            'status': status,
            'last_collection_time': last_collection,
            'minutes_since_last': round(delta_minutes, 1) if delta_minutes else None,
            'data_counts': {
                'kline_5m': count_5m,
                'kline_1h': count_1h,
                'indicators': count_indicators
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def cleanup_expired_signals():
    """
    æ¸…ç†2å°æ—¶ä¹‹å‰çš„è¿‡æœŸä¿¡å·
    å°† is_valid è®¾ç½®ä¸º 0
    """
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=5.0)
        cursor = conn.cursor()
        
        from datetime import datetime, timedelta
        cutoff_time = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # æ¸…ç†ä¹°ç‚¹4è¿‡æœŸä¿¡å·
        cursor.execute('''
            UPDATE buy_point_4_signals
            SET is_valid = 0
            WHERE is_valid = 1 AND confirm_time < ?
        ''', (cutoff_time,))
        buy_point_4_cleaned = cursor.rowcount
        
        # æ¸…ç†å–ç‚¹1è¿‡æœŸä¿¡å·
        cursor.execute('''
            UPDATE sell_point_1_signals
            SET is_valid = 0
            WHERE is_valid = 1 AND mark_time < ?
        ''', (cutoff_time,))
        sell_point_1_cleaned = cursor.rowcount
        
        conn.commit()
        conn.close()
        
        return {
            'buy_point_4_cleaned': buy_point_4_cleaned,
            'sell_point_1_cleaned': sell_point_1_cleaned
        }
    except Exception as e:
        return {'error': str(e)}

@app.route('/api/kline-indicators/signals')
def api_kline_indicators_signals():
    """
    è¿”å›Kçº¿æŒ‡æ ‡ä¿¡å·ï¼ˆ2å°æ—¶æ—¶é—´çª—å£ï¼‰
    æ•°æ®å®Œå…¨ä»æ•°æ®åº“è¯»å–ï¼Œä¸è¿›è¡Œå®æ—¶æ£€æµ‹
    - ä¹°ç‚¹4: ä» buy_point_4_signals è¡¨è¯»å–ï¼ˆRSI < 20ï¼‰
    - å–ç‚¹1: ä» sell_point_1_signals è¡¨è¯»å–ï¼ˆRSI >= 60ï¼‰
    """
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        from datetime import datetime, timedelta
        now = datetime.now()
        cutoff_time = (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # åˆå§‹åŒ–ä¿¡å·å®¹å™¨
        signals = {
            'buy_point_4': [],      # ä¹°ç‚¹4ï¼ˆä»æ•°æ®åº“è¯»å–ï¼‰
            'sell_point_1': []      # å–ç‚¹1ï¼ˆä»æ•°æ®åº“è¯»å–ï¼‰
        }
        
        # 1. è¯»å–ä¹°ç‚¹4ä¿¡å·ï¼ˆä¸æŸ¥è¯¢å½“å‰ä»·æ ¼ï¼Œä½¿ç”¨ä¿¡å·æ—¶çš„ä»·æ ¼ï¼‰
        cursor.execute('''
            SELECT symbol, low_price, low_time, confirm_time, 
                   signal_generated_at, confirm_rsi
            FROM buy_point_4_signals
            WHERE is_valid = 1 
              AND confirm_rsi IS NOT NULL 
              AND confirm_rsi < 20
              AND confirm_time >= ?
            ORDER BY confirm_time DESC
            LIMIT 100
        ''', (cutoff_time,))
        
        for row in cursor.fetchall():
            signals['buy_point_4'].append({
                'symbol': row[0],
                'price': row[1],
                'low_7d': row[1],
                'low_time': row[2],
                'confirm_time': row[3],
                'signal_generated_at': row[4],
                'confirm_rsi': row[5],
                'current_price': row[1],  # ä½¿ç”¨ç¡®è®¤æ—¶çš„ä»·æ ¼
                'distance': 0.0  # ä¿¡å·æ—¶åˆ»è·ç¦»ä¸º0
            })
        
        # 2. è¯»å–å–ç‚¹1ä¿¡å·ï¼ˆä¸æŸ¥è¯¢å½“å‰ä»·æ ¼ï¼‰
        cursor.execute('''
            SELECT symbol, high_price, high_time, mark_price, 
                   mark_time, mark_rsi, signal_generated_at
            FROM sell_point_1_signals
            WHERE is_valid = 1 
              AND mark_rsi IS NOT NULL 
              AND mark_rsi >= 60
              AND mark_time >= ?
            ORDER BY mark_time DESC
            LIMIT 100
        ''', (cutoff_time,))
        
        for row in cursor.fetchall():
            signals['sell_point_1'].append({
                'symbol': row[0],
                'high_price': row[1],
                'high_time': row[2],
                'mark_price': row[3],
                'mark_time': row[4],
                'mark_rsi': row[5],
                'signal_generated_at': row[6],
                'current_price': row[3],  # ä½¿ç”¨æ ‡è®°æ—¶çš„ä»·æ ¼
                'distance': 0.0  # ä¿¡å·æ—¶åˆ»è·ç¦»ä¸º0
            })
        
        conn.close()
        
        # ç»Ÿè®¡ä¿¡å·æ•°é‡
        signal_counts = {k: len(v) for k, v in signals.items()}
        
        # å¼‚æ­¥æ¸…ç†è¿‡æœŸä¿¡å·ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        import threading
        threading.Thread(target=cleanup_expired_signals, daemon=True).start()
        
        return jsonify({
            'success': True,
            'data': {
                'signals': signals,
                'counts': signal_counts,
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S')
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/kline-indicators-tv/latest')
def api_kline_indicators_tv_latest():
    """
    è·å–TradingViewç›´æ¥è·å–çš„Kçº¿æŒ‡æ ‡æ•°æ®ï¼ˆä¸è®¡ç®—ï¼‰
    æ”¯æŒå‚æ•°: symbol, timeframe
    æ•°æ®æº: TradingView (OKXäº¤æ˜“æ‰€)
    """
    try:
        symbol = request.args.get('symbol')
        timeframe = request.args.get('timeframe')
        
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []
        
        if symbol:
            conditions.append('symbol = ?')
            params.append(symbol)
        if timeframe:
            conditions.append('timeframe = ?')
            params.append(timeframe)
        
        # æ„å»ºWHEREå­å¥
        if conditions:
            where_clause = f"WHERE {' AND '.join(conditions)}"
        else:
            where_clause = ""
        
        # è·å–æ¯ä¸ªå¸ç§+æ—¶é—´å‘¨æœŸçš„æœ€æ–°æ•°æ®
        query = f'''
            SELECT 
                symbol, timeframe, current_price, rsi_14, 
                sar, bb_upper, bb_middle, bb_lower,
                ema_10, ema_20, recommendation,
                buy_signals, sell_signals, neutral_signals,
                record_time
            FROM okex_tv_indicators
            {where_clause}
            ORDER BY symbol, timeframe
        '''
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            # Calculate SAR position
            sar_position = None
            if row['sar'] and row['current_price']:
                sar_position = 'bullish' if row['current_price'] > row['sar'] else 'bearish'
            
            # Calculate BB middle if not provided
            bb_middle = row['bb_middle']
            if not bb_middle and row['bb_upper'] and row['bb_lower']:
                bb_middle = (row['bb_upper'] + row['bb_lower']) / 2
            
            data.append({
                'symbol': row['symbol'],
                'timeframe': row['timeframe'],
                'current_price': row['current_price'],
                'rsi_14': row['rsi_14'],
                'sar': row['sar'],
                'sar_position': sar_position,
                'bb_upper': row['bb_upper'],
                'bb_middle': bb_middle,
                'bb_lower': row['bb_lower'],
                'ema_10': row['ema_10'],
                'ema_20': row['ema_20'],
                'recommendation': row['recommendation'],
                'buy_signals': row['buy_signals'],
                'sell_signals': row['sell_signals'],
                'neutral_signals': row['neutral_signals'],
                'record_time': row['record_time'],
                'data_source': 'TradingView (ç›´æ¥è·å–, ä¸è®¡ç®—)'
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data),
            'data_source': 'TradingView API (OKX Exchange)',
            'note': 'æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å‡ç›´æ¥ä»TradingViewè·å–ï¼Œä¸è¿›è¡Œæœ¬åœ°è®¡ç®—',
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/kline-indicators-tv/collector-status')
def api_kline_indicators_tv_status():
    """è·å–TradingViewæŒ‡æ ‡é‡‡é›†å™¨è¿è¡ŒçŠ¶æ€"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute('''
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='okex_tv_collector_status'
        ''')
        
        if not cursor.fetchone():
            conn.close()
            return jsonify({
                'success': True,
                'status': 'not_initialized',
                'message': 'TradingView collector not initialized yet'
            })
        
        # è·å–é‡‡é›†çŠ¶æ€
        cursor.execute('''
            SELECT last_collect_time, total_indicators_count, status
            FROM okex_tv_collector_status
            WHERE id = 1
        ''')
        
        row = cursor.fetchone()
        
        # ç»Ÿè®¡æ•°æ®é‡
        cursor.execute('SELECT COUNT(*) FROM okex_tv_indicators')
        count_indicators = cursor.fetchone()[0]
        
        conn.close()
        
        status = row['status'] if row else 'stopped'
        last_collection = row['last_collect_time'] if row else None
        
        return jsonify({
            'success': True,
            'status': status,
            'last_collection_time': last_collection,
            'total_indicators': count_indicators,
            'data_source': 'TradingView (ç›´æ¥è·å–)',
            'note': 'RSI, SAR, å¸ƒæ—å¸¦å‡ç›´æ¥ä»TradingViewè·å–ï¼Œä¸è®¡ç®—'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== å¸ç§è¯¦æƒ…é¡µé¢ ====================

@app.route('/symbol/<symbol>')
def symbol_detail(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ - è‡ªåŠ¨é‡å®šå‘åˆ°v6ä»¥é¿å¼€æµè§ˆå™¨ç¼“å­˜"""
    from flask import redirect, url_for
    return redirect(url_for('symbol_detail_v6', symbol=symbol), code=302)

@app.route('/api/symbol/<symbol>/kline')
def api_symbol_kline(symbol):
    """è·å–å¸ç§Kçº¿æ•°æ®ï¼ˆ10å¤©ï¼‰- ä½¿ç”¨okex_technical_indicatorsè¡¨"""
    try:
        timeframe = request.args.get('timeframe', '5m')  # 5m æˆ– 1H
        
        # å°†symbolè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        if not symbol.endswith('-USDT-SWAP'):
            symbol = f"{symbol}-USDT-SWAP"
        
        # è½¬æ¢timeframeæ ¼å¼: 5m -> 5m, 1h -> 1H (æ•°æ®åº“ä¸­ä½¿ç”¨å¤§å†™H)
        db_timeframe = timeframe.upper() if timeframe == '1h' else timeframe
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ ¹æ®æ—¶é—´å‘¨æœŸè®¾ç½®limit
        if timeframe == '5m':
            # 10å¤©çš„5åˆ†é’ŸKçº¿ = 10 * 24 * 12 = 2880æ ¹
            limit = 2880
        else:  # 1h
            # 10å¤©çš„1å°æ—¶Kçº¿ = 10 * 24 = 240æ ¹
            limit = 240
        
        # ä»okex_kline_ohlcè¡¨è·å–çœŸå®çš„OHLC Kçº¿æ•°æ®
        # å…ˆæŒ‰æ—¶é—´é™åºå–æœ€æ–°çš„Næ¡ï¼Œç„¶ååè½¬ä¸ºå‡åº
        cursor.execute('''
            SELECT timestamp, open, high, low, close, volume
            FROM (
                SELECT timestamp, open, high, low, close, volume
                FROM okex_kline_ohlc
                WHERE symbol = ? AND timeframe = ?
                ORDER BY timestamp DESC
                LIMIT ?
            )
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe, limit))
        
        rows = cursor.fetchall()
        
        # å¦‚æœOHLCè¡¨æ²¡æœ‰æ•°æ®ï¼Œå›é€€åˆ°indicators_historyè¡¨
        if not rows:
            cursor.execute('''
                SELECT timestamp, current_price
                FROM (
                    SELECT timestamp, current_price
                    FROM okex_indicators_history
                    WHERE symbol = ? AND timeframe = ?
                    ORDER BY timestamp DESC
                    LIMIT ?
                )
                ORDER BY timestamp ASC
            ''', (symbol, db_timeframe, limit))
            
            rows_indicators = cursor.fetchall()
            kline_data = []
            
            for i, row in enumerate(rows_indicators):
                timestamp = int(row[0]) if row[0] else 0
                close_price = float(row[1]) if row[1] else 0
                
                # æ¨¡æ‹ŸOHLC
                open_price = close_price * (1 + 0.001 * (i % 3 - 1))
                high_price = close_price * 1.002
                low_price = close_price * 0.998
                volume = close_price * 10
                
                kline_data.append({
                    'timestamp': timestamp,
                    'data': [open_price, high_price, low_price, close_price],  # æ ‡å‡†Kçº¿æ ¼å¼: OHLC
                    'volume': volume
                })
        else:
            # ä½¿ç”¨çœŸå®OHLCæ•°æ®
            kline_data = []
            for row in rows:
                timestamp = int(row[0]) if row[0] else 0
                open_price = float(row[1]) if row[1] else 0
                high_price = float(row[2]) if row[2] else 0
                low_price = float(row[3]) if row[3] else 0
                close_price = float(row[4]) if row[4] else 0
                volume = float(row[5]) if row[5] else 0
                
                kline_data.append({
                    'timestamp': timestamp,
                    'data': [open_price, high_price, low_price, close_price],  # æ ‡å‡†Kçº¿æ ¼å¼: OHLC
                    'volume': volume
                })
        
        # æŸ¥è¯¢æŠ€æœ¯æ ‡è®°æ•°æ®ï¼ˆçª„å¹…éœ‡è¡ã€é«˜ä½ç‚¹ã€SARã€RSIã€å¸ƒæ—å¸¦ç­‰ï¼‰
        cursor.execute('''
            SELECT timestamp, is_narrow_range, change_percent, range_percent, consecutive_count,
                   is_7d_high, is_7d_low, is_48h_high, is_48h_low,
                   rsi_14, sar, sar_position, sar_quadrant, sar_count_label,
                   bb_upper, bb_middle, bb_lower, is_buy_point_4
            FROM kline_technical_markers
            WHERE symbol = ? AND timeframe = ?
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe))
        
        marker_rows = cursor.fetchall()
        markers_dict = {}
        for marker_row in marker_rows:
            ts = int(marker_row[0]) if marker_row[0] else 0
            markers_dict[ts] = {
                'is_narrow_range': bool(marker_row[1]),
                'change_percent': float(marker_row[2]) if marker_row[2] else 0,
                'range_percent': float(marker_row[3]) if marker_row[3] else 0,
                'consecutive_count': int(marker_row[4]) if marker_row[4] else 0,
                'is_7d_high': bool(marker_row[5]),
                'is_7d_low': bool(marker_row[6]),
                'is_48h_high': bool(marker_row[7]),
                'is_48h_low': bool(marker_row[8]),
                'rsi_14': float(marker_row[9]) if marker_row[9] else None,
                'sar': float(marker_row[10]) if marker_row[10] else None,
                'sar_position': marker_row[11],
                'sar_quadrant': int(marker_row[12]) if marker_row[12] else None,
                'sar_count_label': marker_row[13],
                'bb_upper': float(marker_row[14]) if marker_row[14] else None,
                'bb_middle': float(marker_row[15]) if marker_row[15] else None,
                'bb_lower': float(marker_row[16]) if marker_row[16] else None,
                'is_buy_point_4': bool(marker_row[17])
            }
        
        # å°†æ ‡è®°æ•°æ®åˆå¹¶åˆ°Kçº¿æ•°æ®ä¸­
        for item in kline_data:
            ts = item['timestamp']
            if ts in markers_dict:
                item['markers'] = markers_dict[ts]
        
        conn.close()
        
        # åˆ›å»ºå“åº”å¯¹è±¡å¹¶æ·»åŠ ç¼“å­˜å¤´
        response = jsonify({
            'success': True,
            'symbol': symbol,
            'timeframe': timeframe,
            'data': kline_data,
            'count': len(kline_data)
        })
        
        # æ·»åŠ HTTPç¼“å­˜å¤´ï¼ˆç¼“å­˜60ç§’ï¼Œå› ä¸ºæ•°æ®æ¯60ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
        response.headers['Cache-Control'] = 'public, max-age=60'
        response.headers['Vary'] = 'Accept-Encoding'
        
        return response
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/symbol/<symbol>/indicators')
def api_symbol_indicators(symbol):
    """è·å–å¸ç§æŠ€æœ¯æŒ‡æ ‡æ•°æ® - ä½¿ç”¨okex_technical_indicatorsè¡¨"""
    try:
        timeframe = request.args.get('timeframe', '5m')
        
        # å°†symbolè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        if not symbol.endswith('-USDT-SWAP'):
            symbol = f"{symbol}-USDT-SWAP"
        
        # è½¬æ¢timeframeæ ¼å¼: 5m -> 5m, 1h -> 1H
        db_timeframe = timeframe.upper() if timeframe == '1h' else timeframe
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è®¾ç½®limit
        limit = 2880 if timeframe == '5m' else 240
        
        # ä»okex_indicators_historyè¡¨è·å–å†å²æŒ‡æ ‡æ•°æ®
        cursor.execute('''
            SELECT created_at, current_price, rsi_14, sar, sar_position, sar_count_label,
                   bb_upper, bb_middle, bb_lower, timestamp
            FROM okex_indicators_history
            WHERE symbol = ? AND timeframe = ?
            ORDER BY timestamp ASC
            LIMIT ?
        ''', (symbol, db_timeframe, limit))
        
        rows = cursor.fetchall()
        
        indicators = []
        for row in rows:
            # ä½¿ç”¨æ•°æ®åº“ä¸­çš„timestampå­—æ®µï¼ˆæ¯«ç§’ï¼‰
            timestamp = int(row[9]) if row[9] else 0
            
            indicators.append({
                'timestamp': timestamp,
                'price': float(row[1]) if row[1] else None,
                'rsi': float(row[2]) if row[2] else None,
                'sar': float(row[3]) if row[3] else None,
                'sar_position': row[4],
                'sar_label': row[5],
                'bb_upper': float(row[6]) if row[6] else None,
                'bb_middle': float(row[7]) if row[7] else None,
                'bb_lower': float(row[8]) if row[8] else None,
                'time_str': row[0]  # ä¿ç•™æ—¶é—´å­—ç¬¦ä¸²ç”¨äºè°ƒè¯•
            })
        
        conn.close()
        
        # åˆ›å»ºå“åº”å¯¹è±¡å¹¶æ·»åŠ ç¼“å­˜å¤´
        response = jsonify({
            'success': True,
            'symbol': symbol,
            'timeframe': timeframe,
            'data': indicators,
            'count': len(indicators)
        })
        
        # æ·»åŠ HTTPç¼“å­˜å¤´ï¼ˆç¼“å­˜60ç§’ï¼Œå› ä¸ºæ•°æ®æ¯60ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
        response.headers['Cache-Control'] = 'public, max-age=60'
        response.headers['Vary'] = 'Accept-Encoding'
        
        return response
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/signals/recent')
def api_signals_recent():
    """è·å–æœ€è¿‘2å°æ—¶å†…çš„äº¤æ˜“ä¿¡å·ï¼ŒæŒ‰ç±»å‹åˆ†ç±»"""
    try:
        from datetime import datetime, timedelta
        import json
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è®¡ç®—2å°æ—¶å‰çš„æ—¶é—´
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # è·å–2å°æ—¶å†…çš„ä¿¡å·
        cursor.execute('''
            SELECT record_time, long_signals, short_signals, 
                   today_new_high, today_new_low, raw_data
            FROM trading_signals
            WHERE record_time >= ?
            ORDER BY record_time DESC
        ''', (two_hours_ago,))
        
        rows = cursor.fetchall()
        conn.close()
        
        # åˆ†ç±»ç»Ÿè®¡
        signals_by_type = {
            'long': [],  # åšå¤šä¿¡å·
            'short': [],  # åšç©ºä¿¡å·
            'new_high': [],  # æ–°é«˜ä¿¡å·
            'new_low': []  # æ–°ä½ä¿¡å·
        }
        
        for row in rows:
            record_time = row[0]
            long_count = row[1] or 0
            short_count = row[2] or 0
            new_high = row[3] or 0
            new_low = row[4] or 0
            raw_data = json.loads(row[5]) if row[5] else {}
            
            if long_count > 0:
                signals_by_type['long'].append({
                    'time': record_time,
                    'count': long_count,
                    'detail': raw_data.get('breakdown', {})
                })
            
            if short_count > 0:
                signals_by_type['short'].append({
                    'time': record_time,
                    'count': short_count,
                    'detail': raw_data.get('breakdown', {})
                })
            
            if new_high > 0:
                signals_by_type['new_high'].append({
                    'time': record_time,
                    'count': new_high
                })
            
            if new_low > 0:
                signals_by_type['new_low'].append({
                    'time': record_time,
                    'count': new_low
                })
        
        # è®¡ç®—æ±‡æ€»
        summary = {
            'long_total': sum(s['count'] for s in signals_by_type['long']),
            'short_total': sum(s['count'] for s in signals_by_type['short']),
            'new_high_total': sum(s['count'] for s in signals_by_type['new_high']),
            'new_low_total': sum(s['count'] for s in signals_by_type['new_low']),
            'time_range': two_hours_ago
        }
        
        return jsonify({
            'success': True,
            'signals': signals_by_type,
            'summary': summary
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/symbol/<symbol>/extremes')
def api_symbol_extremes(symbol):
    """è·å–å¸ç§çš„48å°æ—¶å’Œ7å¤©é«˜ä½ç‚¹"""
    try:
        from datetime import datetime, timedelta
        
        timeframe = request.args.get('timeframe', '5m')
        
        # å°†symbolè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        if not symbol.endswith('-USDT-SWAP'):
            symbol = f"{symbol}-USDT-SWAP"
        
        # è½¬æ¢timeframeæ ¼å¼
        db_timeframe = timeframe.upper() if timeframe == '1h' else timeframe
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰
        now_ms = int(datetime.now().timestamp() * 1000)
        hours_48_ago_ms = int((datetime.now() - timedelta(hours=48)).timestamp() * 1000)
        days_7_ago_ms = int((datetime.now() - timedelta(days=7)).timestamp() * 1000)
        
        # è·å–48å°æ—¶å†…çš„é«˜ä½ç‚¹
        cursor.execute('''
            SELECT timestamp, open, high, low, close
            FROM okex_kline_ohlc
            WHERE symbol = ? AND timeframe = ? AND timestamp >= ?
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe, hours_48_ago_ms))
        
        rows_48h = cursor.fetchall()
        
        # è·å–7å¤©å†…çš„é«˜ä½ç‚¹
        cursor.execute('''
            SELECT timestamp, open, high, low, close
            FROM okex_kline_ohlc
            WHERE symbol = ? AND timeframe = ? AND timestamp >= ?
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe, days_7_ago_ms))
        
        rows_7d = cursor.fetchall()
        conn.close()
        
        # è®¡ç®—48å°æ—¶é«˜ä½ç‚¹
        extremes_48h = {'high': None, 'low': None, 'high_time': None, 'low_time': None}
        if rows_48h:
            max_price = max(row[2] for row in rows_48h)  # high
            min_price = min(row[3] for row in rows_48h)  # low
            
            for row in rows_48h:
                if row[2] == max_price:
                    extremes_48h['high'] = max_price
                    extremes_48h['high_time'] = row[0]
                if row[3] == min_price:
                    extremes_48h['low'] = min_price
                    extremes_48h['low_time'] = row[0]
        
        # è®¡ç®—7å¤©é«˜ä½ç‚¹
        extremes_7d = {'high': None, 'low': None, 'high_time': None, 'low_time': None}
        if rows_7d:
            max_price = max(row[2] for row in rows_7d)  # high
            min_price = min(row[3] for row in rows_7d)  # low
            
            for row in rows_7d:
                if row[2] == max_price:
                    extremes_7d['high'] = max_price
                    extremes_7d['high_time'] = row[0]
                if row[3] == min_price:
                    extremes_7d['low'] = min_price
                    extremes_7d['low_time'] = row[0]
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'timeframe': timeframe,
            'extremes_48h': extremes_48h,
            'extremes_7d': extremes_7d
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/test-chart')
def test_chart():
    """æµ‹è¯•Kçº¿å›¾æ¸²æŸ“"""
    with open('test_chart_render.html', 'r', encoding='utf-8') as f:
        return f.read()

# ==================== æ–°ç‰ˆæœ¬è·¯ç”± - å¼ºåˆ¶åˆ·æ–° ====================

@app.route('/symbol/<symbol>/v6')
def symbol_detail_v6(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ v6.0 - å…¨æ–°è·¯ç”±é¿å¼€ç¼“å­˜"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('symbol_detail_v6.html', symbol=symbol, cache_buster=cache_buster))
    
    # ç¦ç”¨HTMLé¡µé¢ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡éƒ½åŠ è½½æœ€æ–°ä»£ç 
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

@app.route('/symbol/<symbol>/v7')
def symbol_detail_v7(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ v7.0 - å…¨æ–°è·¯ç”±é¿å¼€ç¼“å­˜ï¼Œç®€åŒ–è°ƒè¯•"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('symbol_detail_v7.html', symbol=symbol, cache_buster=cache_buster))
    
    # ç¦ç”¨HTMLé¡µé¢ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡éƒ½åŠ è½½æœ€æ–°ä»£ç 
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

@app.route('/symbol/<symbol>/v8')
def symbol_detail_v8(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ v8.0 - å½»åº•é¿å¼€æ‰€æœ‰æµè§ˆå™¨ç¼“å­˜"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('symbol_detail_v8.html', symbol=symbol, cache_buster=cache_buster))
    
    # æœ€å¼ºç¼“å­˜ç¦ç”¨ç­–ç•¥
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    response.headers['X-Content-Type-Options'] = 'nosniff'
    
    return response

@app.route('/kline/<symbol>')
def kline_chart(symbol):
    """å…¨æ–°çš„Kçº¿å›¾è·¯ç”± - å®Œå…¨ç‹¬ç«‹çš„åœ°å€"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('kline_chart.html', symbol=symbol, cache_buster=cache_buster))
    
    # å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    response.headers['X-Content-Type-Options'] = 'nosniff'
    
    return response

@app.route('/test-xlm-data')
def test_xlm_data():
    """XLMæ•°æ®è¯Šæ–­æµ‹è¯•é¡µ"""
    return render_template('test_xlm_data.html')

@app.route('/chart/<symbol>')
def chart_new(symbol):
    """å…¨æ–°Kçº¿å›¾ - ä»é›¶å¼€å§‹ï¼Œç®€å•æ¸…æ™°"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('chart_new.html', symbol=symbol, cache_buster=cache_buster))
    
    # å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

# ==================== Google Drive ç›‘æ§çŠ¶æ€ API ====================

@app.route('/gdrive-monitor-status')
def gdrive_monitor_status_page():
    """Google Drive ç›‘æ§çŠ¶æ€é¡µé¢ - 11åˆ†é’Ÿè¶…æ—¶ä¿é™©æœºåˆ¶å¯è§†åŒ–"""
    return render_template('gdrive_monitor_status.html')

@app.route('/api/gdrive-monitor/status')
def api_gdrive_monitor_status():
    """è·å– Google Drive ç›‘æ§çŠ¶æ€çš„å®æ—¶æ•°æ®"""
    import os
    import json
    from datetime import datetime
    import pytz
    import re
    import requests
    from bs4 import BeautifulSoup
    
    try:
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        config = {}
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        # ğŸ†• æ‰«æ Google Drive ä¸­çš„å®é™…æ–‡ä»¶
        gdrive_dates = {}
        gdrive_scan_error = None
        try:
            ROOT_FOLDER_ID = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"
            url = f"https://drive.google.com/embeddedfolderview?id={ROOT_FOLDER_ID}"
            response = requests.get(url, timeout=5)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            all_links = soup.find_all('a', href=True)
            pattern = re.compile(r'(\d{4}-\d{2}-\d{2})_(\d{4})\.txt')
            
            for link in all_links:
                text = link.get_text(strip=True)
                match = pattern.match(text)
                if match:
                    date = match.group(1)
                    if date not in gdrive_dates:
                        gdrive_dates[date] = 0
                    gdrive_dates[date] += 1
        except Exception as e:
            gdrive_scan_error = str(e)
        
        # è¯»å–æ—¥å¿—æ–‡ä»¶è·å–æœ€æ–°çŠ¶æ€
        log_file = '/home/user/webapp/gdrive_final_detector.log'
        latest_file = None
        latest_file_time = None
        check_count = 0
        last_file_found_time = None
        recovery_count = 0
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
                # åˆ†ææ—¥å¿—
                for line in reversed(lines[-500:]):  # åªçœ‹æœ€è¿‘500è¡Œ
                    # æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
                    if 'æœ€æ–°æ–‡ä»¶å =' in line and not latest_file:
                        match = re.search(r'æœ€æ–°æ–‡ä»¶å = (.+\.txt)', line)
                        if match:
                            latest_file = match.group(1)
                            # æå–æ—¶é—´æˆ³
                            time_match = re.search(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                            if time_match:
                                latest_file_time = time_match.group(1)
                    
                    # æŸ¥æ‰¾æ£€æŸ¥æ¬¡æ•°
                    if 'æ£€æŸ¥ #' in line:
                        match = re.search(r'æ£€æŸ¥ #(\d+)', line)
                        if match:
                            check_count = max(check_count, int(match.group(1)))
                    
                    # æŸ¥æ‰¾æ¢å¤è§¦å‘
                    if 'è§¦å‘11åˆ†é’Ÿè¶…æ—¶æ¢å¤æœºåˆ¶' in line:
                        recovery_count += 1
                    
                    # æŸ¥æ‰¾æœ€åæ‰¾åˆ°æ–‡ä»¶çš„æ—¶é—´
                    if 'æ‰¾åˆ°' in line and 'TXTæ–‡ä»¶' in line and not last_file_found_time:
                        match = re.search(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                        if match:
                            last_file_found_time = match.group(1)
        
        # è®¡ç®—è·ä¸Šæ¬¡æ‰¾åˆ°æ–‡ä»¶çš„æ—¶é—´
        time_since_last_file = 0
        if last_file_found_time:
            try:
                last_time = datetime.strptime(last_file_found_time, '%Y-%m-%d %H:%M:%S')
                last_time = beijing_tz.localize(last_time)
                time_since_last_file = (now - last_time).total_seconds()
            except:
                pass
        
        # è·å–æ•°æ®åº“è®°å½•æ•°
        db_records = 0
        try:
            import sqlite3
            conn = sqlite3.connect('databases/crypto_data.db')
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM crypto_snapshots WHERE snapshot_date = ?", (now.strftime('%Y-%m-%d'),))
            db_records = cursor.fetchone()[0]
            conn.close()
        except:
            pass
        
        # è®¡ç®—ç³»ç»Ÿè¿è¡Œæ—¶é•¿ (ä»æœ€æ—©çš„æ—¥å¿—æ—¶é—´æˆ³å¼€å§‹)
        uptime_seconds = 0
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                first_line = f.readline()
                match = re.search(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', first_line)
                if match:
                    start_time = datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S')
                    start_time = beijing_tz.localize(start_time)
                    uptime_seconds = (now - start_time).total_seconds()
        
        # ğŸ†• åˆ¤æ–­æ•°æ®æºçŠ¶æ€
        today_str = now.strftime('%Y-%m-%d')
        data_source_status = 'unknown'
        data_source_message = ''
        
        if gdrive_dates:
            latest_gdrive_date = max(gdrive_dates.keys())
            if latest_gdrive_date == today_str:
                data_source_status = 'active'
                data_source_message = f'âœ… æ•°æ®æºæ­£å¸¸ï¼Œä»Šå¤©æœ‰ {gdrive_dates[today_str]} ä¸ªæ–‡ä»¶'
            else:
                days_old = (datetime.strptime(today_str, '%Y-%m-%d') - datetime.strptime(latest_gdrive_date, '%Y-%m-%d')).days
                data_source_status = 'stale'
                data_source_message = f'âš ï¸  æ•°æ®æºå·²åœæ›´ {days_old} å¤©ï¼Œæœ€æ–°æ•°æ®ï¼š{latest_gdrive_date}'
        elif gdrive_scan_error:
            data_source_status = 'error'
            data_source_message = f'âŒ æ— æ³•è®¿é—® Google Drive: {gdrive_scan_error}'
        else:
            data_source_status = 'empty'
            data_source_message = 'âŒ Google Drive ä¸­æ²¡æœ‰ä»»ä½•æ•°æ®æ–‡ä»¶'
        
        return jsonify({
            'success': True,
            'time_since_last_file': time_since_last_file,
            'current_folder_id': config.get('folder_id', 'N/A'),
            'folder_date': config.get('current_date', '--'),
            'latest_file': latest_file or '--',
            'file_time': latest_file_time or '--',
            'gdrive_dates': gdrive_dates,  # ğŸ†• Google Drive ä¸­çš„æ—¥æœŸåˆ†å¸ƒ
            'data_source_status': data_source_status,  # ğŸ†• æ•°æ®æºçŠ¶æ€
            'data_source_message': data_source_message,  # ğŸ†• æ•°æ®æºçŠ¶æ€æ¶ˆæ¯
            'today_date': today_str,  # ğŸ†• å½“å‰æ—¥æœŸ
            'root_folder_odd': config.get('root_folder_odd', 'N/A'),  # ğŸ†• å•æ•°æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹
            'root_folder_even': config.get('root_folder_even', 'N/A'),  # ğŸ†• åŒæ•°æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹
            'recovery_count': recovery_count,
            'check_count': check_count,
            'files_found': check_count,  # ç®€åŒ–å¤„ç†
            'db_records': db_records,
            'last_update': now.strftime('%H:%M:%S'),
            'uptime_seconds': uptime_seconds,
            'current_time': now.strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== æ¯æ—¥00:10ä»»åŠ¡çŠ¶æ€ API ====================

@app.route('/daily-tasks-status')
def daily_tasks_status_page():
    """æ¯æ—¥00:10ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€é¡µé¢"""
    return render_template('daily_tasks_status.html')

@app.route('/api/daily-tasks/status')
def api_daily_tasks_status():
    """è·å–æ¯æ—¥00:10ä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€"""
    import os
    import json
    from datetime import datetime
    import pytz
    
    try:
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        today_str = now.strftime('%Y-%m-%d')
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        config = {}
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        # çˆ¶æ–‡ä»¶å¤¹æ›´æ–°ä»»åŠ¡çŠ¶æ€
        parent_folder_update = {
            'status': config.get('auto_update_status', 'pending'),
            'last_update': config.get('last_auto_update', '--'),
            'parent_folder_id': config.get('root_folder_odd') or config.get('root_folder_even', '--'),
            'child_folder_id': config.get('folder_id', '--'),
            'url': config.get('parent_folder_url', '--')
        }
        
        # æ¸…ç†ä»»åŠ¡çŠ¶æ€
        cleanup = {
            'last_cleanup': config.get('last_cleanup', None),
            'cleanup_reason': config.get('cleanup_reason', '--'),
            'root_folder_odd': config.get('root_folder_odd'),
            'root_folder_even': config.get('root_folder_even')
        }
        
        return jsonify({
            'success': True,
            'today_date': today_str,
            'parent_folder_update': parent_folder_update,
            'cleanup': cleanup
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/daily-tasks/logs')
def api_daily_tasks_logs():
    """è·å–æ¯æ—¥ä»»åŠ¡çš„æ‰§è¡Œæ—¥å¿—"""
    import os
    
    try:
        log_file = '/home/user/webapp/parent_folder_update.log'
        logs = []
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # åªè¿”å›æœ€è¿‘100è¡Œ
                logs = [line.rstrip() for line in lines[-100:]]
        
        return jsonify({
            'success': True,
            'logs': logs
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== æ–‡ä»¶å¤¹æ›´æ–°ç›‘æ§ API ====================

@app.route('/folder-update-monitor')
def folder_update_monitor():
    """æ–‡ä»¶å¤¹æ›´æ–°ç›‘æ§é¡µé¢"""
    return render_template('folder_update_monitor.html')

@app.route('/api/folder-update-status')
def api_folder_update_status():
    """è·å–æ–‡ä»¶å¤¹æ›´æ–°çŠ¶æ€"""
    import os
    import json
    
    try:
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        today_str = now.strftime('%Y-%m-%d')
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        config = {}
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        config_date = config.get('current_date', 'unknown')
        need_update = config_date != today_str
        
        return jsonify({
            'success': True,
            'data': {
                'config_date': config_date,
                'today_date': today_str,
                'folder_id': config.get('folder_id', 'N/A'),
                'latest_txt': config.get('latest_txt', 'N/A'),
                'txt_count': config.get('txt_count', 0),
                'last_updated': config.get('last_updated', 'N/A'),
                'need_update': need_update,
                'message': 'é…ç½®æ—¥æœŸä¸ä»Šå¤©ä¸åŒ¹é…' if need_update else 'é…ç½®æ­£å¸¸'
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

@app.route('/api/trigger-folder-update', methods=['POST'])
def api_trigger_folder_update():
    """è§¦å‘æ–‡ä»¶å¤¹æ›´æ–°"""
    import subprocess
    import os
    
    try:
        script_path = '/home/user/webapp/auto_update_today_folder.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'message': 'æ›´æ–°è„šæœ¬ä¸å­˜åœ¨'
            }), 404
        
        # æ‰§è¡Œæ›´æ–°è„šæœ¬
        result = subprocess.run(
            ['python3', script_path],
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode == 0:
            # è¯»å–æ›´æ–°åçš„é…ç½®
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            return jsonify({
                'success': True,
                'data': {
                    'folder_id': config.get('folder_id'),
                    'date': config.get('current_date'),
                    'latest_txt': config.get('latest_txt'),
                    'txt_count': config.get('txt_count', 0)
                },
                'message': 'æ›´æ–°æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': f'æ›´æ–°å¤±è´¥: {result.stderr}'
            }), 500
            
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'message': 'æ›´æ–°è¶…æ—¶ï¼ˆ60ç§’ï¼‰'
        }), 500
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

@app.route('/api/list-recent-folders')
def api_list_recent_folders():
    """åˆ—å‡ºæœ€è¿‘çš„æ–‡ä»¶å¤¹"""
    import requests
    from bs4 import BeautifulSoup
    import re
    
    try:
        parent_folder_id = "1j8YV6KysUCmgcmASFOxztWWIE1Vq-kYV"
        url = f"https://drive.google.com/embeddedfolderview?id={parent_folder_id}"
        
        response = requests.get(url, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        folders = []
        all_links = soup.find_all('a', href=True)
        
        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)
            
            if '/folders/' in href:
                match = re.search(r'/folders/([a-zA-Z0-9_-]+)', href)
                if match:
                    folder_id = match.group(1)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸæ–‡ä»¶å¤¹
                    if re.search(r'\d{4}-\d{2}-\d{2}', text):
                        folders.append({
                            'name': text,
                            'id': folder_id
                        })
        
        # æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        folders.sort(key=lambda x: x['name'], reverse=True)
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        today = datetime.now(beijing_tz).strftime('%Y-%m-%d')
        
        return jsonify({
            'success': True,
            'data': {
                'folders': folders[:10],  # åªè¿”å›æœ€è¿‘10ä¸ª
                'today': today
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

@app.route('/api/get-update-log')
def api_get_update_log():
    """è·å–æ›´æ–°æ—¥å¿—"""
    import os
    
    try:
        log_file = '/home/user/webapp/auto_update_folder.log'
        log_content = ''
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # åªè¿”å›æœ€è¿‘200è¡Œ
                log_content = ''.join(lines[-200:])
        
        return jsonify({
            'success': True,
            'data': {
                'log': log_content or 'æš‚æ— æ—¥å¿—'
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

# æ—§çš„telegram-dashboardè·¯ç”±å·²åºŸå¼ƒï¼Œä½¿ç”¨ä¸‹æ–¹æ–°ç‰ˆæœ¬
# @app.route('/telegram-dashboard')
# def telegram_dashboard():
#     """Telegramä¿¡å·æ¨é€ç³»ç»Ÿç›‘æ§é¢æ¿"""
#     import time
#     cache_buster = int(time.time())
#     return render_template('telegram_dashboard.html', cache_buster=cache_buster)

@app.route('/api/telegram/status')
def telegram_status():
    """è·å–Telegramç›‘æ§ç³»ç»ŸçŠ¶æ€"""
    try:
        import subprocess
        import os
        
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿è¡Œï¼ˆæ£€æŸ¥telegram_signal_system.pyè€Œä¸æ˜¯tg_signal_monitor.pyï¼‰
        result = subprocess.run(
            ['pgrep', '-f', 'telegram_signal_system.py'],
            capture_output=True,
            text=True
        )
        
        is_running = bool(result.stdout.strip())
        pid = result.stdout.strip() if is_running else None
        
        # è·å–æ•°æ®åº“ç»Ÿè®¡
        db_stats = {}
        if os.path.exists('tg_signals.db'):
            conn = sqlite3.connect('tg_signals.db', timeout=5.0)
            cursor = conn.cursor()
            
            # è·å–æ€»å‘é€æ•°
            cursor.execute("SELECT COUNT(*) FROM signal_history")
            total_sent = cursor.fetchone()[0]
            
            # è·å–æœ€è¿‘1å°æ—¶å‘é€æ•°
            cursor.execute("""
                SELECT COUNT(*) FROM signal_history 
                WHERE sent_time >= datetime('now', '-1 hour', 'localtime')
            """)
            sent_1h = cursor.fetchone()[0]
            
            # è·å–ä»Šå¤©å‘é€æ•°
            cursor.execute("""
                SELECT COUNT(*) FROM signal_history 
                WHERE date(sent_time) = date('now', 'localtime')
            """)
            sent_today = cursor.fetchone()[0]
            
            # è·å–å„ç±»ä¿¡å·ç»Ÿè®¡
            cursor.execute("""
                SELECT signal_type, COUNT(*) as count
                FROM signal_history
                GROUP BY signal_type
            """)
            signal_counts = dict(cursor.fetchall())
            
            # è·å–æœ€æ–°å‘é€æ—¶é—´
            cursor.execute("""
                SELECT sent_time FROM signal_history 
                ORDER BY created_at DESC LIMIT 1
            """)
            last_sent = cursor.fetchone()
            last_sent_time = last_sent[0] if last_sent else None
            
            conn.close()
            
            db_stats = {
                'total_sent': total_sent,
                'sent_1h': sent_1h,
                'sent_today': sent_today,
                'signal_counts': signal_counts,
                'last_sent_time': last_sent_time
            }
        
        # è¿”å›æ‰å¹³åŒ–çš„æ•°æ®ç»“æ„ï¼Œç¬¦åˆå‰ç«¯æœŸå¾…çš„æ ¼å¼
        return jsonify({
            'success': True,
            'is_running': is_running,
            'pid': pid,
            'status': 'è¿è¡Œä¸­' if is_running else 'æœªè¿è¡Œ',
            'total_sent': db_stats.get('total_sent', 0),
            'sent_1h': db_stats.get('sent_1h', 0),
            'sent_today': db_stats.get('sent_today', 0),
            'last_sent_time': db_stats.get('last_sent_time'),
            'last_update': db_stats.get('last_sent_time', 'æœªçŸ¥'),
            'signal_counts': signal_counts,
            'last_messages': [],  # å‰ç«¯éœ€è¦çš„å­—æ®µ
            # åŒæ—¶ä¿ç•™åµŒå¥—æ ¼å¼ä»¥å…¼å®¹å…¶ä»–å¯èƒ½çš„è°ƒç”¨
            'data': {
                'is_running': is_running,
                'pid': pid,
                'database_stats': db_stats
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/telegram/history')
def telegram_history():
    """è·å–Telegramä¿¡å·å‘é€å†å²"""
    try:
        import os
        
        if not os.path.exists('tg_signals.db'):
            return jsonify({
                'success': False,
                'error': 'æ•°æ®åº“ä¸å­˜åœ¨'
            }), 404
        
        # è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', 1, type=int)
        limit = request.args.get('limit', 50, type=int)
        signal_type = request.args.get('type', '')
        
        conn = sqlite3.connect('tg_signals.db', timeout=5.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        where_clause = ""
        params = []
        if signal_type:
            where_clause = "WHERE signal_type = ?"
            params.append(signal_type)
        
        # è·å–æ€»æ•°
        cursor.execute(f"SELECT COUNT(*) FROM signal_history {where_clause}", params)
        total = cursor.fetchone()[0]
        
        # è·å–åˆ†é¡µæ•°æ®
        offset = (page - 1) * limit
        cursor.execute(f"""
            SELECT id, signal_type, symbol, signal_name, signal_data, sent_time, created_at
            FROM signal_history
            {where_clause}
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """, params + [limit, offset])
        
        records = []
        for row in cursor.fetchall():
            records.append({
                'id': row['id'],
                'signal_type': row['signal_type'],
                'symbol': row['symbol'],
                'signal_name': row['signal_name'],
                'signal_data': row['signal_data'],
                'sent_time': row['sent_time'],
                'created_at': row['created_at']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'records': records,
                'total': total,
                'page': page,
                'limit': limit,
                'pages': (total + limit - 1) // limit
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/coins/realtime-status')
def api_coins_realtime_status():
    """
    è·å–æ‰€æœ‰å¸ç§çš„å®æ—¶çŠ¶æ€
    åŒ…æ‹¬ï¼šå½“å‰ä»·æ ¼ï¼ˆæ¥è‡ªæœ€æ–°Kçº¿ï¼‰ã€7å¤©é«˜ä½ç‚¹ã€æ¶¨è·Œå¹…ã€äº¤æ˜“ä¿¡å·åŠå‘ç”Ÿæ—¶é—´
    """
    try:
        import pytz
        conn = sqlite3.connect('crypto_data.db', timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        
        # å®šä¹‰27ä¸ªå¸ç§
        symbols = [
            'AAVE', 'APT', 'BCH', 'BNB', 'BTC', 'CRV', 'DOGE', 'DOT', 'ETC', 'ETH', 'FIL',
            'HBAR', 'LDO', 'LINK', 'LTC', 'NEAR', 'SOL', 'SUI', 'TAO', 'TON', 'TRX',
            'XLM', 'XRP', 'CFX', 'CRO', 'STX', 'UNI'
        ]
        
        results = []
        
        for symbol_short in symbols:
            symbol = f"{symbol_short}-USDT-SWAP"
            
            # 1. è·å–æœ€æ–°Kçº¿æ•°æ®ï¼ˆå½“å‰ä»·æ ¼ï¼‰
            cursor.execute('''
                SELECT timestamp, close, open
                FROM okex_kline_ohlc
                WHERE symbol = ? AND timeframe = '5m'
                ORDER BY timestamp DESC
                LIMIT 1
            ''', (symbol,))
            latest_kline = cursor.fetchone()
            
            if not latest_kline:
                continue
            
            current_price = latest_kline['close']
            open_price = latest_kline['open']
            latest_time = datetime.fromtimestamp(latest_kline['timestamp'] / 1000, tz=beijing_tz)
            
            # è®¡ç®—æ¶¨è·Œå¹…
            change_pct = ((current_price - open_price) / open_price * 100) if open_price > 0 else 0
            
            # 2. è·å–7å¤©é«˜ä½ç‚¹
            cursor.execute('''
                SELECT MAX(high) as high_7d, MIN(low) as low_7d
                FROM okex_kline_ohlc
                WHERE symbol = ? AND timeframe = '5m'
                AND timestamp >= ?
            ''', (symbol, int((datetime.now() - timedelta(days=7)).timestamp() * 1000)))
            extremes = cursor.fetchone()
            
            high_7d = extremes['high_7d'] if extremes and extremes['high_7d'] else current_price
            low_7d = extremes['low_7d'] if extremes and extremes['low_7d'] else current_price
            
            # 3. æ£€æŸ¥æœ€è¿‘2å°æ—¶çš„äº¤æ˜“ä¿¡å·
            two_hours_ago = datetime.now(beijing_tz) - timedelta(hours=2)
            
            cursor.execute('''
                SELECT record_time, long_signals, short_signals, today_new_high, today_new_low
                FROM trading_signals
                WHERE record_time >= ?
                ORDER BY record_time DESC
                LIMIT 1
            ''', (two_hours_ago.strftime('%Y-%m-%d %H:%M:%S'),))
            signal_row = cursor.fetchone()
            
            signal_type = None
            signal_time = None
            
            if signal_row:
                signal_time_dt = datetime.strptime(signal_row['record_time'], '%Y-%m-%d %H:%M:%S')
                signal_time_dt = beijing_tz.localize(signal_time_dt)
                signal_time = signal_time_dt.strftime('%m-%d %H:%M')
                
                # åˆ¤æ–­ä¿¡å·ç±»å‹
                if signal_row['long_signals'] > 0 or signal_row['today_new_low'] > 0:
                    signal_type = 'buy'
                elif signal_row['short_signals'] > 0 or signal_row['today_new_high'] > 0:
                    signal_type = 'sell'
            
            results.append({
                'symbol': symbol_short,
                'current_price': current_price,
                'high_7d': high_7d,
                'low_7d': low_7d,
                'change_pct': change_pct,
                'signal_type': signal_type,  # 'buy' or 'sell' or None
                'signal_time': signal_time,  # Kçº¿æ—¶é—´ï¼Œæ ¼å¼ï¼š'MM-DD HH:MM'
                'latest_update': latest_time.strftime('%Y-%m-%d %H:%M:%S')
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': results,
            'count': len(results),
            'timestamp': datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/sell-point-1/save', methods=['POST'])
def api_sell_point_1_save():
    """
    ä¿å­˜å–ç‚¹1ä¿¡å·åˆ°æ•°æ®åº“
    
    è¯·æ±‚ä½“æ ¼å¼:
    {
        "symbol": "BTC",
        "high_price": 90000.0,
        "high_time": "2025-12-15 14:30:00",
        "high_index": 1000,
        "mark_price": 89500.0,
        "mark_time": "2025-12-15 15:00:00",
        "mark_index": 1006,
        "mark_rsi": 65.5
    }
    """
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['symbol', 'high_price', 'high_time', 'high_index', 
                          'mark_price', 'mark_time', 'mark_index', 'mark_rsi']
        for field in required_fields:
            if field not in data:
                return jsonify({
                    'success': False,
                    'error': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}'
                }), 400
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ä¿¡å·ï¼ˆé¿å…é‡å¤æ’å…¥ï¼‰
        cursor.execute('''
            SELECT id FROM sell_point_1_signals
            WHERE symbol = ? AND mark_time = ? AND is_valid = 1
        ''', (data['symbol'], data['mark_time']))
        
        existing = cursor.fetchone()
        if existing:
            conn.close()
            return jsonify({
                'success': True,
                'message': 'ä¿¡å·å·²å­˜åœ¨',
                'signal_id': existing[0]
            })
        
        # æ’å…¥æ–°ä¿¡å·
        now = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('''
            INSERT INTO sell_point_1_signals (
                symbol, high_price, high_time, high_index,
                mark_price, mark_time, mark_index, mark_rsi,
                signal_generated_at, is_valid
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, 1)
        ''', (
            data['symbol'],
            data['high_price'],
            data['high_time'],
            data['high_index'],
            data['mark_price'],
            data['mark_time'],
            data['mark_index'],
            data['mark_rsi'],
            now
        ))
        
        signal_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': 'å–ç‚¹1ä¿¡å·ä¿å­˜æˆåŠŸ',
            'signal_id': signal_id
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/sell-point-1/latest')
def api_sell_point_1_latest():
    """
    è·å–æœ€æ–°çš„å–ç‚¹1ä¿¡å·
    
    å‚æ•°:
        - symbol: å¸ç§ï¼ˆå¯é€‰ï¼Œå¦‚BTCï¼‰
        - hours: æ—¶é—´èŒƒå›´ï¼ˆå¯é€‰ï¼Œé»˜è®¤24å°æ—¶ï¼‰
    """
    try:
        symbol = request.args.get('symbol')
        hours = int(request.args.get('hours', 24))
        
        conn = sqlite3.connect('databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        beijing_tz = pytz.timezone('Asia/Shanghai')
        cutoff_time = (datetime.now(beijing_tz) - timedelta(hours=hours)).strftime('%Y-%m-%d %H:%M:%S')
        
        if symbol:
            cursor.execute('''
                SELECT * FROM sell_point_1_signals
                WHERE symbol = ? AND mark_time >= ? AND is_valid = 1
                ORDER BY mark_time DESC
            ''', (symbol, cutoff_time))
        else:
            cursor.execute('''
                SELECT * FROM sell_point_1_signals
                WHERE mark_time >= ? AND is_valid = 1
                ORDER BY mark_time DESC
            ''', (cutoff_time,))
        
        rows = cursor.fetchall()
        conn.close()
        
        signals = []
        for row in rows:
            signals.append({
                'id': row['id'],
                'symbol': row['symbol'],
                'high_price': row['high_price'],
                'high_time': row['high_time'],
                'high_index': row['high_index'],
                'mark_price': row['mark_price'],
                'mark_time': row['mark_time'],
                'mark_index': row['mark_index'],
                'mark_rsi': row['mark_rsi'],
                'signal_generated_at': row['signal_generated_at'],
                'created_at': row['created_at']
            })
        
        return jsonify({
            'success': True,
            'data': signals,
            'count': len(signals),
            'timestamp': datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/telegram-dashboard')
def telegram_dashboard():
    """Telegramä¿¡å·æ¨é€ç³»ç»Ÿä»ªè¡¨æ¿"""
    return render_template('telegram_signal_dashboard.html')

@app.route('/cache-help')
def cache_help():
    """ç¼“å­˜æ¸…é™¤å¸®åŠ©é¡µé¢"""
    return render_template('cache_clear_guide.html')

@app.route('/api/telegram/signals/support-resistance')
def api_telegram_support_resistance():
    """è·å–æ”¯æ’‘å‹åŠ›çº¿ä¿¡å·ï¼ˆ2å°æ—¶å†…ï¼‰"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        # è·å–2å°æ—¶å†…çš„ä¿¡å·
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT signal_type, symbol, price, signal_time, sent_at
            FROM support_resistance_signals
            WHERE sent_at >= ?
            ORDER BY sent_at DESC
        ''', (two_hours_ago,))
        
        signals = []
        for row in cursor.fetchall():
            signals.append({
                'signal_type': row[0],
                'symbol': row[1],
                'price': row[2],
                'signal_time': row[3],
                'sent_at': row[4]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'signals': signals,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/signals/count-alerts')
def api_telegram_count_alerts():
    """è·å–è®¡æ¬¡é¢„è­¦ï¼ˆ2å°æ—¶å†…ï¼‰"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT record_time, count_value, threshold, full_data, sent_at
            FROM count_alerts
            WHERE sent_at >= ?
            ORDER BY sent_at DESC
        ''', (two_hours_ago,))
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'record_time': row[0],
                'count_value': row[1],
                'threshold': row[2],
                'full_data': row[3],
                'sent_at': row[4]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'alerts': alerts,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/signals/trading')
def api_telegram_trading():
    """è·å–äº¤æ˜“ä¿¡å·ï¼ˆ2å°æ—¶å†…ï¼‰"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT signal_type, symbol, price, signal_time, rsi, sent_at
            FROM trading_signals
            WHERE sent_at >= ?
            ORDER BY sent_at DESC
        ''', (two_hours_ago,))
        
        signals = []
        for row in cursor.fetchall():
            signals.append({
                'signal_type': row[0],
                'symbol': row[1],
                'price': row[2],
                'signal_time': row[3],
                'rsi': row[4],
                'sent_at': row[5]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'signals': signals,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/signals/stats')
def api_telegram_stats():
    """è·å–å‘é€ç»Ÿè®¡"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        # æ€»å‘é€æ•°
        cursor.execute('SELECT COUNT(*) FROM support_resistance_signals')
        support_count = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM count_alerts')
        alert_count = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM trading_signals')
        trade_count = cursor.fetchone()[0]
        total = support_count + alert_count + trade_count
        
        # æœ€è¿‘1å°æ—¶
        one_hour_ago = (datetime.now() - timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('SELECT COUNT(*) FROM support_resistance_signals WHERE sent_at >= ?', (one_hour_ago,))
        support_1h = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM count_alerts WHERE sent_at >= ?', (one_hour_ago,))
        alert_1h = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM trading_signals WHERE sent_at >= ?', (one_hour_ago,))
        trade_1h = cursor.fetchone()[0]
        last_hour = support_1h + alert_1h + trade_1h
        
        # ä»Šæ—¥å‘é€
        today_start = datetime.now().strftime('%Y-%m-%d 00:00:00')
        cursor.execute('SELECT COUNT(*) FROM support_resistance_signals WHERE sent_at >= ?', (today_start,))
        support_today = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM count_alerts WHERE sent_at >= ?', (today_start,))
        alert_today = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM trading_signals WHERE sent_at >= ?', (today_start,))
        trade_today = cursor.fetchone()[0]
        today = support_today + alert_today + trade_today
        
        # æœ€åæ¨é€æ—¶é—´
        cursor.execute('''
            SELECT MAX(sent_at) FROM (
                SELECT sent_at FROM support_resistance_signals
                UNION ALL
                SELECT sent_at FROM count_alerts
                UNION ALL
                SELECT sent_at FROM trading_signals
            )
        ''')
        last_time = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'total': total,
            'last_hour': last_hour,
            'today': today,
            'last_time': last_time
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/system/status')
def api_telegram_system_status():
    """è·å–Telegramæ¨é€ç³»ç»ŸçŠ¶æ€"""
    try:
        import subprocess
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿è¡Œ
        result = subprocess.run(['pgrep', '-f', 'telegram_signal_system.py'], 
                               capture_output=True, text=True)
        is_running = bool(result.stdout.strip())
        pid = result.stdout.strip() if is_running else None
        
        return jsonify({
            'success': True,
            'running': is_running,
            'pid': pid,
            'message': 'ç³»ç»Ÿè¿è¡Œä¸­' if is_running else 'ç³»ç»Ÿæœªè¿è¡Œ'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/start', methods=['POST'])
def api_telegram_start():
    """å¯åŠ¨Telegramæ¨é€ç³»ç»Ÿ"""
    try:
        import subprocess
        result = subprocess.run(['./start_telegram_signal_system.sh'], 
                               capture_output=True, text=True, cwd='/home/user/webapp')
        return jsonify({
            'success': True,
            'message': 'ç³»ç»Ÿå·²å¯åŠ¨',
            'output': result.stdout
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/stop', methods=['POST'])
def api_telegram_stop():
    """åœæ­¢Telegramæ¨é€ç³»ç»Ÿ"""
    try:
        import subprocess
        result = subprocess.run(['./stop_telegram_signal_system.sh'], 
                               capture_output=True, text=True, cwd='/home/user/webapp')
        return jsonify({
            'success': True,
            'message': 'ç³»ç»Ÿå·²åœæ­¢',
            'output': result.stdout
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/query/latest')
def api_query_latest():
    """è·å–æœ€æ–°æŸ¥è¯¢æ•°æ®APIï¼ˆç”¨äºè®¡æ¬¡é¢„è­¦ï¼‰"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                snapshot_time, rush_up, rush_down, diff, count, ratio, status,
                round_rush_up, round_rush_down, price_lowest, price_newhigh,
                count_score_display, rise_24h_count, fall_24h_count
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 1
        """)
        
        snapshot = cursor.fetchone()
        conn.close()
        
        if not snapshot:
            return jsonify({'success': False, 'error': 'æš‚æ— æ•°æ®'})
        
        return jsonify({
            'success': True,
            'data': {
                'è¿ç®—æ—¶é—´': snapshot[0],
                'æ€¥æ¶¨': snapshot[1],
                'æ€¥è·Œ': snapshot[2],
                'å·®å€¼': snapshot[3],
                'è®¡æ¬¡': snapshot[4],
                'æ¯”å€¼': snapshot[5],
                'çŠ¶æ€': snapshot[6],
                'æœ¬è½®æ€¥æ¶¨': snapshot[7],
                'æœ¬è½®æ€¥è·Œ': snapshot[8],
                'æ¯”ä»·æœ€ä½': snapshot[9],
                'æ¯”ä»·åˆ›æ–°é«˜': snapshot[10],
                'è®¡æ¬¡å¾—åˆ†': snapshot[11],
                '24hæ¶¨â‰¥10%': snapshot[12],
                '24hè·Œâ‰¤-10%': snapshot[13]
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/support-resistance/export', methods=['POST'])
def api_support_resistance_export():
    """å¯¼å‡ºæ”¯æ’‘é˜»åŠ›ä½æ•°æ®"""
    try:
        import subprocess
        import os
        
        script_path = '/home/user/webapp/export_support_resistance_data.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'å¯¼å‡ºè„šæœ¬ä¸å­˜åœ¨'
            })
        
        # æ‰§è¡Œå¯¼å‡ºè„šæœ¬
        result = subprocess.run(
            ['python3', script_path],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode != 0:
            return jsonify({
                'success': False,
                'error': 'å¯¼å‡ºå¤±è´¥',
                'output': result.stderr
            })
        
        # ä»è¾“å‡ºä¸­æå–å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        export_file = None
        for line in result.stdout.split('\n'):
            if 'å¯¼å‡ºæ–‡ä»¶:' in line:
                export_file = line.split('å¯¼å‡ºæ–‡ä»¶:')[-1].strip()
                break
        
        if not export_file or not os.path.exists(export_file):
            return jsonify({
                'success': False,
                'error': 'æ‰¾ä¸åˆ°å¯¼å‡ºæ–‡ä»¶'
            })
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(export_file)
        file_size_mb = file_size / (1024 * 1024)
        filename = os.path.basename(export_file)
        
        return jsonify({
            'success': True,
            'message': 'å¯¼å‡ºæˆåŠŸ',
            'file_path': export_file,
            'filename': filename,
            'file_size': file_size,
            'file_size_mb': round(file_size_mb, 2),
            'download_url': f'/api/support-resistance/download/{filename}'
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'error': 'å¯¼å‡ºè¶…æ—¶'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/support-resistance/download/<filename>')
def api_support_resistance_download(filename):
    """ä¸‹è½½å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶"""
    try:
        export_dir = '/home/user/webapp/exports'
        file_path = os.path.join(export_dir, filename)
        
        if not os.path.exists(file_path):
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        return send_from_directory(export_dir, filename, as_attachment=True)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/support-resistance/import', methods=['POST'])
def api_support_resistance_import():
    """å¯¼å…¥æ”¯æ’‘é˜»åŠ›ä½æ•°æ®"""
    try:
        import subprocess
        import os
        from werkzeug.utils import secure_filename
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¼ çš„æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'
            })
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶åä¸ºç©º'
            })
        
        # æ£€æŸ¥æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®
        clear_existing = request.form.get('clear_existing', 'false').lower() == 'true'
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        filename = secure_filename(file.filename)
        upload_dir = '/home/user/webapp/uploads'
        os.makedirs(upload_dir, exist_ok=True)
        
        file_path = os.path.join(upload_dir, filename)
        file.save(file_path)
        
        # æ‰§è¡Œå¯¼å…¥è„šæœ¬
        script_path = '/home/user/webapp/import_support_resistance_data.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'å¯¼å…¥è„šæœ¬ä¸å­˜åœ¨'
            })
        
        # æ„å»ºå‘½ä»¤
        cmd = ['python3', script_path, file_path]
        if clear_existing:
            cmd.append('--clear')
        
        # æ‰§è¡Œå¯¼å…¥
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300
        )
        
        # åˆ é™¤ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(file_path)
        except:
            pass
        
        if result.returncode != 0:
            return jsonify({
                'success': False,
                'error': 'å¯¼å…¥å¤±è´¥',
                'output': result.stderr or result.stdout
            })
        
        # ä»è¾“å‡ºä¸­æå–ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'tables': 0,
            'records': 0
        }
        
        for line in result.stdout.split('\n'):
            if 'è¡¨æ•°é‡:' in line:
                try:
                    stats['tables'] = int(line.split(':')[-1].strip())
                except:
                    pass
            elif 'æ€»è®°å½•æ•°:' in line:
                try:
                    stats['records'] = int(line.split(':')[-1].strip().replace(',', ''))
                except:
                    pass
        
        return jsonify({
            'success': True,
            'message': 'å¯¼å…¥æˆåŠŸ',
            'stats': stats,
            'output': result.stdout
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'error': 'å¯¼å…¥è¶…æ—¶'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/query/batch-import', methods=['POST'])
def api_query_batch_import():
    """æ‰¹é‡å¯¼å…¥å½“å¤©æ‰€æœ‰TXTæ–‡ä»¶æ•°æ®"""
    try:
        import subprocess
        import os
        
        # æ‰§è¡Œæ‰¹é‡å¯¼å…¥è„šæœ¬
        script_path = '/home/user/webapp/batch_import_daily_txt.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'æ‰¹é‡å¯¼å…¥è„šæœ¬ä¸å­˜åœ¨'
            })
        
        # ä½¿ç”¨subprocessè¿è¡Œè„šæœ¬
        result = subprocess.run(
            ['python3', script_path],
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        # è§£æè¾“å‡ºç»“æœ
        output_lines = result.stdout.split('\n')
        
        # æå–ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total': 0,
            'success': 0,
            'exists': 0,
            'invalid': 0,
            'error': 0
        }
        
        for line in output_lines:
            if 'æ€»æ–‡ä»¶æ•°:' in line:
                stats['total'] = int(line.split(':')[-1].strip())
            elif 'æˆåŠŸå¯¼å…¥:' in line:
                stats['success'] = int(line.split(':')[-1].strip())
            elif 'å·²å­˜åœ¨:' in line:
                stats['exists'] = int(line.split(':')[-1].strip())
            elif 'æ— æ•ˆæ•°æ®:' in line:
                stats['invalid'] = int(line.split(':')[-1].strip())
            elif 'å¤±è´¥:' in line and 'âŒ' in line:
                stats['error'] = int(line.split(':')[-1].strip())
        
        return jsonify({
            'success': True,
            'message': 'æ‰¹é‡å¯¼å…¥å®Œæˆ',
            'stats': stats,
            'output': result.stdout
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'error': 'æ‰¹é‡å¯¼å…¥è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/test-simple')
def test_simple():
    """ç®€å•æµ‹è¯•é¡µé¢ - éªŒè¯window.onloadå’ŒEChartsåŸºç¡€åŠŸèƒ½"""
    return render_template('test_simple.html')

@app.route('/api/chart-config')
def chart_config():
    """è·å–Kçº¿å›¾é…ç½®URL"""
    return jsonify({
        'success': True,
        'chart_base_url': CHART_BASE_URL,
        'example': f"{CHART_BASE_URL}/chart/BTC"
    })

@app.route('/gdrive-config')
def gdrive_config():
    """Google Driveé…ç½®ç®¡ç†é¡µé¢"""
    return render_template('gdrive_config.html')

@app.route('/api/gdrive-config/get')
def gdrive_config_get():
    """è·å–å½“å‰Google Driveé…ç½®"""
    try:
        import json
        config_file = '/home/user/webapp/daily_folder_config.json'
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/gdrive-config/update', methods=['POST'])
def gdrive_config_update():
    """æ›´æ–°Google Driveæ–‡ä»¶å¤¹é…ç½®"""
    try:
        import json
        from datetime import datetime
        
        data = request.get_json()
        parent_folder_url = data.get('parent_folder_url', '')
        
        if not parent_folder_url:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›Google Driveæ–‡ä»¶å¤¹é“¾æ¥'
            }), 400
        
        # æå–æ–‡ä»¶å¤¹ID
        import re
        folder_id_match = re.search(r'/folders/([a-zA-Z0-9_-]+)', parent_folder_url)
        if not folder_id_match:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•ä»é“¾æ¥ä¸­æå–æ–‡ä»¶å¤¹IDï¼Œè¯·æ£€æŸ¥é“¾æ¥æ ¼å¼'
            }), 400
        
        root_folder_id = folder_id_match.group(1)
        
        # è¯»å–ç°æœ‰é…ç½®
        config_file = '/home/user/webapp/daily_folder_config.json'
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except:
            config = {}
        
        # æ›´æ–°é…ç½®
        beijing_time = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        today = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d')
        
        # æ ¹æ®æ—¥æœŸåˆ¤æ–­æ˜¯å•æ•°è¿˜æ˜¯åŒæ•°
        day_of_month = datetime.now(BEIJING_TZ).day
        is_odd_day = day_of_month % 2 == 1
        
        if is_odd_day:
            config['root_folder_odd'] = root_folder_id
        else:
            config['root_folder_even'] = root_folder_id
        
        config['parent_folder_url'] = parent_folder_url
        config['last_manual_update'] = beijing_time
        config['last_updated'] = beijing_time
        config['update_reason'] = f'æ‰‹åŠ¨æ›´æ–°{"å•æ•°" if is_odd_day else "åŒæ•°"}æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹'
        
        # ä¿å­˜é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': f'é…ç½®å·²æ›´æ–° ({"å•æ•°" if is_odd_day else "åŒæ•°"}æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹)',
            'config': config
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/gdrive-config/manual-trigger', methods=['POST'])
def gdrive_manual_trigger():
    """æ‰‹åŠ¨è§¦å‘æ•°æ®é‡‡é›†"""
    try:
        import subprocess
        import os
        
        # è¿è¡Œgdrive_final_detector.pyä¸€æ¬¡
        script_path = '/home/user/webapp/gdrive_final_detector.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': f'è„šæœ¬ä¸å­˜åœ¨: {script_path}'
            }), 404
        
        # åœ¨åå°è¿è¡Œä¸€æ¬¡æ£€æµ‹
        process = subprocess.Popen(
            ['python3', script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd='/home/user/webapp'
        )
        
        # ç­‰å¾…æœ€å¤š5ç§’
        try:
            stdout, stderr = process.communicate(timeout=5)
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨è§¦å‘æˆåŠŸï¼Œæ•°æ®é‡‡é›†å·²å¼€å§‹',
                'output': stdout.decode('utf-8', errors='ignore')[:500]
            })
        except subprocess.TimeoutExpired:
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨è§¦å‘æˆåŠŸï¼Œæ•°æ®é‡‡é›†æ­£åœ¨åå°è¿è¡Œ'
            })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/gdrive-config/latest-data')
def gdrive_latest_data():
    """è·å–æœ€æ–°æ•°æ®æ—¶é—´å’ŒçŠ¶æ€"""
    try:
        import sqlite3
        from datetime import datetime
        
        db_path = '/home/user/webapp/crypto_data.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°æ•°æ®
        cursor.execute("""
            SELECT snapshot_time, rush_up, rush_down, count, status, created_at
            FROM crypto_snapshots
            ORDER BY created_at DESC
            LIMIT 1
        """)
        
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return jsonify({
                'success': True,
                'has_data': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        snapshot_time = result[0]
        created_at = result[5]
        
        # è®¡ç®—å»¶è¿Ÿï¼ˆåˆ†é’Ÿï¼‰
        now = datetime.now(BEIJING_TZ)
        try:
            snapshot_dt = datetime.strptime(snapshot_time, '%Y-%m-%d %H:%M:%S')
            snapshot_dt = BEIJING_TZ.localize(snapshot_dt)
        except:
            snapshot_dt = datetime.strptime(snapshot_time, '%Y-%m-%d %H:%M:%S.%f')
            snapshot_dt = BEIJING_TZ.localize(snapshot_dt)
        
        delay_minutes = (now - snapshot_dt).total_seconds() / 60
        
        return jsonify({
            'success': True,
            'has_data': True,
            'data': {
                'snapshot_time': snapshot_time,
                'rush_up': result[1],
                'rush_down': result[2],
                'count': result[3],
                'status': result[4],
                'created_at': created_at,
                'delay_minutes': round(delay_minutes, 1)
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== SARæ–œç‡ç³»ç»Ÿ API ====================

@app.route('/sar-slope')
def sar_slope_page():
    """SARæ–œç‡ç³»ç»Ÿé¡µé¢"""
    return render_template('sar_slope.html')

@app.route('/api/sar-slope/latest')
def api_sar_slope_latest():
    """è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°SARæ–œç‡æ•°æ®"""
    try:
        symbol_filter = request.args.get('symbol', '').upper()
        position_filter = request.args.get('position', '')  # bullish/bearish
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æ¯ä¸ªå¸ç§çš„æœ€æ–°è®°å½•
        query = """
            SELECT 
                s.symbol,
                s.datetime_beijing,
                s.sar_value,
                s.sar_position,
                s.sar_quadrant,
                s.position_duration,
                s.slope_value,
                s.slope_direction,
                s.price_close,
                s.timestamp
            FROM sar_slope_data s
            INNER JOIN (
                SELECT symbol, MAX(timestamp) as max_timestamp
                FROM sar_slope_data
                GROUP BY symbol
            ) latest ON s.symbol = latest.symbol AND s.timestamp = latest.max_timestamp
        """
        
        conditions = []
        params = []
        
        if symbol_filter:
            conditions.append("s.symbol LIKE ?")
            params.append(f"%{symbol_filter}%")
        
        if position_filter:
            conditions.append("s.sar_position = ?")
            params.append(position_filter)
        
        if conditions:
            query += " WHERE " + " AND ".join(conditions)
        
        query += " ORDER BY s.symbol"
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            results.append({
                'symbol': row[0],
                'datetime': row[1],
                'sar_value': round(row[2], 6) if row[2] else None,
                'sar_position': row[3],
                'sar_quadrant': row[4],
                'position_duration': row[5],
                'slope_value': round(row[6], 4) if row[6] else None,
                'slope_direction': row[7],
                'price': round(row[8], 6) if row[8] else None,
                'timestamp': row[9]
            })
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        cursor.execute("""
            SELECT 
                COUNT(*) as total,
                SUM(CASE WHEN current_position = 'bullish' THEN 1 ELSE 0 END) as bullish_count,
                SUM(CASE WHEN current_position = 'bearish' THEN 1 ELSE 0 END) as bearish_count,
                AVG(position_duration) as avg_duration
            FROM sar_position_stats
        """)
        
        stats_row = cursor.fetchone()
        stats = {
            'total_symbols': stats_row[0],
            'bullish_count': stats_row[1],
            'bearish_count': stats_row[2],
            'avg_duration': round(stats_row[3], 1) if stats_row[3] else 0
        }
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': results,
            'stats': stats,
            'timestamp': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/sar-slope/history/<symbol>')
def api_sar_slope_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„SARæ–œç‡å†å²æ•°æ®ï¼ˆé»˜è®¤48å°æ—¶ï¼‰"""
    try:
        days = int(request.args.get('days', 2))
        limit = int(request.args.get('limit', 600))
        
        # è®¡ç®—èµ·å§‹æ—¶é—´æˆ³
        start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                timestamp,
                datetime_beijing,
                sar_value,
                sar_position,
                sar_quadrant,
                position_duration,
                slope_value,
                slope_direction,
                price_open,
                price_close
            FROM sar_slope_data
            WHERE symbol = ? AND timestamp >= ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (symbol, start_time, limit))
        
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            results.append({
                'timestamp': row[0],
                'datetime': row[1],
                'sar_value': round(row[2], 6) if row[2] else None,
                'sar_position': row[3],
                'sar_quadrant': row[4],
                'position_duration': row[5],
                'slope_value': round(row[6], 4) if row[6] else None,
                'slope_direction': row[7],
                'price_open': round(row[8], 6) if row[8] else None,
                'price': round(row[9], 6) if row[9] else None
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'days': days,
            'data': results,
            'count': len(results)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/sar-slope/position-changes/<symbol>')
def api_sar_slope_position_changes(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„SARä½ç½®å˜åŒ–å†å²"""
    try:
        days = int(request.args.get('days', 7))
        start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾ä½ç½®å˜åŒ–ç‚¹
        cursor.execute("""
            WITH position_changes AS (
                SELECT 
                    timestamp,
                    datetime_beijing,
                    sar_value,
                    sar_position,
                    position_duration,
                    price_close,
                    LAG(sar_position) OVER (ORDER BY timestamp) as prev_position
                FROM sar_slope_data
                WHERE symbol = ? AND timestamp >= ?
            )
            SELECT 
                timestamp,
                datetime_beijing,
                sar_value,
                sar_position,
                position_duration,
                price_close
            FROM position_changes
            WHERE prev_position IS NULL OR sar_position != prev_position
            ORDER BY timestamp DESC
            LIMIT 100
        """, (symbol, start_time))
        
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            results.append({
                'timestamp': row[0],
                'datetime': row[1],
                'sar_value': round(row[2], 6) if row[2] else None,
                'position': row[3],
                'duration': row[4],
                'price': round(row[5], 6) if row[5] else None
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'days': days,
            'data': results,
            'count': len(results)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/sar-slope/collector-status')
def api_sar_slope_collector_status():
    """è·å–SARæ–œç‡é‡‡é›†å™¨çŠ¶æ€"""
    try:
        conn = sqlite3.connect('databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°æ•°æ®æ—¶é—´
        cursor.execute("""
            SELECT MAX(timestamp) FROM sar_slope_data
        """)
        
        latest_timestamp = cursor.fetchone()[0]
        
        if latest_timestamp:
            latest_dt = datetime.utcfromtimestamp(latest_timestamp / 1000)
            latest_dt_beijing = latest_dt.replace(tzinfo=pytz.UTC).astimezone(BEIJING_TZ)
            latest_time = latest_dt_beijing.strftime('%Y-%m-%d %H:%M:%S')
            
            # è®¡ç®—å»¶è¿Ÿ
            now = datetime.now(BEIJING_TZ)
            delay_minutes = (now - latest_dt_beijing).total_seconds() / 60
        else:
            latest_time = None
            delay_minutes = None
        
        # è·å–æ•°æ®ç»Ÿè®¡
        cursor.execute("""
            SELECT COUNT(*) FROM sar_slope_data
        """)
        total_records = cursor.fetchone()[0]
        
        # è·å–å„å¸ç§æ•°æ®é‡
        cursor.execute("""
            SELECT symbol, COUNT(*) as count
            FROM sar_slope_data
            GROUP BY symbol
            ORDER BY count DESC
        """)
        
        symbol_counts = [{'symbol': row[0], 'count': row[1]} for row in cursor.fetchall()]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'status': {
                'latest_time': latest_time,
                'delay_minutes': round(delay_minutes, 1) if delay_minutes else None,
                'is_delayed': delay_minutes > 10 if delay_minutes else True,
                'total_records': total_records,
                'symbol_counts': symbol_counts
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== Telegram é…ç½®ç®¡ç† API ====================

@app.route('/api/telegram/config', methods=['GET', 'POST'])
def telegram_config_api():
    """
    è·å–æˆ–æ›´æ–° Telegram é…ç½®
    GET: è¿”å›å½“å‰é…ç½®
    POST: æ›´æ–°é…ç½®
    """
    config_file = 'telegram_config.json'
    
    try:
        if request.method == 'GET':
            # è¯»å–å½“å‰é…ç½®
            if not os.path.exists(config_file):
                return jsonify({
                    'success': False,
                    'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                }), 404
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.json
            
            if not data:
                return jsonify({
                    'success': False,
                    'error': 'è¯·æä¾›é…ç½®æ•°æ®'
                }), 400
            
            # è¯»å–ç°æœ‰é…ç½®
            if not os.path.exists(config_file):
                return jsonify({
                    'success': False,
                    'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                }), 404
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ›´æ–°ä¿¡å·ç±»å‹çš„å¯ç”¨çŠ¶æ€
            if 'buy' in data:
                config['signal_types']['buy']['enabled'] = data['buy']
            if 'sell' in data:
                config['signal_types']['sell']['enabled'] = data['sell']
            if 'double_buy' in data:
                config['signal_types']['double_buy']['enabled'] = data['double_buy']
            if 'double_sell' in data:
                config['signal_types']['double_sell']['enabled'] = data['double_sell']
            
            # å¤‡ä»½åŸé…ç½®
            backup_file = f'telegram_config_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜æ–°é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'message': 'é…ç½®å·²æ›´æ–°',
                'config': config,
                'backup_file': backup_file
            })
            
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== èµ„é‡‘ç›‘æ§ç³»ç»Ÿ API ====================

@app.route('/api/fund-monitor/latest', methods=['GET'])
def fund_monitor_latest():
    """è·å–æœ€æ–°çš„èµ„é‡‘ç›‘æ§æ•°æ®ï¼ˆæ‰€æœ‰å¸ç§ï¼Œæ‰€æœ‰æ—¶é—´å‘¨æœŸï¼‰"""
    try:
        conn = sqlite3.connect('fund_monitor.db')
        cursor = conn.cursor()
        
        # è·å–æ¯ä¸ªå¸ç§ã€æ¯ä¸ªæ—¶é—´å‘¨æœŸçš„æœ€æ–°æ•°æ®
        cursor.execute('''
            SELECT symbol, interval_type, timestamp, collect_time, volume, 
                   avg_3day, deviation_percent, is_abnormal
            FROM fund_monitor_aggregated
            WHERE (symbol, interval_type, timestamp) IN (
                SELECT symbol, interval_type, MAX(timestamp)
                FROM fund_monitor_aggregated
                GROUP BY symbol, interval_type
            )
            ORDER BY symbol, interval_type
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        # æŒ‰å¸ç§ç»„ç»‡æ•°æ®
        data_by_symbol = {}
        for row in rows:
            symbol = row[0]
            if symbol not in data_by_symbol:
                data_by_symbol[symbol] = {
                    '15min': None,
                    '30min': None,
                    '60min': None
                }
            
            interval_type = row[1]
            data_by_symbol[symbol][interval_type] = {
                'timestamp': row[2],
                'collect_time': row[3],
                'volume': round(row[4], 2),
                'avg_3day': round(row[5], 2) if row[5] is not None else None,
                'deviation_percent': round(row[6], 2) if row[6] is not None else None,
                'is_abnormal': bool(row[7])
            }
        
        return jsonify({
            'success': True,
            'data': data_by_symbol,
            'update_time': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/history/<symbol>', methods=['GET'])
def fund_monitor_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²æ•°æ®"""
    try:
        interval_type = request.args.get('interval', '15min')  # é»˜è®¤15åˆ†é’Ÿ
        hours = int(request.args.get('hours', 24))  # é»˜è®¤24å°æ—¶
        
        conn = sqlite3.connect('fund_monitor.db')
        cursor = conn.cursor()
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_time = int(datetime.now(BEIJING_TZ).timestamp() * 1000)
        start_time = end_time - (hours * 60 * 60 * 1000)
        
        cursor.execute('''
            SELECT timestamp, collect_time, volume, avg_3day, 
                   deviation_percent, is_abnormal
            FROM fund_monitor_aggregated
            WHERE symbol = ?
            AND interval_type = ?
            AND timestamp >= ?
            ORDER BY timestamp ASC
        ''', (symbol.upper(), interval_type, start_time))
        
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'timestamp': row[0],
                'collect_time': row[1],
                'volume': round(row[2], 2),
                'avg_3day': round(row[3], 2) if row[3] is not None else None,
                'deviation_percent': round(row[4], 2) if row[4] is not None else None,
                'is_abnormal': bool(row[5])
            })
        
        return jsonify({
            'success': True,
            'symbol': symbol.upper(),
            'interval_type': interval_type,
            'hours': hours,
            'data': history
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal', methods=['GET'])
def fund_monitor_abnormal():
    """è·å–å½“å‰æ‰€æœ‰å¼‚å¸¸æ•°æ®"""
    try:
        conn = sqlite3.connect('fund_monitor.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°å¼‚å¸¸æ•°æ®
        cursor.execute('''
            SELECT symbol, interval_type, timestamp, collect_time, 
                   volume, avg_3day, deviation_percent
            FROM fund_monitor_aggregated
            WHERE is_abnormal = 1
            AND (symbol, interval_type, timestamp) IN (
                SELECT symbol, interval_type, MAX(timestamp)
                FROM fund_monitor_aggregated
                WHERE is_abnormal = 1
                GROUP BY symbol, interval_type
            )
            ORDER BY ABS(deviation_percent) DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        abnormal_list = []
        for row in rows:
            abnormal_list.append({
                'symbol': row[0],
                'interval_type': row[1],
                'timestamp': row[2],
                'collect_time': row[3],
                'volume': round(row[4], 2),
                'avg_3day': round(row[5], 2) if row[5] is not None else None,
                'deviation_percent': round(row[6], 2)
            })
        
        return jsonify({
            'success': True,
            'count': len(abnormal_list),
            'data': abnormal_list,
            'update_time': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/config', methods=['GET', 'POST'])
def fund_monitor_config():
    """è·å–æˆ–æ›´æ–°èµ„é‡‘ç›‘æ§é…ç½®"""
    config_file = 'fund_monitor_config.json'
    
    try:
        if request.method == 'GET':
            # è¯»å–é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            else:
                config = {
                    'threshold_percentage': 20.0,
                    'lookback_days': 3,
                    'collection_interval': 300
                }
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.json
            
            if not data:
                return jsonify({
                    'success': False,
                    'error': 'è¯·æä¾›é…ç½®æ•°æ®'
                }), 400
            
            # è¯»å–ç°æœ‰é…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            else:
                config = {
                    'threshold_percentage': 20.0,
                    'lookback_days': 3,
                    'collection_interval': 300
                }
            
            # æ›´æ–°é…ç½®
            if 'threshold_percentage' in data:
                config['threshold_percentage'] = float(data['threshold_percentage'])
            if 'lookback_days' in data:
                config['lookback_days'] = int(data['lookback_days'])
            if 'collection_interval' in data:
                config['collection_interval'] = int(data['collection_interval'])
            
            # ä¿å­˜é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'message': 'é…ç½®å·²æ›´æ–°',
                'config': config
            })
            
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal-history', methods=['GET'])
def fund_monitor_abnormal_history():
    """æŸ¥è¯¢å¼‚å¸¸æ•°æ®å†å²è®°å½•"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        date = request.args.get('date')  # æ ¼å¼ï¼šYYYY-MM-DD
        start_date = request.args.get('start_date')  # æ ¼å¼ï¼šYYYY-MM-DD
        end_date = request.args.get('end_date')  # æ ¼å¼ï¼šYYYY-MM-DD
        symbol = request.args.get('symbol')  # å¸ç§
        interval = request.args.get('interval')  # æ—¶é—´å‘¨æœŸ
        severity = request.args.get('severity')  # ä¸¥é‡ç¨‹åº¦
        deviation_type = request.args.get('type')  # surgeæˆ–drop
        limit = int(request.args.get('limit', 100))  # è¿”å›è®°å½•æ•°
        
        conn = sqlite3.connect('fund_monitor.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []
        
        if date:
            conditions.append('collect_date = ?')
            params.append(date)
        elif start_date and end_date:
            conditions.append('collect_date BETWEEN ? AND ?')
            params.extend([start_date, end_date])
        elif start_date:
            conditions.append('collect_date >= ?')
            params.append(start_date)
        elif end_date:
            conditions.append('collect_date <= ?')
            params.append(end_date)
        
        if symbol:
            conditions.append('symbol = ?')
            params.append(symbol.upper())
        
        if interval:
            conditions.append('interval_type = ?')
            params.append(interval)
        
        if severity:
            conditions.append('severity = ?')
            params.append(severity)
        
        if deviation_type:
            conditions.append('deviation_type = ?')
            params.append(deviation_type)
        
        where_clause = ' AND '.join(conditions) if conditions else '1=1'
        
        # æ‰§è¡ŒæŸ¥è¯¢
        query = f'''
            SELECT id, symbol, interval_type, timestamp, collect_time, collect_date,
                   volume, avg_3day, deviation_percent, deviation_type, severity
            FROM fund_monitor_abnormal_history
            WHERE {where_clause}
            ORDER BY timestamp DESC
            LIMIT ?
        '''
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        # æ ¼å¼åŒ–ç»“æœ
        history = []
        for row in rows:
            history.append({
                'id': row[0],
                'symbol': row[1],
                'interval_type': row[2],
                'timestamp': row[3],
                'collect_time': row[4],
                'collect_date': row[5],
                'volume': round(row[6], 2),
                'avg_3day': round(row[7], 2),
                'deviation_percent': round(row[8], 2),
                'deviation_type': row[9],
                'severity': row[10]
            })
        
        # ç»Ÿè®¡ä¿¡æ¯
        cursor.execute(f'''
            SELECT COUNT(*) FROM fund_monitor_abnormal_history
            WHERE {where_clause}
        ''', params[:-1])  # å»æ‰limitå‚æ•°
        total_count = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'total_count': total_count,
            'returned_count': len(history),
            'data': history
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal-dates', methods=['GET'])
def fund_monitor_abnormal_dates():
    """è·å–æœ‰å¼‚å¸¸æ•°æ®çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        conn = sqlite3.connect('fund_monitor.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æ‰€æœ‰æœ‰å¼‚å¸¸æ•°æ®çš„æ—¥æœŸåŠå…¶ç»Ÿè®¡
        cursor.execute('''
            SELECT collect_date, 
                   COUNT(*) as count,
                   COUNT(DISTINCT symbol) as affected_coins,
                   AVG(ABS(deviation_percent)) as avg_deviation
            FROM fund_monitor_abnormal_history
            GROUP BY collect_date
            ORDER BY collect_date DESC
        ''')
        
        rows = cursor.fetchall()
        
        dates = []
        for row in rows:
            dates.append({
                'date': row[0],
                'count': row[1],
                'affected_coins': row[2],
                'avg_deviation': round(row[3], 2)
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'dates': dates
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal-timeline', methods=['GET'])
def fund_monitor_abnormal_timeline():
    """è·å–å¼‚å¸¸æ•°æ®æ—¶é—´è½´ï¼ˆæŒ‰å°æ—¶èšåˆï¼‰"""
    try:
        date = request.args.get('date')  # YYYY-MM-DD
        
        if not date:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›dateå‚æ•°'
            }), 400
        
        conn = sqlite3.connect('fund_monitor.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰å¼‚å¸¸æ•°æ®
        cursor.execute('''
            SELECT symbol, interval_type, collect_time, volume, 
                   avg_3day, deviation_percent, deviation_type, severity
            FROM fund_monitor_abnormal_history
            WHERE collect_date = ?
            ORDER BY collect_time ASC
        ''', (date,))
        
        rows = cursor.fetchall()
        
        # æŒ‰å°æ—¶åˆ†ç»„
        timeline = {}
        for row in rows:
            collect_time = row[2]
            hour = collect_time[:13]  # YYYY-MM-DD HH
            
            if hour not in timeline:
                timeline[hour] = []
            
            timeline[hour].append({
                'symbol': row[0],
                'interval_type': row[1],
                'time': collect_time,
                'volume': round(row[3], 2),
                'avg_3day': round(row[4], 2),
                'deviation_percent': round(row[5], 2),
                'deviation_type': row[6],
                'severity': row[7]
            })
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        timeline_list = []
        for hour, events in sorted(timeline.items()):
            timeline_list.append({
                'hour': hour,
                'count': len(events),
                'events': events
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'date': date,
            'timeline': timeline_list
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/fund-monitor', methods=['GET'])
def fund_monitor_page():
    """èµ„é‡‘ç›‘æ§ç³»ç»Ÿå‰ç«¯é¡µé¢"""
    return render_template('fund_monitor.html')

@app.route('/fund-monitor-history', methods=['GET'])
def fund_monitor_history_page():
    """èµ„é‡‘ç›‘æ§å¼‚å¸¸å†å²æŸ¥è¯¢é¡µé¢"""
    return render_template('fund_monitor_history.html')

# ==================== SARæ–œç‡ç³»ç»Ÿè·¯ç”± ====================
@app.route('/sar-slope')
def sar_slope():
    """SARæ–œç‡ç³»ç»Ÿä¸»é¡µé¢"""
    return render_template('sar_slope.html')

@app.route('/sar-slope/<symbol>')
def sar_slope_detail(symbol):
    """SARæ–œç‡å•å¸è¯¦ç»†è¿½è¸ªé¡µé¢"""
    return render_template('sar_slope_detail.html', symbol=symbol.upper())

@app.route('/api/sar-slope/status')
def sar_slope_status():
    """è·å–æ‰€æœ‰å¸ç§çš„SARçŠ¶æ€"""
    # æ£€æŸ¥æœåŠ¡å™¨ç«¯ç¼“å­˜
    cache_key = "sar_slope_status:all"
    cached_data = server_cache.get(cache_key, max_age=30)
    if cached_data:
        cached_data['_from_server_cache'] = True
        cached_data['_cache_age'] = int(time.time() - server_cache.timestamps.get(cache_key, 0))
        return jsonify(cached_data)
    
    try:
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT symbol, last_kline_time, total_klines,
                   current_position, current_sequence, updated_at
            FROM system_status
            ORDER BY symbol
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        status_list = []
        for row in rows:
            status_list.append({
                'symbol': row[0],
                'last_kline_time': row[1],
                'total_klines': row[2],
                'current_position': row[3],
                'current_sequence': row[4],
                'updated_at': row[5]
            })
        
        result = {
            'success': True,
            'data': status_list,
            'count': len(status_list)
        }
        
        # ä¿å­˜åˆ°æœåŠ¡å™¨ç«¯ç¼“å­˜
        server_cache.set(cache_key, result)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/symbol/<symbol>')
def sar_slope_symbol_data(symbol):
    """è·å–å•ä¸ªå¸ç§çš„è¯¦ç»†SARæ•°æ®"""
    try:
        limit = request.args.get('limit', 500, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        # è·å–åŸå§‹SARæ•°æ®
        cursor.execute('''
            SELECT timestamp, kline_time, open_price, high_price, low_price, 
                   close_price, sar_value, position, position_sequence, duration_minutes
            FROM sar_raw_data
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (symbol, limit))
        
        sar_data = []
        for row in cursor.fetchall():
            sar_data.append({
                'timestamp': row[0],
                'kline_time': row[1],
                'open': row[2],
                'high': row[3],
                'low': row[4],
                'close': row[5],
                'sar': row[6],
                'position': row[7],
                'sequence': row[8],
                'duration': row[9]
            })
        
        # è·å–å˜åŒ–ç‡æ•°æ®
        cursor.execute('''
            SELECT sequence_num, prev_sar, current_sar, change_value, 
                   change_percent, kline_time, position
            FROM sar_consecutive_changes
            WHERE symbol = ?
            ORDER BY id DESC
            LIMIT ?
        ''', (symbol, limit))
        
        changes = []
        for row in cursor.fetchall():
            changes.append({
                'sequence': row[0],
                'prev_sar': row[1],
                'current_sar': row[2],
                'change_value': row[3],
                'change_percent': row[4],
                'time': row[5],
                'position': row[6]
            })
        
        # è·å–å¹³å‡å€¼
        cursor.execute('''
            SELECT position, period_type, avg_change_percent, sample_count
            FROM sar_period_averages
            WHERE symbol = ?
        ''', (symbol,))
        
        averages = {}
        for row in cursor.fetchall():
            pos = row[0]
            if pos not in averages:
                averages[pos] = {}
            averages[pos][row[1]] = {
                'avg': row[2],
                'samples': row[3]
            }
        
        # è·å–æœ€è¿‘å¼‚å¸¸
        cursor.execute('''
            SELECT position, sequence_num, sar_value, change_percent,
                   deviation_percent, alert_level, is_extreme_point, kline_time
            FROM sar_anomaly_alerts
            WHERE symbol = ?
            ORDER BY created_at DESC
            LIMIT 100
        ''', (symbol,))
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'position': row[0],
                'sequence': row[1],
                'sar': row[2],
                'change_percent': row[3],
                'deviation': row[4],
                'level': row[5],
                'is_extreme': row[6],
                'time': row[7]
            })
        
        # è·å–è½¬æ¢ç‚¹
        cursor.execute('''
            SELECT timestamp, kline_time, from_position, to_position,
                   conversion_sar, conversion_price, previous_duration
            FROM sar_conversion_points
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT 50
        ''', (symbol,))
        
        conversions = []
        for row in cursor.fetchall():
            conversions.append({
                'timestamp': row[0],
                'time': row[1],
                'from_position': row[2],
                'to_position': row[3],
                'sar': row[4],
                'price': row[5],
                'prev_duration': row[6]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'sar_data': sar_data,
            'changes': changes,
            'averages': averages,
            'alerts': alerts,
            'conversions': conversions
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/alerts')
def sar_slope_alerts():
    """è·å–æ‰€æœ‰å¼‚å¸¸å‘Šè­¦"""
    try:
        limit = request.args.get('limit', 50, type=int)
        symbol = request.args.get('symbol', None)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        if symbol:
            cursor.execute('''
                SELECT symbol, position, sequence_num, sar_value,
                       change_percent, deviation_percent, alert_level,
                       is_extreme_point, extreme_type, kline_time
                FROM sar_anomaly_alerts
                WHERE symbol = ?
                ORDER BY created_at DESC
                LIMIT ?
            ''', (symbol, limit))
        else:
            cursor.execute('''
                SELECT symbol, position, sequence_num, sar_value,
                       change_percent, deviation_percent, alert_level,
                       is_extreme_point, extreme_type, kline_time
                FROM sar_anomaly_alerts
                ORDER BY created_at DESC
                LIMIT ?
            ''', (limit,))
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'symbol': row[0],
                'position': row[1],
                'sequence': row[2],
                'sar': row[3],
                'change_percent': row[4],
                'deviation': row[5],
                'level': row[6],
                'is_extreme': row[7],
                'extreme_type': row[8],
                'time': row[9]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': alerts,
            'count': len(alerts)
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/conversions')
def sar_slope_conversions():
    """è·å–å¤šç©ºè½¬æ¢ç‚¹"""
    try:
        limit = request.args.get('limit', 50, type=int)
        symbol = request.args.get('symbol', None)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        if symbol:
            cursor.execute('''
                SELECT symbol, timestamp, kline_time, from_position, to_position,
                       conversion_sar, conversion_price, previous_duration
                FROM sar_conversion_points
                WHERE symbol = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (symbol, limit))
        else:
            cursor.execute('''
                SELECT symbol, timestamp, kline_time, from_position, to_position,
                       conversion_sar, conversion_price, previous_duration
                FROM sar_conversion_points
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
        
        conversions = []
        for row in cursor.fetchall():
            conversions.append({
                'symbol': row[0],
                'timestamp': row[1],
                'time': row[2],
                'from_position': row[3],
                'to_position': row[4],
                'sar': row[5],
                'price': row[6],
                'prev_duration': row[7]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': conversions,
            'count': len(conversions)
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/query/<symbol>')
def sar_slope_query_symbol(symbol):
    """
    å®Œæ•´çš„å•å¸æŸ¥è¯¢æ¥å£
    æŸ¥è¯¢å‚æ•°:
    - start_time: å¼€å§‹æ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)
    - end_time: ç»“æŸæ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)
    - limit: è¿”å›æ•°é‡é™åˆ¶ (é»˜è®¤: 1000)
    - position: ç­›é€‰å¤šç©ºçŠ¶æ€ (long/short)
    - include_changes: æ˜¯å¦åŒ…å«å˜åŒ–ç‡ (true/false, é»˜è®¤: true)
    - include_alerts: æ˜¯å¦åŒ…å«å¼‚å¸¸å‘Šè­¦ (true/false, é»˜è®¤: true)
    - include_conversions: æ˜¯å¦åŒ…å«å¤šç©ºè½¬æ¢ (true/false, é»˜è®¤: true)
    - include_averages: æ˜¯å¦åŒ…å«å‘¨æœŸå¹³å‡å€¼ (true/false, é»˜è®¤: true)
    """
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        start_time = request.args.get('start_time', None)
        end_time = request.args.get('end_time', None)
        limit = request.args.get('limit', 1000, type=int)
        position = request.args.get('position', None)  # long/short
        
        include_changes = request.args.get('include_changes', 'true').lower() == 'true'
        include_alerts = request.args.get('include_alerts', 'true').lower() == 'true'
        include_conversions = request.args.get('include_conversions', 'true').lower() == 'true'
        include_averages = request.args.get('include_averages', 'true').lower() == 'true'
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'query_params': {
                'start_time': start_time,
                'end_time': end_time,
                'limit': limit,
                'position': position
            }
        }
        
        # 1. è·å–ç³»ç»ŸçŠ¶æ€
        cursor.execute('''
            SELECT last_update_time, last_kline_time, total_klines,
                   current_position, current_sequence, status, updated_at
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status_row = cursor.fetchone()
        if status_row:
            result['system_status'] = {
                'last_update_time': status_row[0],
                'last_kline_time': status_row[1],
                'total_klines': status_row[2],
                'current_position': status_row[3],
                'current_sequence': status_row[4],
                'status': status_row[5],
                'updated_at': status_row[6]
            }
        else:
            return jsonify({
                'success': False,
                'error': f'Symbol {symbol.upper()} not found in system'
            })
        
        # 2. æ„å»ºåŸå§‹æ•°æ®æŸ¥è¯¢SQL
        sql_conditions = ["symbol = ?"]
        sql_params = [symbol.upper()]
        
        if start_time:
            # è½¬æ¢æ—¶é—´å­—ç¬¦ä¸²ä¸ºæ—¶é—´æˆ³
            from datetime import datetime
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            dt = beijing_tz.localize(datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S'))
            timestamp = int(dt.timestamp() * 1000)
            sql_conditions.append("timestamp >= ?")
            sql_params.append(timestamp)
        
        if end_time:
            from datetime import datetime
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            dt = beijing_tz.localize(datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S'))
            timestamp = int(dt.timestamp() * 1000)
            sql_conditions.append("timestamp <= ?")
            sql_params.append(timestamp)
        
        if position:
            sql_conditions.append("position = ?")
            sql_params.append(position)
        
        # è·å–åŸå§‹SARæ•°æ®
        cursor.execute(f'''
            SELECT timestamp, kline_time, open_price, high_price, low_price,
                   close_price, sar_value, position, position_sequence, duration_minutes
            FROM sar_raw_data
            WHERE {' AND '.join(sql_conditions)}
            ORDER BY timestamp DESC
            LIMIT ?
        ''', sql_params + [limit])
        
        sar_data = []
        for row in cursor.fetchall():
            sar_data.append({
                'timestamp': row[0],
                'kline_time': row[1],
                'open': row[2],
                'high': row[3],
                'low': row[4],
                'close': row[5],
                'sar': row[6],
                'position': row[7],
                'sequence': row[8],
                'duration': row[9]
            })
        
        result['sar_data'] = {
            'count': len(sar_data),
            'data': sar_data
        }
        
        # 3. è·å–å˜åŒ–ç‡æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_changes:
            change_conditions = ["symbol = ?"]
            change_params = [symbol.upper()]
            
            if position:
                change_conditions.append("position = ?")
                change_params.append(position)
            
            cursor.execute(f'''
                SELECT sequence_num, prev_sar, current_sar, change_value,
                       change_percent, kline_time, position
                FROM sar_consecutive_changes
                WHERE {' AND '.join(change_conditions)}
                ORDER BY id DESC
                LIMIT ?
            ''', change_params + [limit])
            
            changes = []
            for row in cursor.fetchall():
                changes.append({
                    'sequence': row[0],
                    'prev_sar': row[1],
                    'current_sar': row[2],
                    'change_value': row[3],
                    'change_percent': row[4],
                    'time': row[5],
                    'position': row[6]
                })
            
            result['changes'] = {
                'count': len(changes),
                'data': changes
            }
        
        # 4. è·å–å‘¨æœŸå¹³å‡å€¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_averages:
            cursor.execute('''
                SELECT position, period_type, avg_change_percent, 
                       sample_count, calculated_at
                FROM sar_period_averages
                WHERE symbol = ?
                ORDER BY position, period_type
            ''', (symbol.upper(),))
            
            averages = {
                'long': {},
                'short': {}
            }
            
            for row in cursor.fetchall():
                pos = row[0]
                period = row[1]
                averages[pos][period] = {
                    'avg_change_percent': row[2],
                    'sample_count': row[3],
                    'calculated_at': row[4]
                }
            
            result['averages'] = averages
        
        # 5. è·å–å¼‚å¸¸å‘Šè­¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_alerts:
            alert_conditions = ["symbol = ?"]
            alert_params = [symbol.upper()]
            
            if position:
                alert_conditions.append("position = ?")
                alert_params.append(position)
            
            cursor.execute(f'''
                SELECT position, sequence_num, sar_value, change_percent,
                       period_avg, deviation_percent, alert_level,
                       is_extreme_point, extreme_type, kline_time, created_at
                FROM sar_anomaly_alerts
                WHERE {' AND '.join(alert_conditions)}
                ORDER BY created_at DESC
                LIMIT ?
            ''', alert_params + [min(limit, 200)])
            
            alerts = []
            for row in cursor.fetchall():
                alerts.append({
                    'position': row[0],
                    'sequence': row[1],
                    'sar': row[2],
                    'change_percent': row[3],
                    'period_avg': row[4],
                    'deviation': row[5],
                    'level': row[6],
                    'is_extreme': row[7],
                    'extreme_type': row[8],
                    'time': row[9],
                    'created_at': row[10]
                })
            
            result['alerts'] = {
                'count': len(alerts),
                'data': alerts
            }
        
        # 6. è·å–å¤šç©ºè½¬æ¢ç‚¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_conversions:
            cursor.execute('''
                SELECT timestamp, kline_time, from_position, to_position,
                       conversion_sar, conversion_price, previous_duration, created_at
                FROM sar_conversion_points
                WHERE symbol = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (symbol.upper(), min(limit, 100)))
            
            conversions = []
            for row in cursor.fetchall():
                conversions.append({
                    'timestamp': row[0],
                    'time': row[1],
                    'from_position': row[2],
                    'to_position': row[3],
                    'sar': row[4],
                    'price': row[5],
                    'prev_duration': row[6],
                    'created_at': row[7]
                })
            
            result['conversions'] = {
                'count': len(conversions),
                'data': conversions
            }
        
        # 7. ç»Ÿè®¡ä¿¡æ¯
        result['statistics'] = {
            'total_records': len(sar_data),
            'date_range': {
                'earliest': sar_data[-1]['kline_time'] if sar_data else None,
                'latest': sar_data[0]['kline_time'] if sar_data else None
            }
        }
        
        # è®¡ç®—å¤šç©ºåˆ†å¸ƒ
        if sar_data:
            long_count = sum(1 for d in sar_data if d['position'] == 'long')
            short_count = sum(1 for d in sar_data if d['position'] == 'short')
            result['statistics']['position_distribution'] = {
                'long': long_count,
                'short': short_count,
                'long_percent': round(long_count / len(sar_data) * 100, 2),
                'short_percent': round(short_count / len(sar_data) * 100, 2)
            }
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/sequence-compare/<symbol>')
def sar_slope_sequence_compare(symbol):
    """
    åºåˆ—å·å¯¹æ¯”æ¥å£ - ç”¨æˆ·éœ€æ±‚
    å¯¹æ¯”å½“å‰åºåˆ—å·çš„å˜åŒ–ç‡ä¸è¯¥åºåˆ—å·çš„å†å²å¹³å‡å€¼
    
    ä¾‹å¦‚ï¼šå½“å‰æ˜¯ç©ºå¤´02â†’ç©ºå¤´03ï¼Œå˜åŒ–ç‡æ˜¯0.05%
    æŸ¥è¯¢æ‰€æœ‰å†å²ä¸Š"ç©ºå¤´02â†’ç©ºå¤´03"è¿™ä¸€æ­¥çš„å¹³å‡å˜åŒ–ç‡æ˜¯0.04%
    å¾—å‡ºç»“è®ºï¼šå½“å‰æ¯”å¹³å‡å€¼å¢åŠ äº†0.01%
    
    å‚æ•°:
    - position: long/short (å¯é€‰ï¼Œä¸å¡«åˆ™è¿”å›ä¸¤ä¸ªæ–¹å‘)
    - sequence: åºåˆ—å· (å¯é€‰ï¼Œä¸å¡«åˆ™è¿”å›æ‰€æœ‰åºåˆ—å·)
    """
    try:
        position_filter = request.args.get('position', None)
        sequence_filter = request.args.get('sequence', None, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'comparisons': []
        }
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        result['current_status'] = {
            'position': status[0],
            'sequence': status[1]
        }
        
        # è·å–å½“å‰æœ€æ–°çš„å˜åŒ–ç‡
        cursor.execute('''
            SELECT sequence_num, change_percent, kline_time, position
            FROM sar_consecutive_changes
            WHERE symbol = ?
            ORDER BY id DESC
            LIMIT 50
        ''', (symbol.upper(),))
        
        recent_changes = cursor.fetchall()
        
        # è·å–åºåˆ—å·å¹³å‡å€¼
        cursor.execute('''
            SELECT position, period_type, avg_change_percent, sample_count
            FROM sar_period_averages
            WHERE symbol = ? AND period_type LIKE 'seq_%'
            ORDER BY position, period_type
        ''', (symbol.upper(),))
        
        seq_averages = {}
        for row in cursor.fetchall():
            pos = row[0]
            period = row[1]  # æ ¼å¼: seq_01, seq_02, seq_03
            seq_num = int(period.split('_')[1])
            
            if pos not in seq_averages:
                seq_averages[pos] = {}
            
            seq_averages[pos][seq_num] = {
                'avg': row[2],
                'samples': row[3]
            }
        
        # å¯¹æ¯”åˆ†æ
        for change in recent_changes:
            seq_num = change[0]
            current_change = change[1]
            kline_time = change[2]
            pos = change[3]
            
            # è¿‡æ»¤æ¡ä»¶
            if position_filter and pos != position_filter:
                continue
            if sequence_filter and seq_num != sequence_filter:
                continue
            
            # è·å–è¯¥åºåˆ—å·çš„å†å²å¹³å‡å€¼
            if pos in seq_averages and seq_num in seq_averages[pos]:
                avg_data = seq_averages[pos][seq_num]
                avg_change = avg_data['avg']
                samples = avg_data['samples']
                
                # è®¡ç®—å·®å¼‚
                difference = current_change - avg_change
                difference_percent = (difference / avg_change * 100) if avg_change != 0 else 0
                
                # åˆ¤æ–­å¢åŠ è¿˜æ˜¯å‡å°
                trend = 'increase' if difference > 0 else 'decrease' if difference < 0 else 'equal'
                
                result['comparisons'].append({
                    'position': pos,
                    'sequence': seq_num,
                    'time': kline_time,
                    'current_change': round(current_change, 6),
                    'average_change': round(avg_change, 6),
                    'difference': round(difference, 6),
                    'difference_percent': round(difference_percent, 2),
                    'trend': trend,
                    'sample_count': samples,
                    'description': f'{"å¤šå¤´" if pos == "long" else "ç©ºå¤´"}{seq_num:02d}â†’{seq_num+1:02d}'
                })
        
        result['total_comparisons'] = len(result['comparisons'])
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/duration-signal/<symbol>')
def sar_slope_duration_signal(symbol):
    """
    æŒ‰æŒç»­æ—¶é—´æ®µåˆ†æä¿¡å· - ç”¨æˆ·æœ€æ–°éœ€æ±‚
    
    å¯¹æ¯”é€»è¾‘ï¼š
    - å¤šå¤´åŒºé—´ï¼š
      * 1å¤©å¹³å‡ < 3å¤©å¹³å‡ï¼ˆæ¯”å€¼å‡å°ï¼‰â†’ å¼ºåŠ¿å¤šå¤´ä¿¡å·ï¼ˆåå¤šï¼‰
      * 1å¤©å¹³å‡ > 3å¤©å¹³å‡ï¼ˆæ¯”å€¼å¢å¤§ï¼‰â†’ åŠ é€Ÿèµ¶é¡¶ä¿¡å·ï¼ˆåç©ºï¼‰
    - ç©ºå¤´åŒºé—´ï¼š
      * 1å¤©å¹³å‡ < 3å¤©å¹³å‡ï¼ˆæ¯”å€¼å‡å°ï¼‰â†’ å¼ºåŠ¿ç©ºå¤´ä¿¡å·ï¼ˆåç©ºï¼‰
      * 1å¤©å¹³å‡ > 3å¤©å¹³å‡ï¼ˆæ¯”å€¼å¢å¤§ï¼‰â†’ åŠ é€Ÿèµ¶åº•ä¿¡å·ï¼ˆåå¤šï¼‰
    
    å‚æ•°:
    - position: long/short (å¯é€‰ï¼Œä¸å¡«åˆ™è¿”å›ä¸¤ä¸ªæ–¹å‘)
    - duration: æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼Œå¯é€‰ï¼‰
    """
    try:
        position_filter = request.args.get('position', None)
        duration_filter = request.args.get('duration', None, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'signals': []
        }
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        result['current_status'] = {
            'position': status[0],
            'sequence': status[1]
        }
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = ["symbol = ?", "period_type LIKE 'dur_%'"]
        params = [symbol.upper()]
        
        if position_filter:
            conditions.append("position = ?")
            params.append(position_filter)
        
        # è·å–æ‰€æœ‰ duration çš„å¹³å‡å€¼æ•°æ®
        cursor.execute(f'''
            SELECT position, period_type, avg_change_percent, sample_count
            FROM sar_period_averages
            WHERE {' AND '.join(conditions)}
            ORDER BY position, period_type
        ''', params)
        
        # ç»„ç»‡æ•°æ®ç»“æ„: {position: {duration: {period: avg}}}
        duration_data = {}
        for row in cursor.fetchall():
            pos = row[0]
            period_type = row[1]  # æ ¼å¼: dur_15_1day
            avg_pct = row[2]
            sample_count = row[3]
            
            # è§£æ period_type
            parts = period_type.split('_')
            if len(parts) != 3:
                continue
            
            duration = int(parts[1])
            period = parts[2]  # 1day, 3day, 7day, 15day
            
            # è¿‡æ»¤ duration
            if duration_filter and duration != duration_filter:
                continue
            
            if pos not in duration_data:
                duration_data[pos] = {}
            if duration not in duration_data[pos]:
                duration_data[pos][duration] = {}
            
            duration_data[pos][duration][period] = {
                'avg': avg_pct,
                'samples': sample_count
            }
        
        # åˆ†ææ¯ä¸ª position å’Œ duration çš„ä¿¡å·
        for pos in duration_data:
            for duration in sorted(duration_data[pos].keys()):
                periods = duration_data[pos][duration]
                
                # å¿…é¡»æœ‰ 1day å’Œ 3day æ•°æ®æ‰èƒ½å¯¹æ¯”
                if '1day' not in periods or '3day' not in periods:
                    continue
                
                avg_1day = periods['1day']['avg']
                avg_3day = periods['3day']['avg']
                avg_7day = periods.get('7day', {}).get('avg', None)
                avg_15day = periods.get('15day', {}).get('avg', None)
                
                # è®¡ç®—æ¯”å€¼
                ratio = (avg_1day / avg_3day) if avg_3day != 0 else 1.0
                ratio_change = avg_1day - avg_3day
                ratio_change_percent = ((avg_1day - avg_3day) / avg_3day * 100) if avg_3day != 0 else 0
                
                # æ ¹æ®ç”¨æˆ·é€»è¾‘åˆ¤æ–­ä¿¡å·
                if pos == 'long':
                    if avg_1day < avg_3day:  # æ¯”å€¼å‡å°
                        signal_type = 'strong_long'
                        signal_desc = 'å¼ºåŠ¿å¤šå¤´'
                        bias = 'bullish'  # åå¤š
                        interpretation = 'å½“å¤©å¹³å‡ < 3å¤©å¹³å‡ï¼Œå˜åŒ–ç‡å‡å°ï¼Œè¶‹åŠ¿å¼ºåŠ²'
                    else:  # æ¯”å€¼å¢å¤§
                        signal_type = 'top_acceleration'
                        signal_desc = 'åŠ é€Ÿèµ¶é¡¶'
                        bias = 'bearish'  # åç©º
                        interpretation = 'å½“å¤©å¹³å‡ > 3å¤©å¹³å‡ï¼Œå˜åŒ–ç‡å¢å¤§ï¼Œå¯èƒ½è§é¡¶'
                else:  # short
                    if avg_1day < avg_3day:  # æ¯”å€¼å‡å°
                        signal_type = 'strong_short'
                        signal_desc = 'å¼ºåŠ¿ç©ºå¤´'
                        bias = 'bearish'  # åç©º
                        interpretation = 'å½“å¤©å¹³å‡ < 3å¤©å¹³å‡ï¼Œå˜åŒ–ç‡å‡å°ï¼Œè¶‹åŠ¿å¼ºåŠ²'
                    else:  # æ¯”å€¼å¢å¤§
                        signal_type = 'bottom_acceleration'
                        signal_desc = 'åŠ é€Ÿèµ¶åº•'
                        bias = 'bullish'  # åå¤š
                        interpretation = 'å½“å¤©å¹³å‡ > 3å¤©å¹³å‡ï¼Œå˜åŒ–ç‡å¢å¤§ï¼Œå¯èƒ½è§åº•'
                
                signal = {
                    'position': pos,
                    'duration_minutes': duration,
                    'averages': {
                        '1day': round(avg_1day, 6),
                        '3day': round(avg_3day, 6),
                        '7day': round(avg_7day, 6) if avg_7day else None,
                        '15day': round(avg_15day, 6) if avg_15day else None
                    },
                    'comparison': {
                        'ratio': round(ratio, 4),
                        'change': round(ratio_change, 6),
                        'change_percent': round(ratio_change_percent, 2)
                    },
                    'signal': {
                        'type': signal_type,
                        'description': signal_desc,
                        'bias': bias,
                        'interpretation': interpretation
                    },
                    'sample_counts': {
                        '1day': periods['1day']['samples'],
                        '3day': periods['3day']['samples'],
                        '7day': periods.get('7day', {}).get('samples', None),
                        '15day': periods.get('15day', {}).get('samples', None)
                    }
                }
                
                result['signals'].append(signal)
        
        result['total_signals'] = len(result['signals'])
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/transition-analysis/<symbol>')
def sar_slope_transition_analysis(symbol):
    """
    å¤šç©ºè½¬æ¢åˆ†ææ¥å£ - ç”¨æˆ·æœ€æ–°éœ€æ±‚
    
    æ ¸å¿ƒé€»è¾‘:
    1. è®°å½•æ¯ä¸ª5åˆ†é’Ÿçš„å¤šç©ºè½¬æ¢ç‚¹ï¼ˆä¿ç•™16å¤©æ•°æ®ï¼‰
    2. å¤šå¤´å…³æ³¨ sequence_num=2 (01â†’02ï¼Œç›¸å½“äº03â†’02çš„å˜åŒ–)
    3. ç©ºå¤´å…³æ³¨ sequence_num=2 (01â†’02ï¼Œç›¸å½“äº02â†’03çš„å˜åŒ–)
    4. è®¡ç®— å½“å¤©/3å¤©/7å¤©/15å¤© å¹³å‡å€¼
    5. å¯¹æ¯”å½“å‰å€¼ä¸å¹³å‡å€¼çš„å·®å€¼ç™¾åˆ†æ¯”
    6. åˆ¤æ–­åå¤š/åç©ºçŠ¶æ€
    
    å‚æ•°:
    - position: long/short (å¯é€‰)
    """
    try:
        position_filter = request.args.get('position', None)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'analysis': {}
        }
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence, last_kline_time
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        # è·å–å½“å‰ä»·æ ¼å’ŒæŒç»­æ—¶é—´
        cursor.execute('''
            SELECT close_price, duration_minutes
            FROM sar_raw_data
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT 1
        ''', (symbol.upper(),))
        
        price_data = cursor.fetchone()
        current_price = price_data[0] if price_data else None
        current_duration = price_data[1] if price_data else None
        
        result['current_status'] = {
            'position': status[0],
            'sequence': status[1],
            'last_update': status[2],
            'current_price': round(current_price, 2) if current_price else None,
            'duration_minutes': current_duration
        }
        
        # å¯¹æ¯ä¸ªæ–¹å‘è¿›è¡Œåˆ†æ
        positions = [position_filter] if position_filter else ['long', 'short']
        
        for pos in positions:
            # è·å–è¯¥æ–¹å‘ sequence_num=2 çš„æ‰€æœ‰å˜åŒ–ç‡æ•°æ®ï¼ˆæŒ‰æ—¶é—´é™åºï¼‰
            cursor.execute('''
                SELECT change_percent, kline_time, id
                FROM sar_consecutive_changes
                WHERE symbol = ? AND position = ? AND sequence_num = 2
                ORDER BY id DESC
            ''', (symbol.upper(), pos))
            
            changes = cursor.fetchall()
            
            if not changes:
                continue
            
            # å½“å‰æœ€æ–°å€¼
            current_value = changes[0][0]
            current_time = changes[0][1]
            
            # æå–æ‰€æœ‰å˜åŒ–ç‡ï¼ˆä»æ—§åˆ°æ–°ï¼‰
            all_changes = [c[0] for c in reversed(changes)]
            
            # è®¡ç®—å„å‘¨æœŸå¹³å‡å€¼
            periods = {
                '1day': 288,   # 24å°æ—¶ * 12ä¸ª5åˆ†é’Ÿ
                '3day': 864,   # 3 * 24 * 12
                '7day': 2016,  # 7 * 24 * 12
                '15day': 4320  # 15 * 24 * 12
            }
            
            period_averages = {}
            for period_name, period_count in periods.items():
                if len(all_changes) >= period_count:
                    period_changes = all_changes[-period_count:]
                else:
                    period_changes = all_changes
                
                if period_changes:
                    avg = sum(period_changes) / len(period_changes)
                    period_averages[period_name] = {
                        'average': avg,
                        'sample_count': len(period_changes)
                    }
            
            # å¯¹æ¯”å½“å‰å€¼ä¸å„å‘¨æœŸå¹³å‡å€¼
            comparisons = {}
            for period_name, period_data in period_averages.items():
                avg = period_data['average']
                diff = current_value - avg
                diff_percent = (diff / avg * 100) if avg != 0 else 0
                
                # åˆ¤æ–­è¶‹åŠ¿
                if diff > 0:
                    trend = 'increased'  # å¢åŠ 
                    trend_cn = 'å¢åŠ '
                elif diff < 0:
                    trend = 'decreased'  # å‡å°‘
                    trend_cn = 'å‡å°‘'
                else:
                    trend = 'unchanged'
                    trend_cn = 'æŒå¹³'
                
                comparisons[period_name] = {
                    'period_average': round(avg, 6),
                    'current_value': round(current_value, 6),
                    'difference': round(diff, 6),
                    'difference_percent': round(diff_percent, 2),
                    'trend': trend,
                    'trend_cn': trend_cn,
                    'sample_count': period_data['sample_count']
                }
            
            # ç»¼åˆåˆ¤æ–­åå¤š/åç©ºçŠ¶æ€
            # ä½¿ç”¨ 1å¤© å’Œ 3å¤© çš„å¯¹æ¯”ç»“æœ
            bias = None
            bias_reason = []
            
            if '1day' in comparisons and '3day' in comparisons:
                day1_diff = comparisons['1day']['difference_percent']
                day3_diff = comparisons['3day']['difference_percent']
                
                # å¦‚æœå½“å‰å€¼é«˜äºå¹³å‡å€¼ï¼Œè¯´æ˜å˜åŒ–ç‡åœ¨å¢å¤§
                # å¦‚æœå½“å‰å€¼ä½äºå¹³å‡å€¼ï¼Œè¯´æ˜å˜åŒ–ç‡åœ¨å‡å°
                
                if pos == 'long':
                    # å¤šå¤´åŒºé—´ï¼šå˜åŒ–ç‡å¢å¤§ â†’ åç©ºï¼ˆå¯èƒ½èµ¶é¡¶ï¼‰
                    #          å˜åŒ–ç‡å‡å° â†’ åå¤šï¼ˆè¶‹åŠ¿ç¨³å¥ï¼‰
                    if day1_diff > 0 and day3_diff > 0:
                        bias = 'bearish'
                        bias_cn = 'åç©º'
                        bias_reason.append('å¤šå¤´å˜åŒ–ç‡å¢å¤§ï¼Œå¯èƒ½åŠ é€Ÿèµ¶é¡¶')
                    elif day1_diff < 0 and day3_diff < 0:
                        bias = 'bullish'
                        bias_cn = 'åå¤š'
                        bias_reason.append('å¤šå¤´å˜åŒ–ç‡å‡å°ï¼Œè¶‹åŠ¿ç¨³å¥')
                    else:
                        bias = 'neutral'
                        bias_cn = 'ä¸­æ€§'
                        bias_reason.append('å¤šå¤´ä¿¡å·ä¸æ˜ç¡®')
                else:  # short
                    # ç©ºå¤´åŒºé—´ï¼šå˜åŒ–ç‡å¢å¤§ â†’ åå¤šï¼ˆå¯èƒ½èµ¶åº•ï¼‰
                    #          å˜åŒ–ç‡å‡å° â†’ åç©ºï¼ˆè¶‹åŠ¿ç¨³å¥ï¼‰
                    if day1_diff > 0 and day3_diff > 0:
                        bias = 'bullish'
                        bias_cn = 'åå¤š'
                        bias_reason.append('ç©ºå¤´å˜åŒ–ç‡å¢å¤§ï¼Œå¯èƒ½åŠ é€Ÿèµ¶åº•')
                    elif day1_diff < 0 and day3_diff < 0:
                        bias = 'bearish'
                        bias_cn = 'åç©º'
                        bias_reason.append('ç©ºå¤´å˜åŒ–ç‡å‡å°ï¼Œè¶‹åŠ¿ç¨³å¥')
                    else:
                        bias = 'neutral'
                        bias_cn = 'ä¸­æ€§'
                        bias_reason.append('ç©ºå¤´ä¿¡å·ä¸æ˜ç¡®')
            
            result['analysis'][pos] = {
                'position': pos,
                'position_cn': 'å¤šå¤´' if pos == 'long' else 'ç©ºå¤´',
                'sequence_info': '01â†’02 (åºåˆ—2)',
                'current_value': round(current_value, 6),
                'current_time': current_time,
                'total_samples': len(all_changes),
                'period_comparisons': comparisons,
                'bias': {
                    'type': bias,
                    'type_cn': bias_cn,
                    'reason': bias_reason
                }
            }
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/current-cycle/<symbol>')
def sar_slope_current_cycle(symbol):
    """
    è·å–å½“å‰å®Œæ•´å‘¨æœŸçš„æ‰€æœ‰åºåˆ—æ•°æ®
    
    ç”¨æˆ·éœ€æ±‚:
    - ç©ºå¤´01å¼€å§‹æ˜¾ç¤ºï¼Œä¸€ç›´åˆ°ç©ºå¤´è½¬å¤šå¤´
    - å¤šå¤´01å¼€å§‹æ˜¾ç¤ºï¼Œä¸€ç›´åˆ°å¤šå¤´è½¬ç©ºå¤´
    - ä¸æ˜¾ç¤ºæŒç»­æ—¶é—´å­—æ®µ
    
    è¿”å›å½“å‰å‘¨æœŸä»åºåˆ—01åˆ°å½“å‰åºåˆ—çš„å®Œæ•´æ•°æ®
    """
    # æ£€æŸ¥æœåŠ¡å™¨ç«¯ç¼“å­˜
    cache_key = f"sar_slope_current_cycle:{symbol.upper()}"
    cached_data = server_cache.get(cache_key, max_age=30)
    if cached_data:
        cached_data['_from_server_cache'] = True
        cached_data['_cache_age'] = int(time.time() - server_cache.timestamps.get(cache_key, 0))
        response = jsonify(cached_data)
        # æ·»åŠ é˜²ç¼“å­˜å¤´
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        return response
    
    try:
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence, last_kline_time
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        current_position = status[0]
        current_sequence = status[1]
        last_update = status[2]
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„è¿ç»­æ•°æ®ï¼ˆä¸é™åˆ¶å‘¨æœŸï¼Œæ˜¾ç¤º16å¤©æˆ–æ‰€æœ‰å¯ç”¨æ•°æ®ï¼‰
        # è®¡ç®—16å¤©éœ€è¦çš„è®°å½•æ•°ï¼š16å¤© * 288æ¡/å¤© = 4608æ¡
        max_records = 4608  # 16å¤©çš„æ•°æ®
        cursor.execute('''
            SELECT position_sequence, close_price, kline_time, 
                   open_price, high_price, low_price, sar_value, position
            FROM sar_raw_data
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (symbol.upper(), max_records))
        
        raw_sequences = []
        rows = cursor.fetchall()  # ä»æ–°åˆ°æ—§
        for row in rows:  # ä¸åè½¬ï¼Œä¿æŒæœ€æ–°çš„åœ¨å‰
            seq, close, kline_time, open_p, high, low, sar, pos = row
            raw_sequences.append({
                'sequence': seq,
                'price': round(close, 2),
                'time': kline_time,
                'open': round(open_p, 2),
                'high': round(high, 2),
                'low': round(low, 2),
                'sar': sar,  # ä¿ç•™å®Œæ•´ç²¾åº¦ç”¨äºè®¡ç®—
                'position': pos  # è®°å½•è¯¥æ¡æ•°æ®çš„positionï¼ˆlong/shortï¼‰
            })
        
        # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ä¸€æ¬¡æ€§æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰å†å²æ•°æ®ï¼Œé¿å…åœ¨å¾ªç¯ä¸­é‡å¤æŸ¥è¯¢
        # è·å–æ‰€æœ‰éœ€è¦çš„å†å²å¹³å‡æ•°æ®
        cursor.execute('''
            SELECT position, sequence_num, change_percent
            FROM sar_consecutive_changes
            WHERE symbol = ?
            ORDER BY id DESC
            LIMIT 4320
        ''', (symbol.upper(),))
        
        # æ„å»ºå†å²æ•°æ®å­—å…¸ï¼š{(position, seq_num): [change_percent, ...]}
        historical_data_dict = {}
        for row in cursor.fetchall():
            pos, seq_num, change_pct = row
            key = (pos, seq_num)
            if key not in historical_data_dict:
                historical_data_dict[key] = []
            historical_data_dict[key].append(change_pct)
        
        # è®¡ç®—æ¯ä¸ªåºåˆ—ç›¸å¯¹äºå‰ä¸€ä¸ªåºåˆ—çš„å˜åŒ–ç‡
        # æ³¨æ„ï¼šç°åœ¨raw_sequences[0]æ˜¯æœ€æ–°çš„ï¼Œraw_sequences[-1]æ˜¯æœ€æ—©çš„
        sequences_with_changes = []
        for i, seq_data in enumerate(raw_sequences):
            seq_num = seq_data['sequence']
            
            # è·å–å½“å‰è¡Œçš„position
            row_position = seq_data['position']
            
            # æ·»åŠ åŸºç¡€æ•°æ®
            result_data = {
                'sequence': seq_num,
                'price': seq_data['price'],
                'time': seq_data['time'],
                'open': seq_data['open'],
                'high': seq_data['high'],
                'low': seq_data['low'],
                'sar': round(seq_data['sar'], 4),
                'position': row_position,  # æ·»åŠ positionå­—æ®µç”¨äºå‰ç«¯åˆ¤æ–­
                'position_cn': 'å¤šå¤´' if row_position == 'long' else 'ç©ºå¤´'
            }
            
            # å¦‚æœæœ‰ä¸‹ä¸€ä¸ªåºåˆ—ï¼ˆæ—¶é—´æ›´æ—©çš„ï¼‰ï¼Œä¸”positionç›¸åŒæ‰è®¡ç®—å˜åŒ–ç‡
            if i < len(raw_sequences) - 1:
                next_position = raw_sequences[i+1]['position']
                
                # åªæœ‰å½“å‰åä¸¤æ¡æ•°æ®çš„positionç›¸åŒæ—¶æ‰è®¡ç®—å˜åŒ–ç‡
                # å¦‚æœpositionä¸åŒï¼Œè¯´æ˜å‘ç”Ÿäº†å¤šç©ºè½¬æ¢ï¼Œè·³è¿‡è®¡ç®—
                if row_position == next_position:
                    next_sar = raw_sequences[i+1]['sar']  # ä¸‹ä¸€ä¸ªï¼ˆæ—¶é—´æ›´æ—©ï¼‰
                    curr_sar = seq_data['sar']  # å½“å‰ï¼ˆæ—¶é—´æ›´æ–°ï¼‰
                    
                    # ç”¨æˆ·éœ€æ±‚çš„è®¡ç®—å…¬å¼:
                    # å½“å‰æ˜¯è¾ƒæ–°çš„åºåˆ—å·ï¼Œnextæ˜¯è¾ƒæ—§çš„åºåˆ—å·
                    # ä¾‹å¦‚ï¼šcurr=ç©º03, next=ç©º02
                    # å¤šå¤´: (å½“å‰SAR - å‰ä¸€ä¸ªSAR) / å½“å‰SAR
                    # ç©ºå¤´: (å‰ä¸€ä¸ªSAR - å½“å‰SAR) / å‰ä¸€ä¸ªSAR
                    if row_position == 'long':
                        # å¤šå¤´: (curr - next) / curr
                        seq_change_percent = ((curr_sar - next_sar) / curr_sar) * 100 if curr_sar != 0 else 0
                        sar_absolute_diff = curr_sar - next_sar  # SARç»å¯¹å·®å€¼
                    else:  # short
                        # ç©ºå¤´: (next - curr) / next
                        # æ³¨æ„ï¼šè¿™é‡Œnextæ˜¯æ—§åºåˆ—ï¼ˆåºåˆ—å·å°ï¼‰ï¼Œcurræ˜¯æ–°åºåˆ—ï¼ˆåºåˆ—å·å¤§ï¼‰
                        # ä½†SARå€¼è®¡ç®—æ—¶ï¼Œnextçš„SARåº”è¯¥æ¯”currçš„SARå¤§
                        seq_change_percent = ((next_sar - curr_sar) / next_sar) * 100 if next_sar != 0 else 0
                        sar_absolute_diff = next_sar - curr_sar  # SARç»å¯¹å·®å€¼
                    
                    result_data['sequence_change_percent'] = round(seq_change_percent, 4)
                    result_data['sar_diff'] = round(sar_absolute_diff, 4)  # SARå€¼çš„ç»å¯¹å·®å€¼
                    
                    # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ä»é¢„åŠ è½½çš„å­—å…¸ä¸­è·å–å†å²æ•°æ®ï¼Œè€Œä¸æ˜¯é‡å¤æŸ¥è¯¢æ•°æ®åº“
                    lookup_key = (row_position, seq_num)
                    historical_changes = historical_data_dict.get(lookup_key, [])[:288]  # æœ€å¤šå–288æ¡ï¼ˆ1å¤©ï¼‰
                    if historical_changes:
                        avg_1day = sum(historical_changes) / len(historical_changes)
                        avg_3day = sum(historical_changes[:min(864, len(historical_changes))]) / min(864, len(historical_changes)) if len(historical_changes) >= 1 else avg_1day
                        avg_7day = sum(historical_changes[:min(2016, len(historical_changes))]) / min(2016, len(historical_changes)) if len(historical_changes) >= 1 else avg_1day
                        avg_15day = sum(historical_changes[:min(4320, len(historical_changes))]) / min(4320, len(historical_changes)) if len(historical_changes) >= 1 else avg_1day
                        
                        result_data['avg_1day'] = round(avg_1day, 6)
                        result_data['avg_3day'] = round(avg_3day, 6)
                        result_data['avg_7day'] = round(avg_7day, 6)
                        result_data['avg_15day'] = round(avg_15day, 6)
                        
                        # è®¡ç®—ç›¸å¯¹å˜åŒ–ç™¾åˆ†æ¯”ï¼š(å½“å‰ - å¹³å‡) / å¹³å‡ Ã— 100
                        # ä¾‹: å½“å‰0.0613%, å¹³å‡0.083284%, å˜åŒ– = (0.0613-0.083284)/0.083284*100 = -26.40%
                        if avg_1day != 0:
                            change_1day_percent = ((seq_change_percent - avg_1day) / avg_1day) * 100
                        else:
                            change_1day_percent = 0
                        
                        if avg_3day != 0:
                            change_3day_percent = ((seq_change_percent - avg_3day) / avg_3day) * 100
                        else:
                            change_3day_percent = 0
                        
                        if avg_7day != 0:
                            change_7day_percent = ((seq_change_percent - avg_7day) / avg_7day) * 100
                        else:
                            change_7day_percent = 0
                        
                        if avg_15day != 0:
                            change_15day_percent = ((seq_change_percent - avg_15day) / avg_15day) * 100
                        else:
                            change_15day_percent = 0
                        
                        # åŒæ—¶ä¿ç•™ç»å¯¹å·®å€¼ï¼ˆç”¨äºåå‘åˆ¤æ–­ï¼‰
                        diff_1day = seq_change_percent - avg_1day
                        
                        result_data['change_1day_percent'] = round(change_1day_percent, 2)
                        result_data['change_3day_percent'] = round(change_3day_percent, 2)
                        result_data['change_7day_percent'] = round(change_7day_percent, 2)
                        result_data['change_15day_percent'] = round(change_15day_percent, 2)
                        
                        # åˆ¤æ–­åå‘ï¼ˆä½¿ç”¨å½“å‰è¡Œçš„positionï¼‰
                        if row_position == 'long':
                            bias = 'åå¤š' if diff_1day < 0 else 'åç©º'
                        else:
                            bias = 'åç©º' if diff_1day < 0 else 'åå¤š'
                        
                        result_data['bias'] = bias
            
            sequences_with_changes.append(result_data)
        
        # è®¡ç®—æœ€è¿‘2å°æ—¶çš„åå¤š/åç©ºæ¯”ä¾‹
        # 2å°æ—¶ = 24æ¡æ•°æ®ï¼ˆæ¯5åˆ†é’Ÿä¸€æ¡ï¼‰
        recent_2hours = sequences_with_changes[:24]  # å–æœ€æ–°çš„24æ¡æ•°æ®
        
        bias_bullish_count = 0  # åå¤šæ•°é‡
        bias_bearish_count = 0  # åç©ºæ•°é‡
        bias_neutral_count = 0  # ä¸­æ€§ï¼ˆæ— åå‘æˆ–"-"ï¼‰
        
        for seq in recent_2hours:
            if 'bias' in seq and seq['bias']:
                if seq['bias'] == 'åå¤š':
                    bias_bullish_count += 1
                elif seq['bias'] == 'åç©º':
                    bias_bearish_count += 1
                else:
                    bias_neutral_count += 1
            else:
                bias_neutral_count += 1
        
        total_with_bias = bias_bullish_count + bias_bearish_count
        bias_stats = {
            'period': '2å°æ—¶',
            'total_records': len(recent_2hours),
            'bullish_count': bias_bullish_count,
            'bearish_count': bias_bearish_count,
            'neutral_count': bias_neutral_count,
            'bullish_ratio': round((bias_bullish_count / total_with_bias * 100), 2) if total_with_bias > 0 else 0,
            'bearish_ratio': round((bias_bearish_count / total_with_bias * 100), 2) if total_with_bias > 0 else 0
        }
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'current_status': {
                'position': current_position,
                'position_cn': 'å¤šå¤´' if current_position == 'long' else 'ç©ºå¤´',
                'current_sequence': current_sequence,
                'last_update': last_update,
                'cycle_info': f"{current_position}01 â†’ {current_position}{current_sequence:02d}"
            },
            'bias_statistics': bias_stats,  # æ–°å¢ï¼š2å°æ—¶åå‘ç»Ÿè®¡
            'sequences': sequences_with_changes,
            'total_sequences': len(sequences_with_changes)
        }
        
        # ä¿å­˜åˆ°æœåŠ¡å™¨ç«¯ç¼“å­˜
        server_cache.set(cache_key, result)
        
        conn.close()
        response = jsonify(result)
        # æ·»åŠ é˜²ç¼“å­˜å¤´ï¼Œé¿å…å¤–éƒ¨ä»£ç†ç¼“å­˜æ—§çš„500é”™è¯¯
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        return response
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ============================================
# SARåå‘è¶‹åŠ¿API
# ============================================
@app.route('/sar-bias-trend')
def sar_bias_trend_page():
    """SARåå‘è¶‹åŠ¿å›¾é¡µé¢"""
    return render_template('sar_bias_trend.html')

@app.route('/api/sar-slope/bias-trend')
def sar_slope_bias_trend():
    """è·å–SARåå‘è¶‹åŠ¿æ•°æ®ï¼ˆ12å°æ—¶åˆ†é¡µï¼‰"""
    try:
        from datetime import datetime, timezone, timedelta
        import json
        
        # è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', 1, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        # åŒ—äº¬æ—¶åŒº
        beijing_tz = timezone(timedelta(hours=8))
        
        # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆæ¯é¡µ12å°æ—¶ï¼‰
        # page=1: æœ€è¿‘12å°æ—¶
        # page=2: 12-24å°æ—¶å‰
        # page=3: 24-36å°æ—¶å‰
        hours_end = (page - 1) * 12
        hours_start = page * 12
        
        # è·å–æŒ‡å®šé¡µçš„12å°æ—¶æ•°æ®ï¼ˆæ•°æ®åº“å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼Œéœ€è¦+8å°æ—¶æ¥åŒ¹é…ï¼‰
        cursor.execute('''
        SELECT 
            timestamp,
            bullish_count,
            bearish_count,
            total_symbols,
            bullish_symbols,
            bearish_symbols
        FROM sar_bias_trend
        WHERE datetime(timestamp) >= datetime('now', '+8 hours', '-' || ? || ' hours')
          AND datetime(timestamp) < datetime('now', '+8 hours', '-' || ? || ' hours')
        ORDER BY timestamp ASC
        ''', (hours_start, hours_end))
        
        rows = cursor.fetchall()
        
        # è·å–æ€»é¡µæ•°ï¼ˆåŸºäºæ‰€æœ‰æ•°æ®ï¼‰
        cursor.execute('SELECT MIN(timestamp) FROM sar_bias_trend')
        min_timestamp = cursor.fetchone()[0]
        
        total_pages = 1
        if min_timestamp:
            # è®¡ç®—æœ€æ—©æ•°æ®è·ä»Šçš„å°æ—¶æ•°ï¼ˆä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼‰
            cursor.execute("SELECT (julianday('now', '+8 hours') - julianday(?)) * 24", (min_timestamp,))
            hours_diff = cursor.fetchone()[0]
            total_pages = max(1, int(hours_diff / 12) + 1)
        
        conn.close()
        
        data = []
        for row in rows:
            # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼ˆå¦‚æœéœ€è¦ï¼‰
            timestamp_str = row[0]
            data.append({
                'timestamp': timestamp_str,
                'bullish_count': row[1],
                'bearish_count': row[2],
                'total_symbols': row[3],
                'bullish_symbols': json.loads(row[4]) if row[4] else [],
                'bearish_symbols': json.loads(row[5]) if row[5] else []
            })
        
        # è·å–å½“å‰é¡µçš„æ—¶é—´èŒƒå›´ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        time_range = {
            'start': '',
            'end': ''
        }
        if data:
            time_range['start'] = data[0]['timestamp']
            time_range['end'] = data[-1]['timestamp']
        
        return jsonify({
            'success': True,
            'data': data,
            'total': len(data),
            'page': page,
            'total_pages': total_pages,
            'time_range': time_range,
            'has_prev': page < total_pages,
            'has_next': page > 1
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


# ============================================
# ç¼“å­˜ç®¡ç†API
# ============================================
@app.route('/api/cache/stats')
def cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    stats = server_cache.get_stats()
    return jsonify({
        'success': True,
        'cache_stats': stats,
        'message': 'æœåŠ¡å™¨ç«¯ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯'
    })

@app.route('/api/cache/clear', methods=['POST'])
def cache_clear():
    """æ¸…é™¤æœåŠ¡å™¨ç«¯ç¼“å­˜"""
    try:
        key = request.json.get('key') if request.json else None
        server_cache.clear(key)
        return jsonify({
            'success': True,
            'message': f'ç¼“å­˜å·²æ¸…é™¤{"ï¼ˆé”®: " + key + "ï¼‰" if key else "ï¼ˆå…¨éƒ¨ï¼‰"}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ========== é”šç‚¹ç³»ç»Ÿï¼ˆOKExæŒä»“ç›‘æ§ï¼‰ ==========

@app.route('/warning-test')
def warning_test():
    """é¢„è­¦æ¨¡å—æµ‹è¯•é¡µé¢"""
    return render_template('warning_test.html')

@app.route('/anchor-system')
def anchor_system():
    """é”šç‚¹ç³»ç»Ÿä¸»é¡µ - é‡å®šå‘åˆ°å®ç›˜"""
    return redirect('/anchor-system-real')

@app.route('/anchor-system-real')
def anchor_system_real():
    """å®ç›˜é”šç‚¹ç³»ç»Ÿ"""
    response = make_response(render_template('anchor_system_real.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/anchor-snapshots')
def anchor_snapshots():
    """é”šç‚¹ç³»ç»Ÿå†å²å¿«ç…§æŸ¥çœ‹"""
    response = make_response(render_template('anchor_snapshots.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response


@app.route('/api/anchor-system/real/hourly-extreme-stats')
def get_real_hourly_extreme_stats():
    """è·å–å®ç›˜é”šç‚¹ç³»ç»Ÿæœ€è¿‘1å°æ—¶çš„æå€¼ç»Ÿè®¡ï¼ˆåªç»Ÿè®¡æ¯ä¸ªå¸ç§çš„æœ€æ–°æå€¼ï¼‰"""
    try:
        from datetime import datetime, timedelta
        import pytz
        
        db_path = '/home/user/webapp/anchor_system.db'
        conn = sqlite3.connect(db_path, timeout=10.0)
        cursor = conn.cursor()
        
        # ä½¿ç”¨åŒ—äº¬æ—¶åŒº
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now_beijing = datetime.now(beijing_tz)
        one_hour_ago_beijing = now_beijing - timedelta(hours=1)
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆæ•°æ®åº“ä¸­å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼‰
        one_hour_ago_str = one_hour_ago_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        # è·å–æ‰€æœ‰è®°å½•
        cursor.execute("""
            SELECT inst_id, pos_side, record_type, profit_rate, timestamp
            FROM anchor_real_profit_records
            ORDER BY timestamp DESC
        """)
        
        all_records = cursor.fetchall()
        
        # æŒ‰å¸ç§ã€æ–¹å‘ã€ç±»å‹åˆ†ç»„ï¼Œåªä¿ç•™æœ€æ–°çš„è®°å½•
        latest_records = {}
        for record in all_records:
            inst_id, pos_side, record_type, profit_rate, timestamp = record
            key = (inst_id, pos_side, record_type)
            if key not in latest_records:
                latest_records[key] = record
        
        # ç»Ÿè®¡æœ€è¿‘1å°æ—¶å†…çš„æœ€æ–°æå€¼
        stats = {
            'short_max_profit': 0,  # ç©ºå•åˆ©æ¶¦åˆ›æ–°é«˜
            'short_max_loss': 0,    # ç©ºå•äºæŸåˆ›æ–°é«˜
            'long_max_profit': 0,   # å¤šå•åˆ©æ¶¦åˆ›æ–°é«˜
            'long_max_loss': 0      # å¤šå•äºæŸåˆ›æ–°é«˜
        }
        
        for key, record in latest_records.items():
            inst_id, pos_side, record_type, profit_rate, timestamp = record
            if timestamp >= one_hour_ago_str:
                if pos_side == 'short' and record_type == 'max_profit':
                    stats['short_max_profit'] += 1
                elif pos_side == 'short' and record_type == 'max_loss':
                    stats['short_max_loss'] += 1
                elif pos_side == 'long' and record_type == 'max_profit':
                    stats['long_max_profit'] += 1
                elif pos_side == 'long' and record_type == 'max_loss':
                    stats['long_max_loss'] += 1
        
        conn.close()
        
        return jsonify({
            'success': True,
            'time_range': f'æœ€è¿‘1å°æ—¶ (>{one_hour_ago_str})',
            'current_time': now_beijing.strftime('%Y-%m-%d %H:%M:%S'),
            'stats': stats,
            'note': 'åªç»Ÿè®¡æ¯ä¸ªå¸ç§çš„æœ€æ–°æå€¼è®°å½•ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/anchor-system-paper')
def anchor_system_paper():
    """æ¨¡æ‹Ÿç›˜é”šç‚¹ç³»ç»Ÿ"""
    response = make_response(render_template('anchor_system_paper.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response


@app.route('/anchor-system-v2')
def anchor_system_v2():
    """é”šç‚¹ç³»ç»Ÿä¸»é¡µ v2 (æ–°URLé¿å…ç¼“å­˜)"""
    response = make_response(render_template('anchor_system.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/api/anchor-system/monitors')
def get_anchor_monitors():
    """è·å–æŒä»“ç›‘æ§è®°å½•"""
    try:
        limit = request.args.get('limit', 100, type=int)
        db_path = '/home/user/webapp/anchor_system.db'
        
        conn = sqlite3.connect(db_path, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT * FROM anchor_monitors 
        ORDER BY timestamp DESC 
        LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        monitors = []
        for row in rows:
            monitors.append({
                'id': row['id'],
                'timestamp': row['timestamp'],
                'inst_id': row['inst_id'],
                'pos_side': row['pos_side'],
                'pos_size': row['pos_size'],
                'avg_price': row['avg_price'],
                'mark_price': row['mark_price'],
                'upl': row['upl'],
                'upl_ratio': row['upl_ratio'],
                'margin': row['margin'],
                'leverage': row['leverage'],
                'profit_rate': row['profit_rate'],
                'alert_type': row['alert_type'],
                'alert_sent': row['alert_sent']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': monitors,
            'total': len(monitors)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/alerts')
def get_anchor_alerts():
    """è·å–å‘Šè­¦å†å²"""
    try:
        limit = request.args.get('limit', 50, type=int)
        db_path = '/home/user/webapp/anchor_system.db'
        
        conn = sqlite3.connect(db_path, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT * FROM anchor_alerts 
        ORDER BY timestamp DESC 
        LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        alerts = []
        for row in rows:
            alerts.append({
                'id': row['id'],
                'timestamp': row['timestamp'],
                'inst_id': row['inst_id'],
                'pos_side': row['pos_side'],
                'profit_rate': row['profit_rate'],
                'alert_type': row['alert_type'],
                'message': row['message'],
                'sent_status': row['sent_status']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': alerts,
            'total': len(alerts)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/status')
def get_anchor_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        import json
        
        # è¯»å–é…ç½®
        config_path = '/home/user/webapp/anchor_config.json'
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # è·å–æœ€æ–°ç›‘æ§è®°å½•
        db_path = '/home/user/webapp/anchor_system.db'
        conn = sqlite3.connect(db_path, timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM anchor_monitors')
        total_monitors = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM anchor_alerts')
        total_alerts = cursor.fetchone()[0]
        
        cursor.execute('''
        SELECT * FROM anchor_monitors 
        ORDER BY timestamp DESC 
        LIMIT 1
        ''')
        latest = cursor.fetchone()
        
        conn.close()
        
        # ä½¿ç”¨é»˜è®¤é…ç½®å€¼ï¼ˆå› ä¸º anchor_config.json æ²¡æœ‰ monitor é”®ï¼‰
        return jsonify({
            'success': True,
            'status': {
                'total_monitors': total_monitors,
                'total_alerts': total_alerts,
                'latest_check': latest[1] if latest else None,
                'config': {
                    'profit_target': 40.0,  # é»˜è®¤ç›ˆåˆ©ç›®æ ‡ 40%
                    'loss_limit': -10.0,     # é»˜è®¤æ­¢æŸé™åˆ¶ -10%
                    'check_interval': 30,    # é»˜è®¤æ£€æŸ¥é—´éš” 30ç§’
                    'only_short': False      # é»˜è®¤æ”¯æŒå¤šç©º
                }
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/profit-records')
def get_anchor_profit_records():
    """è·å–å†å²æå€¼è®°å½• - å®ç›˜å’Œæ¨¡æ‹Ÿç›˜ä½¿ç”¨ä¸åŒçš„è¡¨"""
    try:
        inst_id = request.args.get('inst_id')
        pos_side = request.args.get('pos_side')
        trade_mode = request.args.get('trade_mode', 'real')  # é»˜è®¤å®ç›˜
        
        # æ ¹æ® trade_mode é€‰æ‹©ä¸åŒçš„è¡¨
        table_name = 'anchor_real_profit_records' if trade_mode == 'real' else 'anchor_paper_profit_records'
        
        db_path = '/home/user/webapp/anchor_system.db'
        conn = sqlite3.connect(db_path, timeout=10.0)
        cursor = conn.cursor()
        
        if inst_id and pos_side:
            # æŸ¥è¯¢ç‰¹å®šå¸ç§çš„è®°å½•
            cursor.execute(f'''
            SELECT record_type, profit_rate, timestamp, pos_size, avg_price, mark_price, upl, margin, leverage
            FROM {table_name}
            WHERE inst_id = ? AND pos_side = ?
            ORDER BY record_type
            ''', (inst_id, pos_side))
        else:
            # æŸ¥è¯¢æ‰€æœ‰è®°å½•
            cursor.execute(f'''
            SELECT inst_id, pos_side, record_type, profit_rate, timestamp, pos_size, avg_price, mark_price
            FROM {table_name}
            ORDER BY inst_id, pos_side, record_type
            ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        records = []
        if inst_id and pos_side:
            for row in rows:
                records.append({
                    'record_type': row[0],
                    'profit_rate': row[1],
                    'timestamp': row[2],
                    'pos_size': row[3],
                    'avg_price': row[4],
                    'mark_price': row[5],
                    'upl': row[6],
                    'margin': row[7],
                    'leverage': row[8]
                })
        else:
            for row in rows:
                records.append({
                    'inst_id': row[0],
                    'pos_side': row[1],
                    'record_type': row[2],
                    'profit_rate': row[3],
                    'timestamp': row[4],
                    'pos_size': row[5],
                    'avg_price': row[6],
                    'mark_price': row[7]
                })
        
        return jsonify({
            'success': True,
            'records': records,
            'total': len(records),
            'trade_mode': trade_mode
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/cleanup-extremes', methods=['POST'])
def cleanup_extreme_records():
    """æ¸…ç†é”™è¯¯çš„æå€¼è®°å½•ï¼ˆåˆ é™¤æ‰€æœ‰äºæŸè®°å½•ï¼‰"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from extreme_correction_system import (
            init_correction_system, backup_current_data,
            detect_error_records, delete_error_records, get_statistics
        )
        
        # åˆå§‹åŒ–
        from anchor_system import init_database
        init_database()
        init_correction_system()
        
        # å¤‡ä»½
        backup_count = backup_current_data()
        
        # æ£€æµ‹é”™è¯¯è®°å½•
        error_records = detect_error_records()
        
        if not error_records:
            return jsonify({
                'success': True,
                'message': 'æ²¡æœ‰å‘ç°é”™è¯¯è®°å½•',
                'backup_count': backup_count,
                'deleted_count': 0
            })
        
        # åˆ é™¤é”™è¯¯è®°å½•
        deleted_count = delete_error_records(error_records, "Webç«¯æ‰‹åŠ¨æ¸…ç†")
        
        # è·å–ç»Ÿè®¡
        stats = get_statistics()
        
        return jsonify({
            'success': True,
            'message': f'å·²æ¸…ç† {deleted_count} æ¡é”™è¯¯è®°å½•',
            'backup_count': backup_count,
            'deleted_count': deleted_count,
            'statistics': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/anchor-system/extreme-stats')
def get_extreme_stats():
    """è·å–æå€¼è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from extreme_correction_system import get_statistics, detect_error_records
        
        # è·å–ç»Ÿè®¡
        stats = get_statistics()
        
        # æ£€æµ‹é”™è¯¯è®°å½•
        error_records = detect_error_records()
        
        return jsonify({
            'success': True,
            'statistics': stats,
            'error_count': len(error_records),
            'has_errors': len(error_records) > 0
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/anchor-system/correction-log')
def get_correction_log():
    """è·å–çº é”™æ—¥å¿—"""
    try:
        limit = int(request.args.get('limit', 20))
        
        db_path = '/home/user/webapp/anchor_system.db'
        conn = sqlite3.connect(db_path, timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT id, correction_type, inst_id, pos_side, record_type,
               old_profit_rate, new_profit_rate, reason, created_at
        FROM extreme_corrections_log
        ORDER BY created_at DESC
        LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        logs = []
        for row in rows:
            logs.append({
                'id': row[0],
                'correction_type': row[1],
                'inst_id': row[2],
                'pos_side': row[3],
                'record_type': row[4],
                'old_profit_rate': row[5],
                'new_profit_rate': row[6],
                'reason': row[7],
                'created_at': row[8]
            })
        
        return jsonify({
            'success': True,
            'logs': logs,
            'total': len(logs)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/anchor-system/current-positions')
def get_current_positions():
    """è·å–å½“å‰æŒä»“æƒ…å†µ - æ¨¡æ‹Ÿç›˜ç›´æ¥è¯»å–æ•°æ®åº“ï¼Œå®ç›˜ä» OKEx API å®æ—¶è·å–"""
    try:
        import sys
        import sqlite3
        from datetime import datetime
        sys.path.append('/home/user/webapp')
        from anchor_system import get_positions, calculate_profit_rate
        
        # è·å–äº¤æ˜“æ¨¡å¼ï¼ˆé»˜è®¤ä¸º paper æ¨¡æ‹Ÿç›˜ï¼‰
        trade_mode = request.args.get('trade_mode', 'paper')
        
        # è¿æ¥æ•°æ®åº“ï¼Œè·å–ç»´æŠ¤åçš„å¼€ä»“ä»·æ ¼
        DB_PATH = '/home/user/webapp/trading_decision.db'
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ä»æ•°æ®åº“è¯»å–æ¨¡æ‹Ÿç›˜æ•°æ® - è”åˆæŸ¥è¯¢ç»´æŠ¤ä»·æ ¼è¡¨
        cursor.execute('''
            SELECT 
                p.inst_id, 
                p.pos_side, 
                COALESCE(amp.maintenance_price, p.open_price) as open_price,
                p.open_size, 
                p.updated_time, 
                p.mark_price, 
                p.profit_rate, 
                p.upl, 
                p.lever, 
                p.margin,
                amp.original_open_price,
                amp.maintenance_count,
                p.is_anchor
            FROM position_opens p
            LEFT JOIN anchor_maintenance_prices amp 
                ON p.inst_id = amp.inst_id 
                AND p.pos_side = amp.pos_side 
                AND p.trade_mode = amp.trade_mode
            WHERE p.trade_mode = ?
        ''', (trade_mode,))
        
        db_positions = cursor.fetchall()
        conn.close()
        
        # å¦‚æœæ˜¯æ¨¡æ‹Ÿç›˜ï¼Œç›´æ¥ä½¿ç”¨æ•°æ®åº“æ•°æ®
        if trade_mode == 'paper':
            position_list = []
            for row in db_positions:
                profit_rate = row['profit_rate'] if row['profit_rate'] is not None else 0.0
                
                # åˆ¤æ–­çŠ¶æ€
                status = 'ç›‘æ§ä¸­'
                status_class = 'normal'
                if profit_rate >= 40:
                    status = 'æ¥è¿‘ç›ˆåˆ©ç›®æ ‡'
                    status_class = 'profit'
                elif profit_rate <= -10:
                    status = 'æ¥è¿‘æ­¢æŸ'
                    status_class = 'loss'
                
                position_list.append({
                    'inst_id': row['inst_id'],
                    'pos_side': row['pos_side'],
                    'pos_size': abs(float(row['open_size'])),
                    'avg_price': float(row['open_price']),  # ç°åœ¨ä½¿ç”¨ç»´æŠ¤ä»·æ ¼
                    'mark_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'lever': int(row['lever']) if row['lever'] else 10,
                    'upl': float(row['upl']) if row['upl'] else 0.0,
                    'margin': float(row['margin']) if row['margin'] else 0.0,
                    'profit_rate': profit_rate,
                    'status': status,
                    'status_class': status_class,
                    'is_anchor': int(row['is_anchor']) if row['is_anchor'] else 0
                })
            
            return jsonify({
                'success': True,
                'positions': position_list,
                'total': len(position_list),
                'trade_mode': trade_mode
            })
        
        # å¦‚æœæ˜¯å®ç›˜ï¼Œä» OKEx API è·å–å®æ—¶æŒä»“
        okex_positions = get_positions()
        
        if not okex_positions or len(okex_positions) == 0:
            return jsonify({
                'success': True,
                'positions': [],
                'total': 0,
                'trade_mode': trade_mode
            })
        
        # å°†æ•°æ®åº“è®°å½•è½¬æ¢ä¸ºå­—å…¸
        db_positions_dict = {(row['inst_id'], row['pos_side']): row for row in db_positions}
        
        # è·å–ç»´æŠ¤æ¬¡æ•°ç»Ÿè®¡ï¼ˆä¸å†é™åˆ¶ä»Šæ—¥ï¼Œç»Ÿè®¡æ‰€æœ‰ç»´æŠ¤æ¬¡æ•°ï¼‰
        import json as json_lib
        from datetime import datetime
        from collections import defaultdict
        
        maintenance_file = 'maintenance_orders.json'
        maintenance_counts = defaultdict(int)
        
        if os.path.exists(maintenance_file):
            try:
                with open(maintenance_file, 'r', encoding='utf-8') as f:
                    maintenance_records = json_lib.load(f)
                
                # ä¸å†æŒ‰æ—¥æœŸè¿‡æ»¤ï¼Œç»Ÿè®¡æ‰€æœ‰ç»´æŠ¤æ¬¡æ•°
                for record in maintenance_records:
                    inst_id = record.get('inst_id', '')
                    pos_side = record.get('pos_side', '')
                    # ä½¿ç”¨ (inst_id, pos_side) ä½œä¸ºkeyï¼ŒåŒºåˆ†å¤šå•å’Œç©ºå•
                    key = (inst_id, pos_side)
                    maintenance_counts[key] += 1
            except Exception as e:
                print(f"è¯»å–ç»´æŠ¤è®°å½•å¤±è´¥: {e}")
        
        position_list = []
        for pos in okex_positions:
            inst_id = pos.get('instId')
            pos_side = pos.get('posSide')
            pos_value = float(pos.get('pos', 0))
            
            # è·³è¿‡æŒä»“é‡ä¸º0çš„
            if pos_value == 0:
                continue
            
            # æŸ¥æ‰¾æ•°æ®åº“è®°å½•ï¼ˆå¯èƒ½æ˜¯é”šç‚¹å•ï¼Œä¹Ÿå¯èƒ½ä¸æ˜¯ï¼‰
            db_record = db_positions_dict.get((inst_id, pos_side))
            
            # å®‰å…¨è½¬æ¢å‡½æ•°
            def safe_float(value, default=0):
                try:
                    if value == '' or value is None:
                        return default
                    return float(value)
                except (ValueError, TypeError):
                    return default
            
            def safe_int(value, default=10):
                try:
                    if value == '' or value is None:
                        return default
                    return int(value)
                except (ValueError, TypeError):
                    return default
            
            # è®¡ç®—æ•°æ®
            okex_avg_price = safe_float(pos.get('avgPx', 0))
            mark_price = safe_float(pos.get('markPx', 0))
            lever = safe_int(pos.get('lever', 10))
            upl = safe_float(pos.get('upl', 0))
            # ä½¿ç”¨ç†è®ºä¿è¯é‡‘ï¼šæŒä»“ä»·å€¼ / æ æ†
            # è¿™ä¸OKEx Webç•Œé¢æ˜¾ç¤ºçš„"ä¿è¯é‡‘"ä¸€è‡´
            pos_value_abs = abs(pos_value)  # æŒä»“æ•°é‡ï¼ˆç»å¯¹å€¼ï¼‰
            margin = (pos_value_abs * mark_price) / lever if lever > 0 and mark_price > 0 else 0.01
            
            # ç›´æ¥ä½¿ç”¨OKExçš„æ”¶ç›Šç‡ï¼ˆuplRatioï¼‰ï¼Œè½¬æ¢ä¸ºç™¾åˆ†æ¯”
            okex_profit_ratio = safe_float(pos.get('uplRatio', 0))
            profit_rate = okex_profit_ratio * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            
            # å¦‚æœæ•°æ®åº“ä¸­æœ‰è®°å½•ï¼Œä½¿ç”¨æ•°æ®åº“çš„å¼€ä»“ä»·æ ¼
            if db_record:
                avg_price = float(db_record['open_price'])
                is_anchor = int(db_record['is_anchor']) if db_record['is_anchor'] else 0
            else:
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨ OKEx çš„ä»·æ ¼ï¼Œæ ‡è®°ä¸ºéé”šç‚¹å•
                avg_price = okex_avg_price
                is_anchor = 0
            
            # åˆ¤æ–­çŠ¶æ€
            status = 'ç›‘æ§ä¸­'
            status_class = 'normal'
            if profit_rate >= 40:
                status = 'æ¥è¿‘ç›ˆåˆ©ç›®æ ‡'
                status_class = 'profit'
            elif profit_rate <= -10:
                status = 'æ¥è¿‘æ­¢æŸ'
                status_class = 'loss'
            
            position_list.append({
                'inst_id': inst_id,
                'pos_side': pos_side,
                'pos_size': abs(pos_value),
                'avg_price': avg_price,
                'mark_price': mark_price,
                'lever': lever,
                'upl': upl,
                'margin': margin,
                'profit_rate': profit_rate,
                'status': status,
                'status_class': status_class,
                'is_anchor': is_anchor,
                'maintenance_count_today': maintenance_counts.get((inst_id, pos_side), 0),  # æ€»ç»´æŠ¤æ¬¡æ•°ï¼ˆä¸å†é™åˆ¶ä»Šæ—¥ï¼‰
                'total_maintenance_count': maintenance_counts.get((inst_id, pos_side), 0)  # æ–°å¢å­—æ®µï¼Œæ˜ç¡®æ˜¯æ€»æ¬¡æ•°
            })
        
        return jsonify({
            'success': True,
            'positions': position_list,
            'total': len(position_list),
            'trade_mode': trade_mode
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/today-statistics')
def get_today_statistics():
    """è·å–ä»Šæ—¥ç»Ÿè®¡æ•°æ®"""
    try:
        import sqlite3
        import requests
        from datetime import datetime
        
        trade_mode = request.args.get('trade_mode', 'real')
        
        # è·å–ç»´æŠ¤æ¬¡æ•°ç»Ÿè®¡
        maintenance_stats_response = requests.get('http://localhost:5000/api/anchor/maintenance-stats', timeout=5)
        maintenance_stats = {}
        if maintenance_stats_response.status_code == 200:
            maintenance_data = maintenance_stats_response.json()
            if maintenance_data.get('success'):
                maintenance_stats = maintenance_data.get('stats', {})
        
        # ç»Ÿè®¡ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°ï¼ˆæŒ‰ç±»å‹åˆ†ç±»ï¼‰
        maintenance_file = 'maintenance_orders.json'
        auto_maintain_long = 0
        auto_maintain_short = 0
        super_maintain_long = 0
        super_maintain_short = 0
        
        try:
            import json as json_lib
            import os
            if os.path.exists(maintenance_file):
                with open(maintenance_file, 'r', encoding='utf-8') as f:
                    records = json_lib.load(f)
                
                today = get_china_today()
                for record in records:
                    if record.get('created_at', '').startswith(today):
                        pos_side = record.get('pos_side')
                        maintenance_type = record.get('maintenance_type', 'normal')
                        
                        if maintenance_type == 'super_maintain':
                            if pos_side == 'long':
                                super_maintain_long += 1
                            else:
                                super_maintain_short += 1
                        else:
                            if pos_side == 'long':
                                auto_maintain_long += 1
                            else:
                                auto_maintain_short += 1
        except Exception as e:
            print(f"ç»Ÿè®¡ç»´æŠ¤æ¬¡æ•°å¤±è´¥: {e}")
        
        # è·å–å½“å‰æŒä»“ç»Ÿè®¡
        positions_response = requests.get(
            f'http://localhost:5000/api/anchor-system/current-positions?trade_mode={trade_mode}',
            timeout=10
        )
        
        total_positions = 0
        anchor_positions = 0
        warning_positions = 0
        
        if positions_response.status_code == 200:
            positions_data = positions_response.json()
            if positions_data.get('success'):
                positions = positions_data.get('positions', [])
                total_positions = len(positions)
                
                for pos in positions:
                    if pos.get('is_anchor'):
                        anchor_positions += 1
                    if pos.get('profit_rate', 0) <= -8:
                        warning_positions += 1
        
        return jsonify({
            'success': True,
            'statistics': {
                'auto_maintain_long': auto_maintain_long,
                'auto_maintain_short': auto_maintain_short,
                'super_maintain_long': super_maintain_long,
                'super_maintain_short': super_maintain_short,
                'total_positions': total_positions,
                'anchor_positions': anchor_positions,
                'warning_positions': warning_positions
            },
            'trade_mode': trade_mode,
            'date': get_china_today()
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/anchor-system/sub-account-positions')
def get_sub_account_positions():
    """è·å–å­è´¦å·æŒä»“"""
    try:
        import json as json_lib
        import requests
        import hmac
        import base64
        import hashlib
        from datetime import datetime
        
        # åŠ è½½å­è´¦å·é…ç½®
        with open('sub_account_config.json', 'r', encoding='utf-8') as f:
            config = json_lib.load(f)
        
        all_positions = []
        
        # éå†æ‰€æœ‰å­è´¦å·
        for sub_account in config.get('sub_accounts', []):
            if not sub_account.get('enabled'):
                continue
            
            account_name = sub_account['account_name']
            api_key = sub_account['api_key']
            secret_key = sub_account['secret_key']
            passphrase = sub_account['passphrase']
            
            api_success = False
            
            try:
                # ç”ŸæˆOKExç­¾å - GETè¯·æ±‚éœ€è¦åœ¨ç­¾åä¸­åŒ…å«æŸ¥è¯¢å‚æ•°
                request_path = '/api/v5/account/positions'
                query_string = 'instType=SWAP'
                timestamp = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
                message = timestamp + 'GET' + request_path + '?' + query_string
                mac = hmac.new(
                    secret_key.encode('utf-8'),
                    message.encode('utf-8'),
                    hashlib.sha256
                )
                signature = base64.b64encode(mac.digest()).decode('utf-8')
                
                headers = {
                    'OK-ACCESS-KEY': api_key,
                    'OK-ACCESS-SIGN': signature,
                    'OK-ACCESS-TIMESTAMP': timestamp,
                    'OK-ACCESS-PASSPHRASE': passphrase,
                    'Content-Type': 'application/json'
                }
                
                # è·å–æŒä»“
                url = f"https://www.okx.com{request_path}"
                params = {'instType': 'SWAP'}
                response = requests.get(url, headers=headers, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"âš ï¸ å­è´¦å· {account_name} APIå“åº”: code={data.get('code')}, æŒä»“æ•°={len(data.get('data', []))}")
                    if data.get('code') == '0':
                        api_success = True
                        # å¤„ç†æŒä»“æ•°æ®
                        for pos in data.get('data', []):
                            # å®‰å…¨è½¬æ¢floatï¼Œå¤„ç†ç©ºå­—ç¬¦ä¸²
                            try:
                                pos_size = float(pos.get('pos') or 0)
                            except:
                                pos_size = 0
                            
                            if pos_size == 0:
                                continue
                            
                            try:
                                avg_px = float(pos.get('avgPx') or 0)
                                mark_px = float(pos.get('markPx') or 0)
                                upl = float(pos.get('upl') or 0)
                                notional_usd = float(pos.get('notionalUsd') or 0)
                                # æ‰“å°åŸå§‹å­—æ®µå€¼
                                print(f"ğŸ” åŸå§‹æ•°æ® - imr: {pos.get('imr')}, margin: {pos.get('margin')}, mgnRatio: {pos.get('mgnRatio')}")
                                # ä¼˜å…ˆä½¿ç”¨ marginï¼ˆå ç”¨ä¿è¯é‡‘ï¼‰ï¼Œè€Œä¸æ˜¯ imrï¼ˆåˆå§‹ä¿è¯é‡‘ï¼‰
                                margin = float(pos.get('margin') or pos.get('imr') or 0)
                                print(f"ğŸ’° æœ€ç»ˆä½¿ç”¨çš„ä¿è¯é‡‘: {margin}")
                            except Exception as e:
                                print(f"âš ï¸ æ•°æ®è½¬æ¢å¤±è´¥: {e}, pos={pos}")
                                continue
                            
                            leverage = float(pos.get('lever') or 10)  # ç¡®ä¿leverageæ˜¯floatç±»å‹
                            pos_side = pos.get('posSide')
                            
                            # âœ… ä½¿ç”¨å®æ—¶ä»·æ ¼è®¡ç®—æ”¶ç›Šç‡ï¼ˆä¸å‰ç«¯ä¸€è‡´ï¼‰
                            if avg_px > 0 and mark_px > 0:
                                if pos_side == 'long':
                                    # å¤šå•ï¼š(å½“å‰ä»· - å¼€ä»“ä»·) / å¼€ä»“ä»· * æ æ† * 100
                                    profit_rate = (mark_px - avg_px) / avg_px * leverage * 100
                                else:  # short
                                    # ç©ºå•ï¼š(å¼€ä»“ä»· - å½“å‰ä»·) / å¼€ä»“ä»· * æ æ† * 100
                                    profit_rate = (avg_px - mark_px) / avg_px * leverage * 100
                                print(f"ğŸ“Š æ”¶ç›Šç‡è®¡ç®—: {pos['instId']} {pos_side}, å¼€ä»“ä»·={avg_px:.4f}, æ ‡è®°ä»·={mark_px:.4f}, æ æ†={leverage}x, æ”¶ç›Šç‡={profit_rate:.2f}%")
                            else:
                                profit_rate = 0
                                print(f"âš ï¸ {pos['instId']} ä»·æ ¼æ•°æ®å¼‚å¸¸ï¼Œæ”¶ç›Šç‡è®¾ä¸º0")
                            
                            # è·å–ç»´æŠ¤æ¬¡æ•°
                            maintenance_count = 0
                            try:
                                with open('sub_account_maintenance.json', 'r', encoding='utf-8') as f:
                                    maintenance_data = json.load(f)
                                today = get_china_today()
                                # Keyæ ¼å¼: Wu666666_CRV-USDT-SWAP_long
                                key = f"{account_name}_{pos['instId']}_{pos['posSide']}"
                                if key in maintenance_data:
                                    record = maintenance_data[key]
                                    # æ£€æŸ¥æ—¥æœŸæ˜¯å¦æ˜¯ä»Šå¤©
                                    if record.get('date') == today:
                                        maintenance_count = record.get('count', 0)
                            except Exception as e:
                                print(f"è¯»å–ç»´æŠ¤æ¬¡æ•°å¤±è´¥: {e}")
                                pass
                            
                            all_positions.append({
                                'account_name': account_name,
                                'inst_id': pos['instId'],
                                'pos_side': pos['posSide'],
                                'pos_size': abs(pos_size),
                                'avg_price': avg_px,
                                'mark_price': mark_px,
                                'leverage': leverage,
                                'margin': margin,
                                'upl': upl,
                                'profit_rate': profit_rate,
                                'notional_usd': abs(notional_usd),
                                'maintenance_count': maintenance_count,
                                'status': 'æ­£å¸¸',
                                'is_sub_account': True
                            })
            
            except Exception as e:
                print(f"è·å–å­è´¦å· {account_name} æŒä»“å¤±è´¥: {e}")
            
            # å¦‚æœAPIå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°è®°å½•
            if not api_success:
                print(f"âš ï¸ å­è´¦å· {account_name} APIå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°è®°å½•")
                try:
                    with open('sub_account_opened_positions.json', 'r', encoding='utf-8') as f:
                        opened_positions = json_lib.load(f)
                    
                    for key, pos_info in opened_positions.items():
                        if pos_info['account_name'] == account_name:
                            # è·å–ç»´æŠ¤æ¬¡æ•°
                            maintenance_count = 0
                            try:
                                with open('sub_account_maintenance_count.json', 'r', encoding='utf-8') as f:
                                    counts = json_lib.load(f)
                                today = get_china_today()
                                count_key = f"{account_name}:{pos_info['inst_id']}:{pos_info['pos_side']}:{today}"
                                maintenance_count = counts.get(count_key, 0)
                            except:
                                pass
                            
                            # æ·»åŠ åŸºäºæœ¬åœ°è®°å½•çš„æŒä»“ï¼ˆæ²¡æœ‰å®æ—¶ä»·æ ¼æ•°æ®ï¼‰
                            all_positions.append({
                                'account_name': account_name,
                                'inst_id': pos_info['inst_id'],
                                'pos_side': pos_info['pos_side'],
                                'pos_size': 0,  # æœªçŸ¥
                                'avg_price': 0,  # æœªçŸ¥
                                'mark_price': 0,  # æœªçŸ¥
                                'leverage': '10',
                                'margin': 10,  # ä¼°ç®—
                                'upl': 0,  # æœªçŸ¥
                                'profit_rate': 0,  # æœªçŸ¥
                                'notional_usd': 10,  # ä¼°ç®—
                                'maintenance_count': maintenance_count,
                                'status': 'âš ï¸ æ•°æ®æ¥è‡ªæœ¬åœ°è®°å½•',
                                'is_sub_account': True,
                                'from_local': True
                            })
                except Exception as e:
                    print(f"è¯»å–æœ¬åœ°æŒä»“è®°å½•å¤±è´¥: {e}")
        
        # åˆå¹¶åŒä¸€è´¦æˆ·ã€åŒä¸€å¸ç§ã€åŒä¸€æ–¹å‘çš„æŒä»“ï¼ˆé€ä»“æ¨¡å¼ï¼‰
        merged_positions = {}
        for pos in all_positions:
            # åˆ›å»ºåˆå¹¶é”®ï¼šè´¦æˆ·å_å¸ç§_æ–¹å‘
            merge_key = f"{pos['account_name']}_{pos['inst_id']}_{pos['pos_side']}"
            
            if merge_key in merged_positions:
                # å·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                existing = merged_positions[merge_key]
                
                # è®¡ç®—åŠ æƒå¹³å‡å¼€ä»“ä»·
                total_value = existing['avg_price'] * existing['pos_size'] + pos['avg_price'] * pos['pos_size']
                total_size = existing['pos_size'] + pos['pos_size']
                if total_size > 0:
                    weighted_avg_price = total_value / total_size
                else:
                    weighted_avg_price = existing['avg_price']
                
                # åˆå¹¶æ•°æ®
                existing['pos_size'] += pos['pos_size']
                existing['avg_price'] = weighted_avg_price
                existing['margin'] += pos['margin']
                existing['upl'] += pos['upl']
                existing['notional_usd'] += pos['notional_usd']
                
                # é‡æ–°è®¡ç®—æ”¶ç›Šç‡ï¼ˆåŸºäºæ€»ä¿è¯é‡‘ï¼‰
                if existing['margin'] > 0:
                    existing['profit_rate'] = (existing['upl'] / existing['margin']) * 100
                else:
                    existing['profit_rate'] = 0
                
                # ç»´æŠ¤æ¬¡æ•°å–æœ€å¤§å€¼
                existing['maintenance_count'] = max(existing['maintenance_count'], pos['maintenance_count'])
                
                # æ ‡è®°ä»·æ ¼ä½¿ç”¨æœ€æ–°çš„ï¼ˆå‡è®¾æœ€åä¸€ä¸ªæ˜¯æœ€æ–°çš„ï¼‰
                existing['mark_price'] = pos['mark_price']
            else:
                # æ–°æŒä»“ï¼Œç›´æ¥æ·»åŠ 
                merged_positions[merge_key] = pos.copy()
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        final_positions = list(merged_positions.values())
        
        return jsonify({
            'success': True,
            'positions': final_positions,
            'total': len(final_positions)
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/sub-account-config', methods=['GET', 'POST'])
def sub_account_config():
    """å­è´¦æˆ·é…ç½®ç®¡ç†"""
    try:
        import json as json_lib
        import os
        
        config_file = 'sub_account_config.json'
        
        if request.method == 'GET':
            # è¯»å–é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json_lib.load(f)
            else:
                config = {
                    'sub_accounts': [],
                    'main_account': {'account_name': 'JAMESYI', 'enabled': True}
                }
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.json
            
            # è¯»å–ç°æœ‰é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json_lib.load(f)
            else:
                config = {
                    'sub_accounts': [],
                    'main_account': {'account_name': 'JAMESYI', 'enabled': True}
                }
            
            # æ›´æ–°æ‰€æœ‰å­è´¦æˆ·çš„è¶…çº§ç»´æŠ¤å¼€å…³
            if 'super_maintain_long_enabled' in data:
                for sub_account in config.get('sub_accounts', []):
                    sub_account['super_maintain_long_enabled'] = data['super_maintain_long_enabled']
            
            if 'super_maintain_short_enabled' in data:
                for sub_account in config.get('sub_accounts', []):
                    sub_account['super_maintain_short_enabled'] = data['super_maintain_short_enabled']
            
            # ä¿å­˜é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json_lib.dump(config, f, ensure_ascii=False, indent=2)
            
            return jsonify({
                'success': True,
                'message': 'é…ç½®å·²æ›´æ–°',
                'config': config
            })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ“ä½œå¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

# ====================äº¤æ˜“å†³ç­–ç³»ç»Ÿè·¯ç”± ====================

@app.route('/trading-decision')
def trading_decision_page():
    """äº¤æ˜“å†³ç­–ç³»ç»Ÿç®¡ç†é¡µé¢ - é‡å®šå‘åˆ°ç»Ÿä¸€ç®¡ç†é¡µé¢"""
    return redirect('/trading-manager')

@app.route('/api/trading/anchor-maintenance/logs')
def anchor_maintenance_logs_api():
    """è·å–é”šç‚¹å•ç»´æŠ¤æ—¥å¿—"""
    try:
        limit = request.args.get('limit', 10, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT id, inst_id, pos_side, original_size, original_price, 
               original_margin, current_price, profit_rate, step, action,
               trade_size, trade_price, remaining_size, remaining_margin,
               trigger_reason, decision_log, status, executed_at, created_at
        FROM anchor_maintenance_logs
        ORDER BY created_at DESC
        LIMIT ?
        ''', (limit,))
        
        logs = []
        for row in cursor.fetchall():
            logs.append({
                'id': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'original_size': float(row[3]),
                'original_price': float(row[4]),
                'original_margin': float(row[5]),
                'current_price': float(row[6]),
                'profit_rate': float(row[7]),
                'step': row[8],
                'action': row[9],
                'trade_size': float(row[10]),
                'trade_price': float(row[11]),
                'remaining_size': float(row[12]),
                'remaining_margin': float(row[13]),
                'trigger_reason': row[14],
                'decision_log': row[15],
                'status': row[16],
                'executed_at': row[17],
                'created_at': row[18]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'count': len(logs),
            'logs': logs
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/api/trading/config', methods=['GET', 'POST'])
def trading_config_api():
    """äº¤æ˜“é…ç½®API"""
    config_file = '/home/user/webapp/trading_config.json'
    
    if request.method == 'GET':
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            return jsonify({'success': True, 'config': config})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500
    
    elif request.method == 'POST':
        try:
            new_config = request.json
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„é…ç½®
            conn = sqlite3.connect('/home/user/webapp/trading_decision.db', timeout=10.0)
            cursor = conn.cursor()
            cursor.execute('''
            UPDATE market_config SET
                market_mode = ?,
                market_trend = ?,
                total_capital = ?,
                position_limit_percent = ?,
                anchor_capital_limit = ?,
                allow_long = ?,
                enabled = ?,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = 1
            ''', (
                new_config.get('market_mode'),
                new_config.get('market_trend'),
                new_config.get('total_capital'),
                new_config.get('position_limit_percent'),
                new_config.get('anchor_capital_limit'),
                1 if new_config.get('allow_long') else 0,
                1 if new_config.get('enabled') else 0
            ))
            conn.commit()
            conn.close()
            
            # æ›´æ–°JSONæ–‡ä»¶
            with open(config_file, 'w') as f:
                json.dump(new_config, f, indent=2)
            
            return jsonify({'success': True, 'message': 'é…ç½®æ›´æ–°æˆåŠŸ'})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/decisions')
def trading_decisions_api():
    """è·å–äº¤æ˜“å†³ç­–è®°å½•"""
    try:
        limit = request.args.get('limit', 50, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        cursor.execute(f'''
        SELECT id, inst_id, pos_side, action, decision_type, current_size,
               target_size, close_size, close_percent, profit_rate,
               current_price, reason, executed, timestamp
        FROM trading_decisions
        ORDER BY id DESC
        LIMIT {limit}
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        decisions = []
        for row in rows:
            decisions.append({
                'id': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'action': row[3],
                'decision_type': row[4],
                'current_size': row[5],
                'target_size': row[6],
                'close_size': row[7],
                'close_percent': row[8],
                'profit_rate': row[9],
                'current_price': row[10],
                'reason': row[11],
                'executed': bool(row[12]),
                'timestamp': row[13]
            })
        
        return jsonify({'success': True, 'decisions': decisions, 'total': len(decisions)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/signals')
def trading_signals_api():
    """è·å–äº¤æ˜“ä¿¡å·ï¼ˆä¾›å…¶ä»–è´¦å·ä½¿ç”¨ï¼‰"""
    try:
        limit = request.args.get('limit', 50, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        cursor.execute(f'''
        SELECT id, inst_id, signal_type, action, price, size,
               profit_rate, reason, timestamp
        FROM trading_signals
        ORDER BY id DESC
        LIMIT {limit}
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        signals = []
        for row in rows:
            signals.append({
                'id': row[0],
                'inst_id': row[1],
                'signal_type': row[2],
                'action': row[3],
                'price': row[4],
                'size': row[5],
                'profit_rate': row[6],
                'reason': row[7],
                'timestamp': row[8]
            })
        
        return jsonify({'success': True, 'signals': signals, 'total': len(signals)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/maintenance')
def trading_maintenance_api():
    """è·å–é”šç‚¹å•ç»´æŠ¤è®°å½•"""
    try:
        limit = request.args.get('limit', 50, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        cursor.execute(f'''
        SELECT id, inst_id, pos_side, original_size, original_price,
               maintenance_price, maintenance_size, profit_rate,
               action, status, timestamp
        FROM anchor_maintenance
        ORDER BY id DESC
        LIMIT {limit}
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        records = []
        for row in rows:
            records.append({
                'id': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'original_size': row[3],
                'original_price': row[4],
                'maintenance_price': row[5],
                'maintenance_size': row[6],
                'profit_rate': row[7],
                'action': row[8],
                'status': row[9],
                'timestamp': row[10]
            })
        
        return jsonify({'success': True, 'records': records, 'total': len(records)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/dashboard')
def dashboard():
    """å®æ—¶ç›‘æ§ä»ªè¡¨æ¿ - é‡å®šå‘åˆ°ç»Ÿä¸€ç®¡ç†é¡µé¢"""
    return redirect('/trading-manager')

@app.route('/trading-manager')
def trading_manager():
    """äº¤æ˜“ç®¡ç†ç•Œé¢ - æ¨¡æ‹Ÿäº¤æ˜“ç³»ç»Ÿ"""
    try:
        with open('/home/user/webapp/templates/trading_manager.html', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ·»åŠ ç¼“å­˜æ§åˆ¶å¤´ï¼Œå¼ºåˆ¶æµè§ˆå™¨åˆ·æ–°
        response = make_response(content)
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        return response
    except FileNotFoundError:
        return "Trading manager template not found", 404
    except Exception as e:
        return f"Error loading trading manager: {str(e)}", 500

@app.route('/simulated-trades')
def simulated_trades():
    """æ¨¡æ‹Ÿäº¤æ˜“è¯¦æƒ…ç•Œé¢"""
    try:
        with open('/home/user/webapp/templates/simulated_trades.html', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "Simulated trades template not found", 404
    except Exception as e:
        return f"Error loading simulated trades: {str(e)}", 500

@app.route('/api/anchor-system/warnings')
def get_anchor_warnings():
    """è·å–å½“å‰æ´»è·ƒçš„é”šç‚¹é¢„è­¦"""
    try:
        import sqlite3
        
        # è·å–äº¤æ˜“æ¨¡å¼
        trade_mode = request.args.get('trade_mode', 'paper')
        
        DB_PATH = '/home/user/webapp/trading_decision.db'
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æ´»è·ƒé¢„è­¦
        cursor.execute('''
            SELECT inst_id, pos_side, open_price, current_price, profit_rate, 
                   open_size, warning_level, alert_message, status, created_at, trade_mode
            FROM anchor_warning_monitor
            WHERE status = 'active' AND trade_mode = ?
            ORDER BY profit_rate ASC
        ''', (trade_mode,))
        
        warnings = cursor.fetchall()
        conn.close()
        
        warning_list = []
        for row in warnings:
            warning_list.append({
                'inst_id': row['inst_id'],
                'pos_side': row['pos_side'],
                'open_price': float(row['open_price']),
                'current_price': float(row['current_price']) if row['current_price'] else 0.0,
                'profit_rate': float(row['profit_rate']),
                'open_size': float(row['open_size']),
                'warning_level': row['warning_level'],
                'alert_message': row['alert_message'],
                'status': row['status'],
                'created_at': row['created_at'],
                'trade_mode': row['trade_mode']
            })
        
        return jsonify({
            'success': True,
            'warnings': warning_list,
            'total': len(warning_list),
            'trade_mode': trade_mode
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/super-maintain-anchor', methods=['POST'])
def super_maintain_anchor_order():
    """è¶…çº§ç»´æŠ¤é”šç‚¹å•ï¼šä¹°å…¥100Uï¼Œä¿ç•™10Uï¼Œå–å‡ºå‰©ä½™"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        from okex_api_config import OKEX_API_KEY, OKEX_SECRET_KEY, OKEX_PASSPHRASE, OKEX_REST_URL
        
        data = request.json
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')
        current_pos_size = float(data.get('current_pos_size', 0))
        maintenance_amount = float(data.get('maintenance_amount', 100))  # é»˜è®¤100U
        target_margin = float(data.get('target_margin', 10))  # é»˜è®¤ä¿ç•™10U
        
        print(f"ğŸš€ å¼€å§‹è¶…çº§ç»´æŠ¤: {inst_id} {pos_side} å½“å‰æŒä»“={current_pos_size}")
        print(f"   ç»´æŠ¤é‡‘é¢: {maintenance_amount}U, ç›®æ ‡ä¿è¯é‡‘: {target_margin}U")
        
        # ç”Ÿæˆç­¾åå‡½æ•°
        def generate_signature(timestamp, method, request_path, body=''):
            if body:
                body = json.dumps(body)
            message = timestamp + method + request_path + body
            mac = hmac.new(
                bytes(OKEX_SECRET_KEY, encoding='utf8'),
                bytes(message, encoding='utf-8'),
                digestmod=hashlib.sha256
            )
            return base64.b64encode(mac.digest()).decode()
        
        def get_headers(method, request_path, body=''):
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
            sign = generate_signature(timestamp, method, request_path, body)
            return {
                'OK-ACCESS-KEY': OKEX_API_KEY,
                'OK-ACCESS-SIGN': sign,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': OKEX_PASSPHRASE,
                'Content-Type': 'application/json'
            }
        
        # è·å–å½“å‰æ ‡è®°ä»·æ ¼å’Œæ æ†
        position_path = f'/api/v5/account/positions?instType=SWAP&instId={inst_id}'
        headers = get_headers('GET', position_path)
        pos_response = requests.get(OKEX_REST_URL + position_path, headers=headers, timeout=10)
        pos_data = pos_response.json()
        
        mark_price = 0
        lever = 10
        if pos_data.get('code') == '0' and pos_data.get('data'):
            for position in pos_data['data']:
                if position.get('posSide') == pos_side:
                    mark_price = float(position.get('markPx', 0))
                    lever = int(position.get('lever', 10))
                    break
        
        if mark_price == 0:
            return jsonify({
                'success': False,
                'message': f'æ— æ³•è·å–æ ‡è®°ä»·æ ¼ï¼Œæ£€æŸ¥æŒä»“å’Œè¡Œæƒ…æ•°æ®'
            })
        
        print(f"ğŸ“Š æ ‡è®°ä»·æ ¼: ${mark_price}, æ æ†: {lever}x")
        
        # è®¡ç®—ä¹°å…¥æ•°é‡ï¼šmaintenance_amount Ã— æ æ† / æ ‡è®°ä»·æ ¼
        buy_size_raw = (maintenance_amount * lever) / mark_price
        
        # è·å–åˆçº¦é¢å€¼
        inst_path = f'/api/v5/public/instruments?instType=SWAP&instId={inst_id}'
        inst_resp = requests.get(OKEX_REST_URL + inst_path, timeout=10)
        inst_data = inst_resp.json()
        lot_size = 1
        if inst_data.get('code') == '0' and inst_data.get('data'):
            lot_size = float(inst_data['data'][0].get('ctVal', 1))
        
        # å‘ä¸‹å–æ•´åˆ°lot_sizeçš„æ•´æ•°å€
        buy_size = int(buy_size_raw / lot_size) * lot_size
        
        print(f"ğŸ’° æ–°å¼€ä»“æ•°é‡: {buy_size} (åŸå§‹: {buy_size_raw:.2f}, lot_size: {lot_size})")
        
        # è®¡ç®—ä¿ç•™ç›®æ ‡ï¼štarget_margin Ã— æ æ† / æ ‡è®°ä»·æ ¼
        keep_size_raw = (target_margin * lever) / mark_price
        keep_size = int(keep_size_raw / lot_size) * lot_size
        
        # è®¡ç®—éœ€è¦å¹³ä»“çš„æ•°é‡ = æ—§æŒä»“ + æ–°å¼€ä»“ - æœ€ç»ˆä¿ç•™
        total_pos_size = current_pos_size + buy_size
        close_size_raw = total_pos_size - keep_size
        close_size = int(close_size_raw / lot_size) * lot_size if close_size_raw > 0 else 0
        
        print(f"ğŸ“Š ä»“ä½è®¡ç®—:")
        print(f"   å½“å‰æŒä»“: {current_pos_size} å¼ ")
        print(f"   æ–°å¼€ä»“: {buy_size} å¼ ")
        print(f"   æ€»æŒä»“: {total_pos_size} å¼ ")
        print(f"   æœ€ç»ˆä¿ç•™: {keep_size} å¼  (ç›®æ ‡ä¿è¯é‡‘ {target_margin}U)")
        print(f"   éœ€è¦å¹³ä»“: {close_size} å¼ ")
        
        # ğŸ”„ ä¼˜åŒ–åçš„æµç¨‹ï¼šå…ˆå¼€ä»“å†å¹³ä»“ï¼ˆæ›´çœæ‰‹ç»­è´¹ï¼‰
        order_path = '/api/v5/trade/order'
        
        # ç¬¬ä¸€æ­¥ï¼šå¼€ä»“æ–°æŒä»“ï¼ˆç»´æŠ¤é‡‘é¢å¯¹åº”çš„ä»“ä½ï¼‰
        print(f"ğŸ“Š ç¬¬1æ­¥ï¼šå¼€ä»“æ–°æŒä»“ {buy_size} å¼ ï¼ˆ{maintenance_amount}Uï¼‰")
        buy_side = 'sell' if pos_side == 'short' else 'buy'
        
        buy_order_body = {
            'instId': inst_id,
            'tdMode': 'isolated',  # é€ä»“æ¨¡å¼ï¼šæ¯ä¸ªæŒä»“ç‹¬ç«‹ä¿è¯é‡‘
            'side': buy_side,
            'posSide': pos_side,
            'ordType': 'market',
            'sz': str(buy_size),
            'lever': str(lever)
        }
        
        headers = get_headers('POST', order_path, buy_order_body)
        buy_response = requests.post(
            OKEX_REST_URL + order_path,
            headers=headers,
            json=buy_order_body,
            timeout=10
        )
        buy_data = buy_response.json()
        
        if buy_data.get('code') != '0':
            return jsonify({
                'success': False,
                'message': f'å¼€ä»“å¤±è´¥: {buy_data.get("msg")}',
                'error_code': buy_data.get('code')
            })
        
        buy_order_id = buy_data['data'][0]['ordId']
        print(f"âœ… å¼€ä»“è®¢å•æäº¤æˆåŠŸ: {buy_order_id}")
        
        # ç­‰å¾…3ç§’è®©è®¢å•æˆäº¤
        import time
        time.sleep(3)
        
        # ç¬¬äºŒæ­¥ï¼šå¹³ä»“å¤šä½™æŒä»“ï¼Œä¿ç•™ç›®æ ‡ä¿è¯é‡‘
        if close_size <= 0:
            print(f"âš ï¸  æ— éœ€å¹³ä»“ï¼Œå½“å‰æŒä»“å·²è¾¾åˆ°ç›®æ ‡")
            return jsonify({
                'success': True,
                'message': 'è¶…çº§ç»´æŠ¤å®Œæˆï¼ˆæ— éœ€å¹³ä»“ï¼‰',
                'data': {
                    'buy_order_id': buy_order_id,
                    'buy_size': buy_size,
                    'close_size': 0,
                    'keep_size': keep_size
                }
            })
        
        print(f"ğŸ“Š ç¬¬2æ­¥ï¼šå¹³ä»“å¤šä½™æŒä»“ {close_size} å¼ ï¼ˆä¿ç•™: {keep_size} å¼  = {target_margin}Uï¼‰")
        close_side = 'buy' if pos_side == 'short' else 'sell'
        
        close_order_body = {
            'instId': inst_id,
            'tdMode': 'isolated',  # é€ä»“æ¨¡å¼ï¼šæ¯ä¸ªæŒä»“ç‹¬ç«‹ä¿è¯é‡‘
            'side': close_side,
            'posSide': pos_side,
            'ordType': 'market',
            'sz': str(close_size)
        }
        
        headers = get_headers('POST', order_path, close_order_body)
        close_response = requests.post(
            OKEX_REST_URL + order_path,
            headers=headers,
            json=close_order_body,
            timeout=10
        )
        close_data = close_response.json()
        
        if close_data.get('code') != '0':
            return jsonify({
                'success': False,
                'message': f'å¹³ä»“å¤±è´¥: {close_data.get("msg")}',
                'buy_order_id': buy_order_id,
                'error_code': close_data.get('code')
            })
        
        close_order_id = close_data['data'][0]['ordId']
        print(f"âœ… ç¬¬2æ­¥å¹³ä»“è®¢å•æäº¤æˆåŠŸ: {close_order_id}")
        
        # ä¿å­˜è¶…çº§ç»´æŠ¤è®°å½•ï¼ˆè®¡æ•°+1ï¼‰
        try:
            import os
            maintenance_file = 'maintenance_orders.json'
            
            if os.path.exists(maintenance_file):
                with open(maintenance_file, 'r', encoding='utf-8') as f:
                    records = json_lib.load(f)
            else:
                records = []
            
            # æ·»åŠ è¶…çº§ç»´æŠ¤è®°å½•ï¼ˆä¼˜åŒ–åæµç¨‹ï¼šå¹³ä»“â†’å¼€ä»“â†’å†å¹³ä»“ï¼‰
            new_record = {
                'id': len(records) + 1,
                'inst_id': inst_id,
                'pos_side': pos_side,
                'type': 'super_maintain',  # æ ‡è®°ä¸ºè¶…çº§ç»´æŠ¤
                'close_old_order_id': close_order_id,  # å¹³æ‰æ—§æŒä»“
                'buy_order_id': buy_order_id,
                'buy_size': buy_size,
                'sell_order_id': sell_order_id,  # å–å‡ºåˆ°ç›®æ ‡
                'sell_size': sell_size,
                'keep_size': keep_size,
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'status': 'success',
                'maintenance_count': 1  # è¶…çº§ç»´æŠ¤ä¹Ÿæ˜¯è®¡æ•°+1
            }
            
            records.insert(0, new_record)
            
            if len(records) > 100:
                records = records[:100]
            
            with open(maintenance_file, 'w', encoding='utf-8') as f:
                json_lib.dump(records, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… è¶…çº§ç»´æŠ¤è®°å½•å·²ä¿å­˜")
        except Exception as save_error:
            print(f"âš ï¸  ä¿å­˜è¶…çº§ç»´æŠ¤è®°å½•å¤±è´¥: {save_error}")
        
        print(f"ğŸ‰ è¶…çº§ç»´æŠ¤å®Œæˆï¼æµç¨‹ï¼šå¹³ä»“æ—§æŒä»“({current_pos_size}å¼ ) â†’ å¼€ä»“æ–°æŒä»“({new_pos_size}å¼ ) â†’ å¹³åˆ°ç›®æ ‡({keep_size}å¼ )")
        
        return jsonify({
            'success': True,
            'message': 'è¶…çº§ç»´æŠ¤æ‰§è¡ŒæˆåŠŸï¼ˆä¼˜åŒ–æµç¨‹ï¼šå…ˆå¹³ä»“å†å¼€ä»“ï¼‰',
            'data': {
                'close_old_order_id': close_order_id,
                'buy_order_id': buy_order_id,
                'buy_size': buy_size,
                'sell_order_id': sell_order_id,
                'sell_size': sell_size,
                'keep_size': keep_size,
                'new_pos_size': new_pos_size
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è¶…çº§ç»´æŠ¤å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/maintain-anchor', methods=['POST'])
def maintain_anchor_order():
    """ç»´æŠ¤é”šç‚¹å•ï¼šä»¥å¸‚ä»·ä¹°å…¥10å€åº•ä»“æ•°é‡ï¼ˆ10å€æ æ†ï¼‰ï¼Œç„¶åç«‹å³å¹³æ‰92%"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        from okex_api_config import OKEX_API_KEY, OKEX_SECRET_KEY, OKEX_PASSPHRASE, OKEX_REST_URL
        
        data = request.json
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')  # 'short' or 'long'
        pos_size = float(data.get('pos_size'))
        auto_adjust = data.get('auto_adjust', False)  # æ˜¯å¦è‡ªåŠ¨è°ƒæ•´ä¿è¯é‡‘ï¼ˆåªç”¨äºè‡ªåŠ¨ç»´æŠ¤-10%ï¼‰
        
        # è®¡ç®—10å€æ•°é‡
        order_size = pos_size * 10
        
        # æ£€æŸ¥ç»´æŠ¤æ¬¡æ•°ï¼ˆä¸å†é™åˆ¶æ¯æ—¥æ¬¡æ•°ï¼‰
        # æ³¨é‡Šæ‰åŸæœ‰çš„ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°é™åˆ¶é€»è¾‘
        # import json as json_lib_check
        # import os
        # from collections import defaultdict
        
        # maintenance_file = 'maintenance_orders.json'
        # today = get_china_today()
        
        # # ç»Ÿè®¡ä»Šå¤©çš„ç»´æŠ¤æ¬¡æ•°
        # today_count = 0
        # if os.path.exists(maintenance_file):
        #     try:
        #         with open(maintenance_file, 'r', encoding='utf-8') as f:
        #             records = json_lib_check.load(f)
        #         
        #         for record in records:
        #             created_at = record.get('created_at', '')
        #             if created_at.startswith(today):
        #                 if record.get('inst_id') == inst_id and record.get('pos_side') == pos_side:
        #                     today_count += 1
        #     except Exception as e:
        #         print(f"è¯»å–ç»´æŠ¤è®°å½•å¤±è´¥: {e}")
        
        # print(f"ğŸ“Š {inst_id} {pos_side} ä»Šæ—¥å·²ç»´æŠ¤æ¬¡æ•°: {today_count}/3")
        
        # # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ¯æ—¥ä¸Šé™
        # if today_count >= 3:
        #     return jsonify({
        #         'success': False,
        #         'message': f'ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°å·²è¾¾ä¸Šé™(3æ¬¡)ï¼Œè¯·æ˜å¤©å†è¯•',
        #         'today_count': today_count,
        #         'max_count': 3
        #     })
        
        # ğŸ”„ ä¼˜åŒ–åçš„æµç¨‹ï¼šå…ˆå¼€ä»“å†å¹³ä»“ï¼ˆèŠ‚çœæ‰‹ç»­è´¹ï¼‰
        # ç¬¬ä¸€æ­¥ï¼šå¼€ä»“æ–°æŒä»“
        print(f"ğŸ“Š ç¬¬1æ­¥ï¼šå¼€ä»“æ–°æŒä»“ {order_size} å¼ ï¼ˆ10å€åº•ä»“æ•°é‡ï¼‰")
        
        # ç”Ÿæˆç­¾å
        def generate_signature(timestamp, method, request_path, body=''):
            if body:
                body = json.dumps(body)
            message = timestamp + method + request_path + body
            mac = hmac.new(
                bytes(OKEX_SECRET_KEY, encoding='utf8'),
                bytes(message, encoding='utf-8'),
                digestmod=hashlib.sha256
            )
            return base64.b64encode(mac.digest()).decode()
        
        def get_headers(method, request_path, body=''):
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
            sign = generate_signature(timestamp, method, request_path, body)
            return {
                'OK-ACCESS-KEY': OKEX_API_KEY,
                'OK-ACCESS-SIGN': sign,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': OKEX_PASSPHRASE,
                'Content-Type': 'application/json'
            }
        
        order_path = '/api/v5/trade/order'
        
        # è®¾ç½®æ æ†ä¸º10å€
        leverage_path = '/api/v5/account/set-leverage'
        leverage_body = {
            'instId': inst_id,
            'lever': '10',
            'mgnMode': 'isolated',
            'posSide': pos_side
        }
        headers = get_headers('POST', leverage_path, leverage_body)
        leverage_response = requests.post(
            OKEX_REST_URL + leverage_path,
            headers=headers,
            json=leverage_body,
            timeout=10
        )
        leverage_result = leverage_response.json()
        if leverage_result.get('code') == '0':
            print(f"âœ… æ æ†è®¾ç½®æˆåŠŸ: {lever}x")
        else:
            print(f"âš ï¸ æ æ†è®¾ç½®å¤±è´¥: {leverage_result}")
        
        import time
        
        # ç¡®å®šå¼€ä»“æ–¹å‘
        open_side = 'sell' if pos_side == 'short' else 'buy'
        
        open_order_body = {
            'instId': inst_id,
            'tdMode': 'isolated',
            'side': open_side,
            'posSide': pos_side,
            'ordType': 'market',
            'sz': str(order_size),
            'lever': str(lever)
        }
        
        headers = get_headers('POST', order_path, open_order_body)
        open_response = requests.post(
            OKEX_REST_URL + order_path,
            headers=headers,
            json=open_order_body,
            timeout=10
        )
        
        open_result = open_response.json()
        
        # è®°å½•è¯¦ç»†çš„å“åº”æ—¥å¿—
        print(f"ğŸ“ OKExå¼€ä»“å“åº”: {open_result}")
        
        if open_result.get('code') != '0':
            error_msg = open_result.get('msg', 'æœªçŸ¥é”™è¯¯')
            error_code = open_result.get('code', 'æœªçŸ¥ä»£ç ')
            print(f"âŒ OKEx APIé”™è¯¯ - Code: {error_code}, Message: {error_msg}")
            
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯æç¤º
            if 'permission' in error_msg.lower():
                error_msg = f"{error_msg}\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š\n1. ç™»å½•OKExåå° (www.okx.com)\n2. è¿›å…¥APIç®¡ç†é¡µé¢\n3. ç¡®è®¤APIå¯†é’¥å·²å‹¾é€‰ã€Œäº¤æ˜“ã€æƒé™\n4. å¦‚æœªå‹¾é€‰ï¼Œéœ€è¦é‡æ–°åˆ›å»ºAPIå¯†é’¥"
            
            return jsonify({
                'success': False,
                'message': f"å¼€ä»“å¤±è´¥: {error_msg}",
                'error_code': error_code,
                'full_response': open_result
            })
        
        open_order_id = open_result['data'][0]['ordId']
        print(f"âœ… å¼€ä»“è®¢å•æäº¤æˆåŠŸï¼Œè®¢å•ID: {open_order_id}")
        
        # ç­‰å¾…è®¢å•æˆäº¤ï¼ˆå¢åŠ ç­‰å¾…æ—¶é—´åˆ°3ç§’ï¼‰
        print(f"â³ ç­‰å¾…3ç§’ç¡®ä¿è®¢å•æˆäº¤...")
        time.sleep(3)
        
        # æŸ¥è¯¢è®¢å•çŠ¶æ€
        order_detail_path = f'/api/v5/trade/order?instId={inst_id}&ordId={open_order_id}'
        headers = get_headers('GET', order_detail_path)
        order_detail_response = requests.get(
            OKEX_REST_URL + order_detail_path,
            headers=headers,
            timeout=10
        )
        order_detail = order_detail_response.json()
        print(f"ğŸ“ å¼€ä»“è®¢å•çŠ¶æ€: {order_detail}")
        
        # æ£€æŸ¥è®¢å•æ˜¯å¦å®Œå…¨æˆäº¤
        if order_detail.get('code') == '0' and order_detail.get('data'):
            order_state = order_detail['data'][0].get('state', '')
            if order_state != 'filled':
                print(f"âš ï¸ è®¢å•æœªå®Œå…¨æˆäº¤ï¼ŒçŠ¶æ€: {order_state}")
                # ç»§ç»­å°è¯•å¹³ä»“
        
        
        # ç¬¬äºŒæ­¥ï¼šå¹³æ‰å¤šä½™æŒä»“ï¼Œä¿ç•™target_marginå¯¹åº”çš„æ•°é‡
        print(f"ğŸ“Š ç¬¬2æ­¥ï¼šå¹³åˆ°ç›®æ ‡ä¿è¯é‡‘ {target_margin}Uï¼ˆå¹³æ‰å¤šä½™æŒä»“ï¼‰")
        
        import math
        
        # è®¡ç®—åº”è¯¥ä¿ç•™çš„æ•°é‡
        keep_size_raw = (target_margin * lever) / mark_price
        keep_size = math.floor(keep_size_raw)
        
        # ç¡®ä¿è‡³å°‘ä¿ç•™0.6Uçš„ä¿è¯é‡‘
        MIN_MARGIN = 0.6
        min_keep_size = math.ceil((MIN_MARGIN * lever) / mark_price)
        if keep_size < min_keep_size:
            print(f"âš ï¸ ä¿ç•™æ•°é‡ {keep_size} å¼ å°äºæœ€å°è¦æ±‚ {min_keep_size} å¼ ï¼ˆæœ€å°ä¿è¯é‡‘ {MIN_MARGIN}Uï¼‰ï¼Œå¼ºåˆ¶è®¾ç½®ä¸º {min_keep_size} å¼ ")
            keep_size = min_keep_size
        
        # è®¡ç®—æ€»æŒä»“ï¼šåŸæŒä»“ + æ–°å¼€ä»“
        total_pos_size = pos_size + order_size
        
        # è®¡ç®—éœ€è¦å¹³æ‰çš„æ•°é‡
        close_size = max(0, total_pos_size - keep_size)
        
        print(f"ğŸ“Š ä»“ä½è®¡ç®—:")
        print(f"   å½“å‰æŒä»“: {pos_size} å¼ ")
        print(f"   æ–°å¼€ä»“: {order_size} å¼ ")
        print(f"   æ€»æŒä»“: {total_pos_size} å¼ ")
        print(f"   æœ€ç»ˆä¿ç•™: {keep_size} å¼  = {target_margin}U")
        print(f"   éœ€è¦å¹³ä»“: {close_size} å¼ ")
        
        if close_size <= 0:
            print(f"âœ… è·³è¿‡ç¬¬2æ­¥ï¼šä¸éœ€è¦å¹³ä»“ï¼ˆclose_size={close_size}ï¼‰")
            close_order_id = 'SKIPPED'
        else:
            # å¹³ä»“æ–¹å‘ä¸å¼€ä»“ç›¸å
            close_side = 'buy' if pos_side == 'short' else 'sell'
            
            close_order_body = {
                'instId': inst_id,
                'tdMode': 'isolated',
                'side': close_side,
                'posSide': pos_side,
                'ordType': 'market',
                'sz': str(close_size)
            }
            
            print(f"ğŸ“ å¹³ä»“è¯·æ±‚å‚æ•°: {close_order_body}")
            
            headers = get_headers('POST', order_path, close_order_body)
            close_response = requests.post(
                OKEX_REST_URL + order_path,
                headers=headers,
                json=close_order_body,
                timeout=10
            )
            
            close_result = close_response.json()
            print(f"ğŸ“ OKExå¹³ä»“å“åº”: {close_result}")
            
            if close_result.get('code') != '0':
                error_msg = close_result.get('msg', 'æœªçŸ¥é”™è¯¯')
                error_code = close_result.get('code', 'æœªçŸ¥ä»£ç ')
                print(f"âŒ å¹³ä»“å¤±è´¥ - Code: {error_code}, Message: {error_msg}")
                
                return jsonify({
                    'success': False,
                    'message': f"å¹³ä»“å¤±è´¥: {error_msg} (å¼€ä»“è®¢å•ID: {open_order_id})",
                    'error_code': error_code,
                    'open_order_id': open_order_id,
                    'full_response': close_result
                })
            
            close_order_id = close_result['data'][0]['ordId']
            print(f"âœ… ç¬¬2æ­¥å¹³ä»“è®¢å•æäº¤æˆåŠŸ: {close_order_id}")
            
            # ç­‰å¾…å¹³ä»“è®¢å•æˆäº¤
            print(f"â³ ç­‰å¾…3ç§’ç¡®ä¿å¹³ä»“è®¢å•æˆäº¤...")
            time.sleep(3)
        
        # æŸ¥è¯¢å¼€ä»“è®¢å•çš„æˆäº¤æ˜ç»†ï¼ˆfillsï¼‰
        fills_path = f'/api/v5/trade/fills?instId={inst_id}&ordId={open_order_id}'
        headers = get_headers('GET', fills_path)
        open_fills_response = requests.get(
            OKEX_REST_URL + fills_path,
            headers=headers,
            timeout=10
        )
        open_fills_data = open_fills_response.json()
        
        # æŸ¥è¯¢å¹³ä»“è®¢å•çš„æˆäº¤æ˜ç»†
        close_fills_path = f'/api/v5/trade/fills?instId={inst_id}&ordId={close_order_id}'
        headers = get_headers('GET', close_fills_path)
        close_fills_response = requests.get(
            OKEX_REST_URL + close_fills_path,
            headers=headers,
            timeout=10
        )
        close_fills_data = close_fills_response.json()
        
        # å¤„ç†å¼€ä»“æˆäº¤æ˜ç»†
        open_fills = []
        open_total_fee = 0
        open_total_qty = 0
        open_total_value = 0
        if open_fills_data.get('code') == '0' and open_fills_data.get('data'):
            for fill in open_fills_data['data']:
                qty = float(fill.get('fillSz', 0))
                price = float(fill.get('fillPx', 0))
                fee = float(fill.get('fee', 0))
                value = qty * price  # è¿™ç¬”äº¤æ˜“çš„ä»·å€¼
                open_fills.append({
                    'trade_id': fill.get('tradeId'),
                    'qty': qty,
                    'price': price,
                    'value': value,  # äº¤æ˜“ä»·å€¼
                    'fee': abs(fee),  # è´¹ç”¨å–ç»å¯¹å€¼
                    'fee_currency': fill.get('feeCcy', 'USDT')
                })
                open_total_fee += abs(fee)
                open_total_qty += qty
                open_total_value += value
        
        # å¤„ç†å¹³ä»“æˆäº¤æ˜ç»†
        close_fills = []
        close_total_fee = 0
        close_total_qty = 0
        close_total_value = 0
        if close_fills_data.get('code') == '0' and close_fills_data.get('data'):
            for fill in close_fills_data['data']:
                qty = float(fill.get('fillSz', 0))
                price = float(fill.get('fillPx', 0))
                fee = float(fill.get('fee', 0))
                value = qty * price  # è¿™ç¬”äº¤æ˜“çš„ä»·å€¼
                close_fills.append({
                    'trade_id': fill.get('tradeId'),
                    'qty': qty,
                    'price': price,
                    'value': value,  # äº¤æ˜“ä»·å€¼
                    'fee': abs(fee),
                    'fee_currency': fill.get('feeCcy', 'USDT')
                })
                close_total_fee += abs(fee)
                close_total_qty += qty
                close_total_value += value
        
        # è®¡ç®—æ€»è´¹ç”¨å’Œè´¹ç‡
        total_fee = open_total_fee + close_total_fee
        
        # è®¡ç®—å¹³å‡å¼€ä»“ä»·æ ¼
        avg_open_price = 0
        if open_total_qty > 0:
            avg_open_price = open_total_value / open_total_qty
        
        # è®¡ç®—å¹³å‡å¹³ä»“ä»·æ ¼
        avg_close_price = 0
        if close_total_qty > 0:
            avg_close_price = close_total_value / close_total_qty
        
        # è®¡ç®—äº¤æ˜“é‡‘é¢ï¼ˆä»¥USDTè®¡ï¼‰
        trade_value = open_total_qty * avg_open_price
        
        # è®¡ç®—æ€»ç›ˆäº
        total_profit = 0
        if pos_side == 'long':
            total_profit = (avg_close_price - avg_open_price) * close_total_qty
        else:
            total_profit = (avg_open_price - avg_close_price) * close_total_qty
        
        # å‡€ç›ˆäºï¼ˆæ‰£é™¤æ‰‹ç»­è´¹ï¼‰
        net_profit = total_profit - total_fee
        
        # è®¡ç®—æ€»æˆæœ¬ï¼šæ‰‹ç»­è´¹ + äºæŸï¼ˆå¦‚æœç›ˆåˆ©åˆ™ä¸ç®—ï¼‰
        total_cost = total_fee
        if total_profit < 0:
            total_cost += abs(total_profit)  # äºæŸä¹Ÿæ˜¯æˆæœ¬
        
        # è®¡ç®—è´¹ç‡ï¼ˆæ€»æˆæœ¬/äº¤æ˜“é‡‘é¢ï¼‰
        fee_rate = (total_cost / trade_value * 100) if trade_value > 0 else 0
        
        # è®¡ç®—æ¯ç¬”è®¢å•çš„ç›ˆäº
        # å¯¹äºæ¯ç¬”å¼€ä»“ï¼Œè®¡ç®—å¯¹åº”çš„å¹³ä»“ç›ˆäº
        # ç›ˆäº = (å¹³ä»“ä»·æ ¼ - å¼€ä»“ä»·æ ¼) * æ•°é‡ (å¤šå•)
        # ç›ˆäº = (å¼€ä»“ä»·æ ¼ - å¹³ä»“ä»·æ ¼) * æ•°é‡ (ç©ºå•)
        for i, open_fill in enumerate(open_fills):
            if i < len(close_fills):
                close_fill = close_fills[i]
                qty = min(open_fill['qty'], close_fill['qty'])
                
                if pos_side == 'long':
                    # å¤šå•ï¼šå¹³ä»“ä»·æ ¼ - å¼€ä»“ä»·æ ¼
                    profit = (close_fill['price'] - open_fill['price']) * qty
                else:
                    # ç©ºå•ï¼šå¼€ä»“ä»·æ ¼ - å¹³ä»“ä»·æ ¼
                    profit = (open_fill['price'] - close_fill['price']) * qty
                
                # å‡å»è¿™ç¬”äº¤æ˜“çš„æ‰‹ç»­è´¹
                net_profit = profit - open_fill['fee'] - close_fill['fee']
                
                open_fill['profit'] = profit
                open_fill['net_profit'] = net_profit
                close_fill['profit'] = profit
                close_fill['net_profit'] = net_profit
        
        print(f"ğŸ“Š å¼€ä»“æˆäº¤: {len(open_fills)}ç¬”, æ€»é‡{open_total_qty}, å‡ä»·${avg_open_price:.4f}, è´¹ç”¨${open_total_fee:.4f}")
        print(f"ğŸ“Š å¹³ä»“æˆäº¤: {len(close_fills)}ç¬”, æ€»é‡{close_total_qty}, å‡ä»·${avg_close_price:.4f}, è´¹ç”¨${close_total_fee:.4f}")
        print(f"ğŸ’° æ€»è´¹ç”¨: ${total_fee:.4f}, æ€»æˆæœ¬: ${total_cost:.4f}, è´¹ç‡: {fee_rate:.4f}%")
        print(f"ğŸ’µ ç›ˆäº: ${total_profit:.4f}, å‡€ç›ˆäº: ${net_profit:.4f}")
        
        # ä¿å­˜ç»´æŠ¤è®°å½•åˆ°JSONæ–‡ä»¶
        try:
            import json as json_lib
            import os
            from datetime import datetime
            
            maintenance_file = 'maintenance_orders.json'
            
            # è¯»å–ç°æœ‰è®°å½•
            if os.path.exists(maintenance_file):
                with open(maintenance_file, 'r', encoding='utf-8') as f:
                    records = json_lib.load(f)
            else:
                records = []
            
            # æ·»åŠ æ–°è®°å½•ï¼ˆä¼˜åŒ–åæµç¨‹ï¼šå…ˆå¼€æ–°ä»“â†’å¹³åˆ°ç›®æ ‡ä¿è¯é‡‘ï¼‰
            new_record = {
                'id': len(records) + 1,
                'account_name': 'JAMESYI',  # è´¦æˆ·åç§°ï¼ˆåç»­å¯ä»é…ç½®è¯»å–ï¼‰
                'inst_id': inst_id,
                'pos_side': pos_side,
                'original_size': pos_size,
                'open_order_id': open_order_id,
                'open_size': order_size,
                'open_fills': open_fills,
                'open_total_qty': open_total_qty,
                'open_avg_price': avg_open_price,
                'open_total_fee': open_total_fee,
                'close_order_id': close_order_id,
                'close_size': close_size,
                'close_fills': close_fills,
                'close_total_qty': close_total_qty,
                'close_avg_price': avg_close_price,
                'close_total_fee': close_total_fee,
                'remaining_size': order_size - close_size,
                'total_fee': total_fee,
                'total_cost': total_cost,  # æ€»æˆæœ¬ï¼ˆæ‰‹ç»­è´¹+äºæŸï¼‰
                'fee_rate': fee_rate,
                'total_profit': total_profit,  # æ€»ç›ˆäº
                'net_profit': net_profit,  # å‡€ç›ˆäºï¼ˆæ‰£é™¤æ‰‹ç»­è´¹ï¼‰
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'status': 'success',
                'flow_type': 'optimized'  # æ ‡è®°ä¸ºä¼˜åŒ–æµç¨‹
            }
            
            records.insert(0, new_record)  # æœ€æ–°çš„è®°å½•æ”¾åœ¨å‰é¢
            
            # åªä¿ç•™æœ€è¿‘100æ¡è®°å½•
            if len(records) > 100:
                records = records[:100]
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(maintenance_file, 'w', encoding='utf-8') as f:
                json_lib.dump(records, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ç»´æŠ¤è®°å½•å·²ä¿å­˜: ID {new_record['id']}")
            
            # å‘é€TGé€šçŸ¥
            try:
                from telegram_notifier import TelegramNotifier
                
                notifier = TelegramNotifier()
                
                # æ„å»ºé€šçŸ¥æ¶ˆæ¯ï¼ˆä¼˜åŒ–æµç¨‹ï¼šå…ˆå¹³æ—§ä»“â†’å¼€æ–°ä»“â†’å¹³åˆ°92%ï¼‰
                tg_message = f"""ğŸ”§ **é”šç‚¹å•ç»´æŠ¤é€šçŸ¥**ï¼ˆä¼˜åŒ–æµç¨‹ï¼‰

ğŸ“ **å¸ç§**: {inst_id}
ğŸ“Š **æ–¹å‘**: {'åšç©º' if pos_side == 'short' else 'åšå¤š'}
ğŸ’¼ **åŸå§‹ä»“ä½**: {pos_size}

**ğŸ”µ ç¬¬1æ­¥-å¹³æ‰æ—§æŒä»“**:
â€¢ è®¢å•ID: `{old_close_order_id}`
â€¢ æ•°é‡: {pos_size}
â€¢ ç›®çš„: é‡Šæ”¾ä¿è¯é‡‘

**ğŸŸ¢ ç¬¬2æ­¥-å¼€ä»“è¯¦æƒ…**:
â€¢ è®¢å•ID: `{open_order_id}`
â€¢ å¼€ä»“æ•°é‡: {open_total_qty}
â€¢ å¹³å‡ä»·æ ¼: ${avg_open_price:.4f}
â€¢ æˆäº¤ç¬”æ•°: {len(open_fills)}ç¬”
â€¢ å¼€ä»“è´¹ç”¨: ${open_total_fee:.4f} USDT

**ğŸ”´ ç¬¬3æ­¥-å¹³ä»“åˆ°92%**:
â€¢ è®¢å•ID: `{close_order_id}`
â€¢ å¹³ä»“æ•°é‡: {close_total_qty}
â€¢ å¹³å‡ä»·æ ¼: ${avg_close_price:.4f}
â€¢ æˆäº¤ç¬”æ•°: {len(close_fills)}ç¬”
â€¢ å¹³ä»“è´¹ç”¨: ${close_total_fee:.4f} USDT

**ğŸ’° ç›ˆäºç»Ÿè®¡**:
â€¢ æ€»ç›ˆäº: ${total_profit:.4f} USDT {'ğŸ“ˆ' if total_profit > 0 else 'ğŸ“‰' if total_profit < 0 else 'â–'}
â€¢ æ‰‹ç»­è´¹: ${total_fee:.4f} USDT
â€¢ æ€»æˆæœ¬: ${total_cost:.4f} USDT (æ‰‹ç»­è´¹{'+ äºæŸ' if total_profit < 0 else ''})
â€¢ å‡€ç›ˆäº: ${net_profit:.4f} USDT {'âœ…' if net_profit > 0 else 'âŒ' if net_profit < 0 else 'â–'}
â€¢ è´¹ç‡: {fee_rate:.4f}%
â€¢ å‰©ä½™ä»“ä½: {order_size - close_size}

â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
                
                notifier.send_message(tg_message)
                print(f"âœ… TGé€šçŸ¥å·²å‘é€")
            except Exception as tg_error:
                print(f"âš ï¸  å‘é€TGé€šçŸ¥å¤±è´¥: {tg_error}")
                import traceback
                print(traceback.format_exc())
                # ä¸å½±å“ä¸»æµç¨‹
        except Exception as save_error:
            print(f"âš ï¸  ä¿å­˜ç»´æŠ¤è®°å½•å¤±è´¥: {save_error}")
            # ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­è¿”å›æˆåŠŸ
        
        # æ£€æŸ¥å‰©ä½™æŒä»“çš„ä¿è¯é‡‘ï¼Œå¦‚æœå¤§äº2Uåˆ™ç»§ç»­å¹³ä»“åˆ°0.6-1Uä¹‹é—´
        # æ³¨æ„ï¼šåªåœ¨è‡ªåŠ¨ç»´æŠ¤ï¼ˆauto_adjust=Trueï¼‰æ—¶æ‰æ‰§è¡Œæ­¤æ£€æŸ¥
        # è¶…çº§ç»´æŠ¤ä¸åšæ­¤é™åˆ¶
        adjustment_order_id = None
        adjustment_size = 0
        
        if auto_adjust:  # åªæœ‰è‡ªåŠ¨ç»´æŠ¤æ‰è°ƒæ•´ä¿è¯é‡‘
            try:
                print(f"ğŸ” æ£€æŸ¥å‰©ä½™æŒä»“ä¿è¯é‡‘...")
                
                # ç­‰å¾…3ç§’è®©æŒä»“æ•°æ®æ›´æ–°
                import time
                time.sleep(3)
                
                # æŸ¥è¯¢å½“å‰æŒä»“
                position_path = f'/api/v5/account/positions?instType=SWAP&instId={inst_id}'
                headers = get_headers('GET', position_path)
                pos_response = requests.get(
                    OKEX_REST_URL + position_path,
                    headers=headers,
                    timeout=10
                )
                pos_data = pos_response.json()
                
                if pos_data.get('code') == '0' and pos_data.get('data'):
                    for position in pos_data['data']:
                        if position.get('posSide') == pos_side:
                            current_pos_size = abs(float(position.get('pos', 0)))
                            current_margin = float(position.get('margin', 0))
                            mark_price = float(position.get('markPx', 0))
                            lever = int(position.get('lever', 10))
                            
                            print(f"ğŸ“Š å½“å‰æŒä»“: æ•°é‡={current_pos_size}, ä¿è¯é‡‘={current_margin:.4f}u, æ ‡è®°ä»·æ ¼={mark_price}")
                            
                            if current_margin > 2.0 and current_pos_size > 0:
                                print(f"âš ï¸  ä¿è¯é‡‘ {current_margin:.4f}u > 2uï¼Œéœ€è¦è°ƒæ•´")
                                
                                # ç›®æ ‡ä¿è¯é‡‘è®¾ä¸º0.8Uï¼ˆåœ¨0.6-1Uä¹‹é—´ï¼‰
                                target_margin = 0.8
                                
                                # è®¡ç®—éœ€è¦çš„æŒä»“é‡ï¼šmargin = pos_size * mark_price / lever
                                # target_pos_size = target_margin * lever / mark_price
                                target_pos_size = (target_margin * lever) / mark_price
                                
                                # è®¡ç®—éœ€è¦å¹³ä»“çš„æ•°é‡
                                adjustment_size_raw = current_pos_size - target_pos_size
                                
                                # è·å–åˆçº¦é¢å€¼
                                inst_path = f'/api/v5/public/instruments?instType=SWAP&instId={inst_id}'
                                inst_resp = requests.get(OKEX_REST_URL + inst_path, timeout=10)
                                inst_data = inst_resp.json()
                                lot_size = 1
                                if inst_data.get('code') == '0' and inst_data.get('data'):
                                    lot_size = float(inst_data['data'][0].get('ctVal', 1))
                                
                                # å‘ä¸‹å–æ•´åˆ°lot_sizeçš„æ•´æ•°å€
                                adjustment_size = int(adjustment_size_raw / lot_size) * lot_size
                                
                                if adjustment_size > 0:
                                    print(f"ğŸ“‰ è®¡åˆ’å¹³ä»“: {adjustment_size} (ç›®æ ‡ä¿è¯é‡‘: {target_margin}u)")
                                    
                                    # æ‰§è¡Œå¹³ä»“
                                    close_side = 'buy' if pos_side == 'short' else 'sell'
                                    adjustment_body = {
                                        'instId': inst_id,
                                        'tdMode': 'isolated',  # é€ä»“æ¨¡å¼ï¼šæ¯ä¸ªæŒä»“ç‹¬ç«‹ä¿è¯é‡‘
                                        'side': close_side,
                                        'posSide': pos_side,
                                        'ordType': 'market',
                                        'sz': str(adjustment_size)
                                    }
                                    
                                    headers = get_headers('POST', order_path, adjustment_body)
                                    adj_response = requests.post(
                                        OKEX_REST_URL + order_path,
                                        headers=headers,
                                        json=adjustment_body,
                                        timeout=10
                                    )
                                    adj_data = adj_response.json()
                                    
                                    if adj_data.get('code') == '0':
                                        adjustment_order_id = adj_data['data'][0]['ordId']
                                        print(f"âœ… è°ƒæ•´å¹³ä»“æˆåŠŸ: è®¢å•ID {adjustment_order_id}, å¹³ä»“æ•°é‡ {adjustment_size}")
                                    else:
                                        print(f"âŒ è°ƒæ•´å¹³ä»“å¤±è´¥: {adj_data.get('msg')}")
                                else:
                                    print(f"âš ï¸  è®¡ç®—çš„å¹³ä»“æ•°é‡ <= 0ï¼Œè·³è¿‡è°ƒæ•´")
                            else:
                                print(f"âœ… ä¿è¯é‡‘ {current_margin:.4f}u <= 2uï¼Œæ— éœ€è°ƒæ•´")
                            break
            except Exception as adj_error:
                print(f"âš ï¸  ä¿è¯é‡‘è°ƒæ•´å¤±è´¥: {adj_error}")
                import traceback
                print(traceback.format_exc())
        else:
            print(f"â„¹ï¸  æ‰‹åŠ¨ç»´æŠ¤/è¶…çº§ç»´æŠ¤æ¨¡å¼ï¼Œè·³è¿‡ä¿è¯é‡‘è‡ªåŠ¨è°ƒæ•´")
        
        response_data = {
            'open_order_id': open_order_id,
            'close_order_id': close_order_id,
            'open_size': order_size,
            'close_size': close_size,
            'remaining_size': order_size - close_size,
            'open_fills': open_fills,
            'close_fills': close_fills,
            'open_total_fee': open_total_fee,
            'close_total_fee': close_total_fee,
            'total_fee': total_fee,
            'fee_rate': fee_rate
        }
        
        if adjustment_order_id:
            response_data['adjustment_order_id'] = adjustment_order_id
            response_data['adjustment_size'] = adjustment_size
        
        return jsonify({
            'success': True,
            'message': 'ç»´æŠ¤é”šç‚¹å•æ‰§è¡ŒæˆåŠŸ' + (f'ï¼Œå·²è°ƒæ•´ä¿è¯é‡‘ï¼ˆå¹³ä»“{adjustment_size}ï¼‰' if adjustment_order_id else ''),
            'data': response_data
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ‰§è¡Œå¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/maintenance-orders', methods=['GET'])
def get_maintenance_orders():
    """æŸ¥è¯¢ç»´æŠ¤é”šç‚¹å•è®°å½•"""
    try:
        import json as json_lib
        import os
        
        maintenance_file = 'maintenance_orders.json'
        
        # è¯»å–è®°å½•
        if os.path.exists(maintenance_file):
            with open(maintenance_file, 'r', encoding='utf-8') as f:
                records = json_lib.load(f)
        else:
            records = []
        
        # è·å–æŸ¥è¯¢å‚æ•°
        limit = request.args.get('limit', 50, type=int)
        inst_id = request.args.get('inst_id', None)
        
        # è¿‡æ»¤
        if inst_id:
            records = [r for r in records if r['inst_id'] == inst_id]
        
        # é™åˆ¶æ•°é‡
        records = records[:limit]
        
        return jsonify({
            'success': True,
            'data': records,
            'total': len(records)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/test-api-permission', methods=['GET'])
def test_api_permission():
    """æµ‹è¯•APIå¯†é’¥æƒé™"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        from okex_api_config import OKEX_API_KEY, OKEX_SECRET_KEY, OKEX_PASSPHRASE, OKEX_REST_URL
        
        # ç”Ÿæˆç­¾å
        def generate_signature(timestamp, method, request_path, body=''):
            if body:
                body = json.dumps(body)
            message = timestamp + method + request_path + body
            mac = hmac.new(
                bytes(OKEX_SECRET_KEY, encoding='utf8'),
                bytes(message, encoding='utf-8'),
                digestmod=hashlib.sha256
            )
            return base64.b64encode(mac.digest()).decode()
        
        def get_headers(method, request_path, body=''):
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
            sign = generate_signature(timestamp, method, request_path, body)
            return {
                'OK-ACCESS-KEY': OKEX_API_KEY,
                'OK-ACCESS-SIGN': sign,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': OKEX_PASSPHRASE,
                'Content-Type': 'application/json'
            }
        
        # æµ‹è¯•1ï¼šè¯»å–è´¦æˆ·ä½™é¢
        balance_path = '/api/v5/account/balance'
        headers = get_headers('GET', balance_path)
        balance_response = requests.get(
            OKEX_REST_URL + balance_path,
            headers=headers,
            timeout=10
        )
        balance_result = balance_response.json()
        
        # æµ‹è¯•2ï¼šè¯»å–æŒä»“ä¿¡æ¯
        position_path = '/api/v5/account/positions'
        headers = get_headers('GET', position_path)
        position_response = requests.get(
            OKEX_REST_URL + position_path,
            headers=headers,
            timeout=10
        )
        position_result = position_response.json()
        
        return jsonify({
            'success': True,
            'api_key': OKEX_API_KEY[:10] + '...',
            'tests': {
                'balance': {
                    'code': balance_result.get('code'),
                    'msg': balance_result.get('msg'),
                    'has_permission': balance_result.get('code') == '0'
                },
                'positions': {
                    'code': position_result.get('code'),
                    'msg': position_result.get('msg'),
                    'has_permission': position_result.get('code') == '0'
                }
            },
            'message': 'å¦‚æœhas_permissionéƒ½æ˜¯Trueï¼Œè¯´æ˜APIå¯†é’¥å¯ä»¥è¯»å–æ•°æ®ã€‚å¦‚æœäº¤æ˜“å¤±è´¥ï¼Œéœ€è¦åœ¨OKExåå°å‹¾é€‰ã€Œäº¤æ˜“ã€æƒé™ã€‚'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æµ‹è¯•å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/auto-maintenance-config', methods=['GET', 'POST'])
def auto_maintenance_config():
    """è·å–æˆ–è®¾ç½®è‡ªåŠ¨ç»´æŠ¤é…ç½®"""
    try:
        import json as json_lib
        import os
        
        config_file = 'auto_maintenance_config.json'
        
        if request.method == 'GET':
            # è¯»å–é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json_lib.load(f)
            else:
                # é»˜è®¤é…ç½®
                config = {
                    'auto_maintain_long_enabled': False,
                    'auto_maintain_short_enabled': False,
                    'super_maintain_long_enabled': False,
                    'super_maintain_short_enabled': False,
                    'loss_threshold': -10,
                    'margin_min': 0.6,
                    'margin_max': 1.0,
                    'last_check_time': None
                }
                # ä¿å­˜é»˜è®¤é…ç½®
                with open(config_file, 'w', encoding='utf-8') as f:
                    json_lib.dump(config, f, ensure_ascii=False, indent=2)
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.get_json()
            
            # è¯»å–ç°æœ‰é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json_lib.load(f)
            else:
                config = {
                    'auto_maintain_long_enabled': False,
                    'auto_maintain_short_enabled': False,
                    'super_maintain_long_enabled': False,
                    'super_maintain_short_enabled': False,
                    'loss_threshold': -10,
                    'margin_min': 0.6,
                    'margin_max': 1.0,
                    'last_check_time': None
                }
            
            # æ›´æ–°æŒ‡å®šçš„å­—æ®µ
            if 'auto_maintain_long_enabled' in data:
                config['auto_maintain_long_enabled'] = data['auto_maintain_long_enabled']
            if 'auto_maintain_short_enabled' in data:
                config['auto_maintain_short_enabled'] = data['auto_maintain_short_enabled']
            if 'super_maintain_long_enabled' in data:
                config['super_maintain_long_enabled'] = data['super_maintain_long_enabled']
            if 'super_maintain_short_enabled' in data:
                config['super_maintain_short_enabled'] = data['super_maintain_short_enabled']
            if 'loss_threshold' in data:
                config['loss_threshold'] = data['loss_threshold']
            if 'margin_min' in data:
                config['margin_min'] = data['margin_min']
            if 'margin_max' in data:
                config['margin_max'] = data['margin_max']
            
            # ä¿å­˜é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json_lib.dump(config, f, ensure_ascii=False, indent=2)
            
            return jsonify({
                'success': True,
                'message': 'é…ç½®å·²æ›´æ–°',
                'config': config
            })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ“ä½œå¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/sub-account/config', methods=['GET', 'POST'])
def sub_account_config_v2():
    """è·å–æˆ–è®¾ç½®å­è´¦æˆ·é…ç½®"""
    try:
        import json as json_lib
        import os
        
        config_file = 'sub_account_config.json'
        
        if request.method == 'GET':
            # è¯»å–é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json_lib.load(f)
            else:
                return jsonify({
                    'success': False,
                    'message': 'å­è´¦æˆ·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                })
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.get_json()
            
            # è¯»å–ç°æœ‰é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json_lib.load(f)
            else:
                return jsonify({
                    'success': False,
                    'message': 'å­è´¦æˆ·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                })
            
            # æ›´æ–°æŒ‡å®šçš„å­—æ®µ
            if 'super_maintain_long_enabled' in data:
                config['super_maintain_long_enabled'] = data['super_maintain_long_enabled']
            if 'super_maintain_short_enabled' in data:
                config['super_maintain_short_enabled'] = data['super_maintain_short_enabled']
            
            # ä¿å­˜é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json_lib.dump(config, f, ensure_ascii=False, indent=2)
            
            return jsonify({
                'success': True,
                'message': 'å­è´¦æˆ·é…ç½®å·²æ›´æ–°',
                'config': config
            })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ“ä½œå¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/maintenance-stats', methods=['GET'])
def get_maintenance_stats():
    """è·å–ç»´æŠ¤æ¬¡æ•°ç»Ÿè®¡ï¼ˆæŒ‰è‡ªç„¶æ—¥ã€å¸ç§å’Œæ–¹å‘ï¼‰"""
    try:
        import json as json_lib
        import os
        from datetime import datetime
        from collections import defaultdict
        
        maintenance_file = 'maintenance_orders.json'
        
        if not os.path.exists(maintenance_file):
            return jsonify({
                'success': True,
                'stats': {},
                'today_date': get_china_today()
            })
        
        # è¯»å–ç»´æŠ¤è®°å½•
        with open(maintenance_file, 'r', encoding='utf-8') as f:
            records = json_lib.load(f)
        
        # ä»Šå¤©çš„æ—¥æœŸ
        today = get_china_today()
        
        # ç»Ÿè®¡ä»Šå¤©æ¯ä¸ªå¸ç§+æ–¹å‘çš„ç»´æŠ¤æ¬¡æ•°ï¼ˆæ™®é€šç»´æŠ¤å’Œè¶…çº§ç»´æŠ¤éƒ½æ˜¯+1ï¼‰
        stats = defaultdict(int)
        
        for record in records:
            created_at = record.get('created_at', '')
            if created_at.startswith(today):
                inst_id = record.get('inst_id', '')
                pos_side = record.get('pos_side', '')
                key = f"{inst_id}:{pos_side}"
                
                # æ— è®ºæ˜¯æ™®é€šç»´æŠ¤è¿˜æ˜¯è¶…çº§ç»´æŠ¤ï¼Œéƒ½è®¡æ•°+1
                stats[key] += 1
        
        return jsonify({
            'success': True,
            'stats': dict(stats),
            'today_date': today
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

# ==================== å†å²å¿«ç…§API ====================

@app.route('/api/anchor/snapshots/positions', methods=['GET'])
def get_position_snapshots():
    """è·å–æŒä»“å†å²å¿«ç…§"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        # è·å–å‚æ•°
        start_time = request.args.get('start_time')  # 2025-12-30 00:00:00
        end_time = request.args.get('end_time')      # 2025-12-30 23:59:59
        inst_id = request.args.get('inst_id')        # å¯é€‰ï¼šç­›é€‰å¸ç§
        pos_side = request.args.get('pos_side')      # å¯é€‰ï¼šç­›é€‰æ–¹å‘
        limit = int(request.args.get('limit', 100))  # é»˜è®¤100æ¡
        
        # é»˜è®¤æŸ¥è¯¢æœ€è¿‘24å°æ—¶
        if not end_time:
            end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        if not start_time:
            start_dt = datetime.now() - timedelta(hours=24)
            start_time = start_dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # æŸ¥è¯¢æ•°æ®åº“
        conn = sqlite3.connect('/home/user/webapp/anchor_snapshots.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        query = '''
        SELECT snapshot_time, inst_id, pos_side, pos_size, avg_price,
               mark_price, leverage, margin, profit_rate, upl,
               maintenance_count, is_anchor, status
        FROM position_snapshots
        WHERE snapshot_time BETWEEN ? AND ?
        '''
        params = [start_time, end_time]
        
        if inst_id:
            query += ' AND inst_id = ?'
            params.append(inst_id)
        
        if pos_side:
            query += ' AND pos_side = ?'
            params.append(pos_side)
        
        query += ' ORDER BY snapshot_time DESC LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        snapshots = []
        for row in rows:
            snapshots.append({
                'snapshot_time': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'pos_size': row[3],
                'avg_price': row[4],
                'mark_price': row[5],
                'leverage': row[6],
                'margin': row[7],
                'profit_rate': row[8],
                'upl': row[9],
                'maintenance_count': row[10],
                'is_anchor': row[11],
                'status': row[12]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'snapshots': snapshots,
            'count': len(snapshots),
            'start_time': start_time,
            'end_time': end_time
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/anchor/snapshots/statistics', methods=['GET'])
def get_statistics_snapshots():
    """è·å–ç»Ÿè®¡å†å²å¿«ç…§"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        # è·å–å‚æ•°
        start_time = request.args.get('start_time')
        end_time = request.args.get('end_time')
        stat_type = request.args.get('stat_type')  # å¯é€‰ï¼šç­›é€‰ç»Ÿè®¡ç±»å‹
        limit = int(request.args.get('limit', 100))
        
        # é»˜è®¤æŸ¥è¯¢æœ€è¿‘24å°æ—¶
        if not end_time:
            end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        if not start_time:
            start_dt = datetime.now() - timedelta(hours=24)
            start_time = start_dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # æŸ¥è¯¢æ•°æ®åº“
        conn = sqlite3.connect('/home/user/webapp/anchor_snapshots.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        query = '''
        SELECT snapshot_time, stat_type, stat_value, stat_label
        FROM statistics_snapshots
        WHERE snapshot_time BETWEEN ? AND ?
        '''
        params = [start_time, end_time]
        
        if stat_type:
            query += ' AND stat_type = ?'
            params.append(stat_type)
        
        query += ' ORDER BY snapshot_time DESC, stat_type LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        snapshots = []
        for row in rows:
            snapshots.append({
                'snapshot_time': row[0],
                'stat_type': row[1],
                'stat_value': row[2],
                'stat_label': row[3]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'snapshots': snapshots,
            'count': len(snapshots),
            'start_time': start_time,
            'end_time': end_time
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/anchor/snapshots/times', methods=['GET'])
def get_snapshot_times():
    """è·å–å¯ç”¨çš„å¿«ç…§æ—¶é—´ç‚¹åˆ—è¡¨"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        # è·å–å‚æ•°
        date = request.args.get('date')  # æ ¼å¼ï¼š2025-12-30
        
        if not date:
            date = get_china_today()
        
        # æŸ¥è¯¢æ•°æ®åº“
        conn = sqlite3.connect('/home/user/webapp/anchor_snapshots.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢å½“å¤©çš„æ‰€æœ‰å¿«ç…§æ—¶é—´
        cursor.execute('''
        SELECT DISTINCT snapshot_time
        FROM position_snapshots
        WHERE snapshot_time LIKE ?
        ORDER BY snapshot_time DESC
        ''', (f"{date}%",))
        
        rows = cursor.fetchall()
        times = [row[0] for row in rows]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'times': times,
            'count': len(times),
            'date': date
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/trading/positions/opens')
def get_trading_positions_opens():
    """è·å–å¼€ä»“æŒä»“ - Trading Managerä¸“ç”¨ï¼Œæ”¯æŒç»´æŠ¤ä»·æ ¼è¡¨"""
    try:
        import sqlite3
        
        # è·å–å‚æ•°
        is_anchor = request.args.get('is_anchor', type=int)
        limit = request.args.get('limit', 50, type=int)
        trade_mode = request.args.get('trade_mode', 'paper')
        
        DB_PATH = '/home/user/webapp/trading_decision.db'
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # å¦‚æœæ˜¯é”šç‚¹å•ï¼Œä½¿ç”¨ç»´æŠ¤ä»·æ ¼è¡¨
        if is_anchor == 1:
            # è”åˆæŸ¥è¯¢ï¼šposition_opens å’Œ anchor_maintenance_prices
            cursor.execute('''
                SELECT 
                    p.id,
                    p.inst_id,
                    p.pos_side,
                    p.open_size,
                    p.mark_price,
                    p.profit_rate,
                    p.lever,
                    p.upl,
                    p.margin,
                    p.created_at,
                    p.updated_time,
                    p.trade_mode,
                    p.is_anchor,
                    p.granularity,
                    p.open_percent,
                    p.total_adds,
                    p.total_positions,
                    COALESCE(amp.maintenance_price, p.open_price) as open_price,
                    amp.original_open_price,
                    amp.maintenance_count,
                    amp.last_maintenance_time,
                    p.mark_price as current_price
                FROM position_opens p
                LEFT JOIN anchor_maintenance_prices amp 
                    ON p.inst_id = amp.inst_id 
                    AND p.pos_side = amp.pos_side 
                    AND p.trade_mode = amp.trade_mode
                WHERE p.is_anchor = 1 AND p.trade_mode = ?
                ORDER BY p.id DESC
                LIMIT ?
            ''', (trade_mode, limit))
            
            rows = cursor.fetchall()
            
            # è·å–æœ€æ–°ä»·æ ¼æ›´æ–°æ—¶é—´
            cursor.execute('''
                SELECT MAX(updated_time) FROM position_opens WHERE is_anchor = 1 AND trade_mode = ?
            ''', (trade_mode,))
            
            price_update_time = cursor.fetchone()[0] or ''
            
            records = []
            for row in rows:
                records.append({
                    'id': row['id'],
                    'inst_id': row['inst_id'],
                    'pos_side': row['pos_side'],
                    'open_price': float(row['open_price']),  # ä½¿ç”¨ç»´æŠ¤ä»·æ ¼
                    'original_open_price': float(row['original_open_price']) if row['original_open_price'] else None,
                    'open_size': float(row['open_size']),
                    'current_price': float(row['current_price']) if row['current_price'] else 0.0,
                    'mark_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'profit_rate': float(row['profit_rate']) if row['profit_rate'] else 0.0,
                    'lever': int(row['lever']) if row['lever'] else 10,
                    'upl': float(row['upl']) if row['upl'] else 0.0,
                    'margin': float(row['margin']) if row['margin'] else 0.0,
                    'is_anchor': bool(row['is_anchor']),
                    'granularity': float(row['granularity']) if row['granularity'] else 0.0,
                    'open_percent': float(row['open_percent']) if row['open_percent'] else 0.0,
                    'total_adds': int(row['total_adds']) if row['total_adds'] else 0,
                    'total_positions': int(row['total_positions']) if row['total_positions'] else 0,
                    'maintenance_count': int(row['maintenance_count']) if row['maintenance_count'] else 0,
                    'last_maintenance_time': row['last_maintenance_time'] or '',
                    'created_at': row['created_at'],
                    'price_update_time': row['updated_time'] or '',
                    'trade_mode': row['trade_mode']
                })
            
            conn.close()
            
            return jsonify({
                'success': True,
                'records': records,
                'total': len(records),
                'price_update_time': price_update_time,
                'trade_mode': trade_mode
            })
        
        # éé”šç‚¹å•ï¼Œç›´æ¥æŸ¥è¯¢
        else:
            cursor.execute('''
                SELECT 
                    id, inst_id, pos_side, open_price, open_size, mark_price, 
                    profit_rate, lever, upl, margin, created_at, updated_time,
                    trade_mode, is_anchor, granularity, open_percent, 
                    total_adds, total_positions
                FROM position_opens
                WHERE (? IS NULL OR is_anchor = ?) AND trade_mode = ?
                ORDER BY id DESC
                LIMIT ?
            ''', (is_anchor, is_anchor, trade_mode, limit))
            
            rows = cursor.fetchall()
            conn.close()
            
            records = []
            for row in rows:
                records.append({
                    'id': row['id'],
                    'inst_id': row['inst_id'],
                    'pos_side': row['pos_side'],
                    'open_price': float(row['open_price']),
                    'open_size': float(row['open_size']),
                    'current_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'mark_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'profit_rate': float(row['profit_rate']) if row['profit_rate'] else 0.0,
                    'lever': int(row['lever']) if row['lever'] else 10,
                    'upl': float(row['upl']) if row['upl'] else 0.0,
                    'margin': float(row['margin']) if row['margin'] else 0.0,
                    'is_anchor': bool(row['is_anchor']),
                    'granularity': float(row['granularity']) if row['granularity'] else 0.0,
                    'open_percent': float(row['open_percent']) if row['open_percent'] else 0.0,
                    'total_adds': int(row['total_adds']) if row['total_adds'] else 0,
                    'total_positions': int(row['total_positions']) if row['total_positions'] else 0,
                    'created_at': row['created_at'],
                    'price_update_time': row['updated_time'] or '',
                    'trade_mode': row['trade_mode']
                })
            
            return jsonify({
                'success': True,
                'records': records,
                'total': len(records),
                'trade_mode': trade_mode
            })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/reset-maintenance-count', methods=['POST'])
def reset_maintenance_count():
    """æ¸…é›¶å­è´¦æˆ·ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°"""
    try:
        from datetime import datetime
        import pytz
        
        data = request.json
        account_name = data.get('account_name')
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')
        
        if not all([account_name, inst_id, pos_side]):
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            })
        
        # è¯»å–ç»´æŠ¤è®°å½•æ–‡ä»¶
        maintenance_file = 'sub_account_maintenance.json'
        try:
            with open(maintenance_file, 'r', encoding='utf-8') as f:
                maintenance_data = json.load(f)
        except FileNotFoundError:
            maintenance_data = {}
        
        # æ„å»ºè®°å½•é”®
        record_key = f"{account_name}_{inst_id}_{pos_side}"
        
        # è·å–å½“å‰åŒ—äº¬æ—¶é—´çš„æ—¥æœŸ
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now_beijing = datetime.now(beijing_tz)
        today_date = now_beijing.strftime('%Y-%m-%d')
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»Šæ—¥è®°å½•
        if record_key not in maintenance_data:
            return jsonify({
                'success': False,
                'message': 'è¯¥æŒä»“æ²¡æœ‰ç»´æŠ¤è®°å½•'
            })
        
        record = maintenance_data[record_key]
        
        # æ¸…é›¶ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°
        old_count = record.get('count', 0)
        old_date = record.get('date', '')
        
        # é‡ç½®è®°å½•
        record['count'] = 0
        record['date'] = today_date
        record['last_reset'] = now_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(maintenance_file, 'w', encoding='utf-8') as f:
            json.dump(maintenance_data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'message': f'æ¸…é›¶æˆåŠŸï¼åŸç»´æŠ¤æ¬¡æ•°: {old_count}æ¬¡',
            'data': {
                'account_name': account_name,
                'inst_id': inst_id,
                'pos_side': pos_side,
                'old_count': old_count,
                'old_date': old_date,
                'new_count': 0,
                'reset_time': record['last_reset']
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ¸…é›¶å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/maintain-sub-account', methods=['POST'])
def maintain_sub_account():
    """å­è´¦æˆ·ç»´æŠ¤é”šç‚¹å•ï¼šä¹°å…¥100Uå¹¶ç«‹å³å¹³æ‰"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        import pytz
        import os
        import math
        import time
        
        data = request.json
        account_name = data.get('account_name')
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')
        pos_size = float(data.get('pos_size', 0))
        
        # æ–°å¢å‚æ•°ï¼šæ”¯æŒåŠ¨æ€ç»´æŠ¤é‡‘é¢å’Œç›®æ ‡ä¿è¯é‡‘
        maintenance_amount = float(data.get('amount', 100))  # ç»´æŠ¤é‡‘é¢ï¼Œé»˜è®¤100U
        target_margin = float(data.get('target_margin', 10))  # ç›®æ ‡ä¿è¯é‡‘ï¼Œé»˜è®¤10U
        maintenance_count = int(data.get('maintenance_count', 0))  # å½“å‰ç»´æŠ¤æ¬¡æ•°
        
        if not all([account_name, inst_id, pos_side]):
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            })
        
        # è¯»å–å­è´¦æˆ·é…ç½®
        with open('sub_account_config.json', 'r', encoding='utf-8') as f:
            config = json_lib.load(f)
        
        # æŸ¥æ‰¾å¯¹åº”çš„å­è´¦æˆ·
        sub_account = None
        for acc in config.get('sub_accounts', []):
            if acc['account_name'] == account_name:
                sub_account = acc
                break
        
        if not sub_account:
            return jsonify({
                'success': False,
                'message': f'æœªæ‰¾åˆ°å­è´¦æˆ·: {account_name}'
            })
        
        api_key = sub_account['api_key']
        secret_key = sub_account['secret_key']
        passphrase = sub_account['passphrase']
        
        # æ£€æŸ¥ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°
        maintenance_file = 'sub_account_maintenance.json'
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now_beijing = datetime.now(beijing_tz)
        today_date = now_beijing.strftime('%Y-%m-%d')
        
        # è¯»å–ç»´æŠ¤è®°å½•
        if os.path.exists(maintenance_file):
            with open(maintenance_file, 'r', encoding='utf-8') as f:
                maintenance_data = json.load(f)
        else:
            maintenance_data = {}
        
        record_key = f"{account_name}_{inst_id}_{pos_side}"
        record = maintenance_data.get(record_key, {})
        
        # æ£€æŸ¥15åˆ†é’Ÿç»´æŠ¤é—´éš”
        last_maintenance_str = record.get('last_maintenance', '')
        if last_maintenance_str:
            try:
                last_time = datetime.strptime(last_maintenance_str, '%Y-%m-%d %H:%M:%S')
                last_time = beijing_tz.localize(last_time)
                time_diff = (now_beijing - last_time).total_seconds() / 60
                
                if time_diff < 15:
                    return jsonify({
                        'success': False,
                        'message': f'è·ç¦»ä¸Šæ¬¡ç»´æŠ¤ä»…{time_diff:.1f}åˆ†é’Ÿï¼Œéœ€è¦è‡³å°‘15åˆ†é’Ÿé—´éš”',
                        'last_maintenance': last_maintenance_str,
                        'next_available': (last_time + timedelta(minutes=15)).strftime('%Y-%m-%d %H:%M:%S')
                    })
            except Exception as e:
                print(f"è§£æä¸Šæ¬¡ç»´æŠ¤æ—¶é—´å¤±è´¥: {e}")
        
        # è·å–å½“å‰ç»´æŠ¤æ¬¡æ•°ï¼ˆä¸å†æŒ‰æ—¥æœŸé‡ç½®ï¼‰
        current_count = record.get('count', 0)
        
        max_count = sub_account.get('max_maintenance_count', 3)
        if current_count >= max_count:
            return jsonify({
                'success': False,
                'message': f'ç»´æŠ¤æ¬¡æ•°å·²è¾¾ä¸Šé™({max_count}æ¬¡)ï¼Œè¯·æ‰‹åŠ¨æ¸…é›¶',
                'current_count': current_count,
                'max_count': max_count
            })
        
        # OKEx APIç­¾åå‡½æ•°
        def generate_signature(timestamp, method, request_path, body=''):
            if body:
                body = json.dumps(body)
            message = timestamp + method + request_path + body
            mac = hmac.new(
                bytes(secret_key, encoding='utf8'),
                bytes(message, encoding='utf-8'),
                digestmod=hashlib.sha256
            )
            return base64.b64encode(mac.digest()).decode()
        
        def get_headers(method, request_path, body=''):
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
            sign = generate_signature(timestamp, method, request_path, body)
            return {
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': sign,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
                'Content-Type': 'application/json'
            }
        
        OKEX_REST_URL = 'https://www.okx.com'
        
        # ç»´æŠ¤æ“ä½œï¼šä¹°å…¥100Uå¹¶ç«‹å³å¹³æ‰
        # è®¡ç®—ä¹°å…¥æ•°é‡ï¼š100U / æ ‡è®°ä»·æ ¼ * æ æ†
        # å…ˆè·å–å½“å‰æ ‡è®°ä»·æ ¼
        position_path = f'/api/v5/account/positions?instType=SWAP&instId={inst_id}'
        headers = get_headers('GET', position_path)
        pos_response = requests.get(
            OKEX_REST_URL + position_path,
            headers=headers,
            timeout=10
        )
        pos_data = pos_response.json()
        
        mark_price = 0
        for position in pos_data.get('data', []):
            if position.get('posSide') == pos_side:
                # å®‰å…¨è½¬æ¢ï¼šå¤„ç†ç©ºå­—ç¬¦ä¸²å’ŒNone
                mark_px_str = position.get('markPx', '0')
                try:
                    mark_price = float(mark_px_str) if mark_px_str and mark_px_str != '' else 0
                except (ValueError, TypeError):
                    mark_price = 0
                break
        
        if mark_price == 0:
            # å¦‚æœæ²¡æœ‰æŒä»“ï¼ŒæŸ¥è¯¢è¡Œæƒ…è·å–ä»·æ ¼
            ticker_path = f'/api/v5/market/ticker?instId={inst_id}'
            ticker_response = requests.get(
                OKEX_REST_URL + ticker_path,
                timeout=10
            )
            ticker_data = ticker_response.json()
            if ticker_data.get('code') == '0' and ticker_data.get('data'):
                # å®‰å…¨è½¬æ¢ï¼šå¤„ç†ç©ºå­—ç¬¦ä¸²å’ŒNone
                last_price_str = ticker_data['data'][0].get('last', '0')
                try:
                    mark_price = float(last_price_str) if last_price_str and last_price_str != '' else 0
                except (ValueError, TypeError):
                    mark_price = 0
        
        if mark_price == 0:
            return jsonify({
                'success': False,
                'message': f'æ— æ³•è·å–æ ‡è®°ä»·æ ¼ï¼Œæ£€æŸ¥æŒä»“å’Œè¡Œæƒ…æ•°æ®'
            })
        
        print(f"ğŸ¯ å­è´¦æˆ·ç»´æŠ¤: {account_name} {inst_id} {pos_side}")
        print(f"   æ ‡è®°ä»·æ ¼: {mark_price}")
        print(f"   ç»´æŠ¤é‡‘é¢: {maintenance_amount}U")
        print(f"   ç›®æ ‡ä¿è¯é‡‘: {target_margin}U")
        print(f"   æ æ†: {sub_account.get('leverage', 10)}x")
        
        # ========== è®¡ç®—å¼€ä»“å’Œå¹³ä»“æ•°é‡ï¼ˆå…ˆå¼€å†å¹³é€»è¾‘ï¼‰==========
        import math
        lever = int(sub_account.get('leverage', 10))
        
        # æ–°å¼€ä»“çš„æ•°é‡ï¼šä½¿ç”¨åŠ¨æ€ç»´æŠ¤é‡‘é¢
        new_order_size_raw = (maintenance_amount * lever) / mark_price
        new_order_size = math.floor(new_order_size_raw)
        
        # é‡è¦ï¼šå¦‚æœnew_order_sizeè®¡ç®—ä¸º0ï¼Œè¯´æ˜ç»´æŠ¤é‡‘é¢å¤ªå°ï¼Œè‡³å°‘å¼€1å¼ 
        if new_order_size == 0 and new_order_size_raw > 0:
            new_order_size = 1
            print(f"âš ï¸  new_order_sizeè®¡ç®—ä¸º {new_order_size_raw:.2f}ï¼Œå‘ä¸‹å–æ•´ä¸º0ï¼Œå¼ºåˆ¶å¼€ä»“1å¼ ")
        
        # å¦‚æœnew_order_sizeä»ç„¶æ˜¯0ï¼Œè¿”å›é”™è¯¯
        if new_order_size == 0:
            return jsonify({
                'success': False,
                'message': f'ç»´æŠ¤é‡‘é¢å¤ªå°ï¼Œæ— æ³•å¼€ä»“ã€‚å½“å‰ä»·æ ¼ {mark_price}ï¼Œå»ºè®®å¢åŠ ç»´æŠ¤é‡‘é¢è‡³å°‘åˆ° {math.ceil(mark_price / lever)}U'
            })
        
        # è®¡ç®—æœ€ç»ˆä¿ç•™çš„ä»“ä½ï¼štarget_marginå¯¹åº”çš„ä»“ä½
        keep_size_raw = (target_margin * lever) / mark_price
        keep_size = math.floor(keep_size_raw)
        
        # ğŸ”´ é‡è¦ï¼šç¡®ä¿ä¿ç•™çš„ä»“ä½å¯¹åº”çš„ä¿è¯é‡‘ä¸å°äº0.6Uï¼ˆOKExæœ€å°ä¿è¯é‡‘è¦æ±‚ï¼‰
        MIN_MARGIN = 0.6  # æœ€å°ä¿è¯é‡‘0.6U
        min_keep_size = math.ceil((MIN_MARGIN * lever) / mark_price)
        
        if keep_size < min_keep_size:
            old_keep_size = keep_size
            keep_size = min_keep_size
            print(f"âš ï¸  keep_sizeè®¡ç®—ä¸º {keep_size_raw:.2f}ï¼ˆ{old_keep_size} å¼ ï¼‰ï¼Œä½†ä¸ºæ»¡è¶³æœ€å°ä¿è¯é‡‘0.6Uè¦æ±‚ï¼Œå¼ºåˆ¶ä¿ç•™ {keep_size} å¼ ")
        
        # è®¡ç®—éœ€è¦å¹³æ‰çš„æ•°é‡ = æ—§æŒä»“ + æ–°å¼€ä»“ - æœ€ç»ˆä¿ç•™
        # ä¾‹å¦‚ï¼šæ—§æŒä»“10U(100å¼ ) + æ–°å¼€100U(1000å¼ ) - ä¿ç•™10U(100å¼ ) = å¹³æ‰1000å¼ 
        total_pos_size = pos_size + new_order_size
        close_size = total_pos_size - keep_size
        
        # ç¡®ä¿close_sizeä¸ä¸ºè´Ÿæ•°
        if close_size < 0:
            close_size = 0
            print(f"âš ï¸  è®¡ç®—å‡ºçš„close_sizeä¸ºè´Ÿæ•°ï¼Œè®¾ä¸º0ï¼ˆæ— éœ€å¹³ä»“ï¼‰")
        
        print(f"ğŸ“Š ä»“ä½è®¡ç®—:")
        print(f"   å½“å‰æŒä»“: {pos_size} å¼ ")
        print(f"   æ–°å¼€ä»“: {new_order_size} å¼ ")
        print(f"   æ€»æŒä»“: {total_pos_size} å¼ ")
        print(f"   æœ€ç»ˆä¿ç•™: {keep_size} å¼ ")
        print(f"   éœ€è¦å¹³ä»“: {close_size} å¼ ")
        
        # ========== ç¬¬1æ­¥ï¼šè®¾ç½®é€ä»“æ æ† ==========
        print(f"ğŸ“Š ç¬¬1æ­¥ï¼šè®¾ç½®é€ä»“æ æ† {lever}x")
        leverage_path = '/api/v5/account/set-leverage'
        leverage_body = {
            'instId': inst_id,
            'lever': str(lever),
            'mgnMode': 'isolated',  # é€ä»“æ¨¡å¼
            'posSide': pos_side
        }
        leverage_headers = get_headers('POST', leverage_path, leverage_body)
        leverage_response = requests.post(
            OKEX_REST_URL + leverage_path,
            headers=leverage_headers,
            json=leverage_body,
            timeout=10
        )
        leverage_result = leverage_response.json()
        print(f"ğŸ“¥ è®¾ç½®æ æ†å“åº”: code={leverage_result.get('code')}, msg={leverage_result.get('msg')}")
        if leverage_result.get('code') != '0':
            print(f"âš ï¸  è®¾ç½®æ æ†å¤±è´¥ï¼ˆå¯èƒ½å·²è®¾ç½®ï¼‰: {leverage_result.get('msg')}")
        time.sleep(0.5)
        
        # ========== ç¬¬2æ­¥ï¼šå¼€ä»“æ–°æŒä»“ï¼ˆç»´æŠ¤é‡‘é¢å¯¹åº”çš„ä»“ä½ï¼‰==========
        print(f"ğŸ“Š ç¬¬2æ­¥ï¼šå¼€ä»“æ–°æŒä»“ {new_order_size} å¼ ï¼ˆç»´æŠ¤é‡‘é¢ {maintenance_amount}Uï¼‰")
        order_path = '/api/v5/trade/order'
        side = 'sell' if pos_side == 'short' else 'buy'
        
        open_order_body = {
            'instId': inst_id,
            'tdMode': 'isolated',  # é€ä»“æ¨¡å¼
            'side': side,
            'posSide': pos_side,
            'ordType': 'market',
            'sz': str(new_order_size)
        }
        
        headers = get_headers('POST', order_path, open_order_body)
        open_response = requests.post(
            OKEX_REST_URL + order_path,
            headers=headers,
            json=open_order_body,
            timeout=10
        )
        
        open_result = open_response.json()
        
        # è¯¦ç»†æ—¥å¿—ï¼šæ‰“å°OKExå“åº”
        print(f"ğŸ“¤ å¼€ä»“è¯·æ±‚: {open_order_body}")
        print(f"ğŸ“¥ OKExå“åº”: code={open_result.get('code')}, msg={open_result.get('msg')}")
        if open_result.get('code') != '0':
            print(f"âŒ å®Œæ•´å“åº”: {open_result}")
        
        if open_result.get('code') != '0':
            return jsonify({
                'success': False,
                'message': f"å¼€ä»“å¤±è´¥: {open_result.get('msg', 'æœªçŸ¥é”™è¯¯')}",
                'error_code': open_result.get('code'),
                'full_response': str(open_result)
            })
        
        open_order_id = open_result['data'][0]['ordId']
        print(f"âœ… å¼€ä»“è®¢å•ID: {open_order_id}")
        
        # ç­‰å¾…å¼€ä»“å®Œæˆ
        time.sleep(2)
        open_order_id = open_result['data'][0]['ordId']
        
        # ç­‰å¾…è®¢å•æˆäº¤
        import time
        time.sleep(2)
        
        # ========== ç¬¬3æ­¥ï¼šå¹³æ‰å¤šä½™ä»“ä½ï¼Œä¿ç•™target_marginå¯¹åº”çš„æ•°é‡ ==========
        close_order_id = None
        if close_size > 0:
            print(f"ğŸ“Š ç¬¬3æ­¥ï¼šå¹³åˆ°ç›®æ ‡ä¿è¯é‡‘ï¼Œå¹³æ‰ {close_size} å¼ ")
            # close_sizeå·²ç»åœ¨å‰é¢è®¡ç®—å¥½äº†
            close_side = 'buy' if pos_side == 'short' else 'sell'
            
            close_order_body = {
                'instId': inst_id,
                'tdMode': 'isolated',  # é€ä»“æ¨¡å¼
                'side': close_side,
                'posSide': pos_side,
                'ordType': 'market',
                'sz': str(close_size)
            }
            
            headers = get_headers('POST', order_path, close_order_body)
            close_response = requests.post(
                OKEX_REST_URL + order_path,
                headers=headers,
                json=close_order_body,
                timeout=10
            )
            
            close_result = close_response.json()
            
            if close_result.get('code') != '0':
                return jsonify({
                    'success': False,
                    'message': f"å¹³ä»“å¤±è´¥: {close_result.get('msg', 'æœªçŸ¥é”™è¯¯')} (å¼€ä»“è®¢å•ID: {open_order_id})",
                    'error_code': close_result.get('code'),
                    'open_order_id': open_order_id
                })
            
            close_order_id = close_result['data'][0]['ordId']
        else:
            print(f"ğŸ“Š ç¬¬3æ­¥ï¼šè·³è¿‡ï¼ˆclose_size={close_size}ï¼Œæ— éœ€å¹³ä»“ï¼‰")
            close_order_id = "SKIPPED"
        
        # ç»´æŠ¤æˆåŠŸï¼Œæ›´æ–°ç»´æŠ¤æ¬¡æ•°ï¼ˆä¸å†æŒ‰æ—¥æœŸé‡ç½®ï¼‰
        if not record:
            # ç¬¬ä¸€æ¬¡ç»´æŠ¤ï¼Œåˆ›å»ºè®°å½•
            record = {
                'count': 1,
                'last_maintenance': now_beijing.strftime('%Y-%m-%d %H:%M:%S')
            }
        else:
            # å¢åŠ æ¬¡æ•°ï¼ˆä¸å†æ£€æŸ¥æ—¥æœŸï¼‰
            record['count'] = record.get('count', 0) + 1
            record['last_maintenance'] = now_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        maintenance_data[record_key] = record
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(maintenance_file, 'w', encoding='utf-8') as f:
            json.dump(maintenance_data, f, ensure_ascii=False, indent=2)
        
        # ğŸ” ç»´æŠ¤åè‡ªåŠ¨éªŒè¯å’Œçº é”™
        print(f"\n{'='*60}")
        print(f"ğŸ” å¯åŠ¨ç»´æŠ¤åè‡ªåŠ¨éªŒè¯...")
        try:
            from maintenance_verifier import verify_and_correct
            verify_result = verify_and_correct(
                account_name=account_name,
                inst_id=inst_id,
                pos_side=pos_side,
                target_margin=target_margin,
                maintenance_count=record['count']
            )
            print(f"âœ… éªŒè¯å®Œæˆ: {verify_result.get('message')}")
            if verify_result.get('corrected'):
                print(f"âš ï¸ å·²æ‰§è¡Œè‡ªåŠ¨çº é”™")
        except Exception as e:
            print(f"âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        print(f"{'='*60}\n")
        
        return jsonify({
            'success': True,
            'message': f'ç»´æŠ¤æˆåŠŸï¼ç¬¬{record["count"]}æ¬¡ç»´æŠ¤',
            'data': {
                'account_name': account_name,
                'inst_id': inst_id,
                'pos_side': pos_side,
                'open_order_id': open_order_id,
                'close_order_id': close_order_id,
                'order_size': new_order_size,  # æ–°å¼€ä»“çš„æ•°é‡
                'close_size': close_size,  # å¹³ä»“çš„æ•°é‡
                'total_count': record['count'],
                'max_count': max_count
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'ç»´æŠ¤å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/sub-account/close-all-positions', methods=['POST'])
def close_all_sub_account_positions():
    """ä¸€é”®å…¨éƒ¨å¹³ä»“ï¼šå…³é—­æ‰€æœ‰å­è´¦æˆ·çš„æ‰€æœ‰æŒä»“"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        
        print("ğŸš¨ å¼€å§‹æ‰§è¡Œä¸€é”®å…¨éƒ¨å¹³ä»“...")
        
        # OKEx APIé…ç½®
        OKEX_REST_URL = 'https://www.okx.com'
        
        # ç›´æ¥è¯»å–å­è´¦æˆ·é…ç½®å¹¶è·å–æŒä»“
        all_positions = []
        
        try:
            with open('sub_account_config.json', 'r', encoding='utf-8') as f:
                config_data = json_lib.load(f)
        except FileNotFoundError:
            return jsonify({
                'success': False,
                'message': 'å­è´¦æˆ·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
            })
        
        # éå†æ‰€æœ‰å­è´¦å·è·å–æŒä»“
        print(f"ğŸ“‹ é…ç½®ä¸­çš„å­è´¦å·æ•°é‡: {len(config_data.get('sub_accounts', []))}")
        
        for sub_account in config_data.get('sub_accounts', []):
            account_name = sub_account.get('account_name', 'Unknown')
            enabled = sub_account.get('enabled', False)
            print(f"  - {account_name}: enabled={enabled}")
            
            if not enabled:
                continue
            
            api_key = sub_account.get('api_key', '')
            secret_key = sub_account.get('secret_key', '')
            passphrase = sub_account.get('passphrase', '')
            
            try:
                # ç”ŸæˆOKExç­¾å
                request_path = '/api/v5/account/positions'
                query_string = 'instType=SWAP'
                timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
                message = timestamp + 'GET' + request_path + '?' + query_string
                mac = hmac.new(
                    secret_key.encode('utf-8'),
                    message.encode('utf-8'),
                    hashlib.sha256
                )
                signature = base64.b64encode(mac.digest()).decode('utf-8')
                
                headers = {
                    'OK-ACCESS-KEY': api_key,
                    'OK-ACCESS-SIGN': signature,
                    'OK-ACCESS-TIMESTAMP': timestamp,
                    'OK-ACCESS-PASSPHRASE': passphrase,
                    'Content-Type': 'application/json'
                }
                
                # è·å–æŒä»“
                print(f"  ğŸ” æ­£åœ¨è·å– {account_name} çš„æŒä»“...")
                response = requests.get(
                    f'{OKEX_REST_URL}{request_path}?{query_string}',
                    headers=headers,
                    timeout=10
                )
                
                result = response.json()
                print(f"  ğŸ“Š APIå“åº”: code={result.get('code')}, data_count={len(result.get('data', []))}")
                
                if result.get('code') == '0' and result.get('data'):
                    pos_count = 0
                    for pos_data in result['data']:
                        pos_size = float(pos_data.get('pos', 0) or 0)
                        if pos_size != 0:
                            inst_id = pos_data.get('instId', '')
                            pos_side = pos_data.get('posSide', '')
                            mgn_mode = pos_data.get('mgnMode', 'isolated')  # è·å–æŒä»“æ¨¡å¼
                            margin_str = pos_data.get('margin', '0')
                            mark_px_str = pos_data.get('markPx', '0')
                            
                            # å¤„ç†ç©ºå­—ç¬¦ä¸²
                            margin = float(margin_str or 0)
                            mark_price = float(mark_px_str or 0)
                            
                            all_positions.append({
                                'account_name': account_name,
                                'inst_id': inst_id,
                                'pos_side': pos_side,
                                'pos_size': pos_size,
                                'margin': margin,
                                'mark_price': mark_price,
                                'mgn_mode': mgn_mode  # ä¿å­˜æŒä»“æ¨¡å¼
                            })
                            pos_count += 1
                            print(f"    âœ… {inst_id} {pos_side}: {pos_size}å¼  (æ¨¡å¼: {mgn_mode})")
                    print(f"  ğŸ“ˆ {account_name} å…±æ‰¾åˆ° {pos_count} ä¸ªæŒä»“")
                else:
                    error_msg = result.get('msg', 'Unknown error')
                    print(f"  âŒ APIé”™è¯¯: {error_msg}")
            except Exception as e:
                print(f"  âš ï¸ è·å– {account_name} æŒä»“å¤±è´¥: {str(e)}")
                import traceback
                print(f"  Stack trace: {traceback.format_exc()}")
                continue
        
        positions = all_positions
        
        if not positions:
            return jsonify({
                'success': True,
                'message': 'æ²¡æœ‰æŒä»“éœ€è¦å¹³ä»“',
                'success_count': 0,
                'fail_count': 0,
                'results': []
            })
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(positions)} ä¸ªæŒä»“ï¼Œå¼€å§‹é€ä¸ªå¹³ä»“...")
        
        success_count = 0
        fail_count = 0
        results = []
        
        # OKEx APIç­¾åå’Œè¯·æ±‚å¤´å‡½æ•°
        def generate_signature(timestamp, method, request_path, body='', secret_key=''):
            if body:
                body = json_lib.dumps(body)
            message = timestamp + method + request_path + body
            mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(message, encoding='utf-8'), digestmod=hashlib.sha256)
            return base64.b64encode(mac.digest()).decode()
        
        def get_headers(api_key, secret_key, passphrase, timestamp, method, request_path, body=''):
            return {
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': generate_signature(timestamp, method, request_path, body, secret_key),
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
                'Content-Type': 'application/json'
            }
        
        # é€ä¸ªå¹³ä»“
        for pos in positions:
            account_name = pos.get('account_name')
            inst_id = pos.get('inst_id')
            pos_side = pos.get('pos_side')
            pos_size = abs(float(pos.get('pos_size', 0)))
            mgn_mode = pos.get('mgn_mode', 'isolated')  # è·å–æŒä»“æ¨¡å¼ï¼Œé»˜è®¤é€ä»“
            
            if pos_size == 0:
                continue
            
            print(f"\nğŸ”§ å¼€å§‹å¹³ä»“: {account_name} {inst_id} {pos_side} ({pos_size}å¼ , æ¨¡å¼:{mgn_mode})")
            
            try:
                # æŸ¥æ‰¾å¯¹åº”çš„å­è´¦æˆ·
                sub_account = None
                for acc in config_data.get('sub_accounts', []):
                    if acc['account_name'] == account_name:
                        sub_account = acc
                        break
                
                if not sub_account:
                    fail_count += 1
                    results.append({
                        'account_name': account_name,
                        'inst_id': inst_id,
                        'pos_side': pos_side,
                        'success': False,
                        'message': f'æœªæ‰¾åˆ°å­è´¦æˆ·é…ç½®'
                    })
                    continue
                
                api_key = sub_account['api_key']
                secret_key = sub_account['secret_key']
                passphrase = sub_account['passphrase']
                
                # å¤šç­–ç•¥å¹³ä»“ï¼šå°è¯•3ç§æ–¹æ³•ç¡®ä¿æˆåŠŸ
                close_success = False
                order_id = None
                error_details = []
                
                # ç­–ç•¥1: ä½¿ç”¨å¿«æ·å¹³ä»“æ¥å£ï¼ˆæœ€å¯é ï¼‰
                print(f"  ğŸ¯ ç­–ç•¥1: å¿«æ·å¹³ä»“æ¥å£ - {inst_id} {pos_side}")
                try:
                    timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
                    request_path = '/api/v5/trade/close-position'
                    
                    close_body = {
                        'instId': inst_id,
                        'mgnMode': mgn_mode,  # ä½¿ç”¨å®é™…çš„æŒä»“æ¨¡å¼
                        'posSide': pos_side,
                        'ccy': 'USDT'
                    }
                    
                    headers = get_headers(api_key, secret_key, passphrase, timestamp, 'POST', request_path, close_body)
                    
                    response = requests.post(
                        f'{OKEX_REST_URL}{request_path}',
                        headers=headers,
                        json=close_body,
                        timeout=10
                    )
                    
                    result = response.json()
                    print(f"     å“åº”: code={result.get('code')}, msg={result.get('msg', 'N/A')}")
                    
                    if result.get('code') == '0' and result.get('data'):
                        order_id = result['data'][0].get('ordId', '--')
                        close_success = True
                        print(f"     âœ… ç­–ç•¥1æˆåŠŸ")
                    else:
                        error_details.append(f"ç­–ç•¥1å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                except Exception as e:
                    error_details.append(f"ç­–ç•¥1å¼‚å¸¸: {str(e)}")
                    print(f"     âŒ ç­–ç•¥1å¼‚å¸¸: {str(e)}")
                
                # ç­–ç•¥2: æ ‡å‡†ä¸‹å•æ¥å£ + reduceOnlyï¼ˆå¦‚æœç­–ç•¥1å¤±è´¥ï¼‰
                if not close_success:
                    print(f"  ğŸ¯ ç­–ç•¥2: æ ‡å‡†ä¸‹å•æ¥å£ + reduceOnly")
                    try:
                        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
                        request_path = '/api/v5/trade/order'
                        
                        close_side = 'sell' if pos_side == 'long' else 'buy'
                        
                        order_body = {
                            'instId': inst_id,
                            'tdMode': mgn_mode,  # ä½¿ç”¨å®é™…çš„æŒä»“æ¨¡å¼
                            'side': close_side,
                            'posSide': pos_side,
                            'ordType': 'market',
                            'sz': str(int(pos_size)),
                            'reduceOnly': True  # å…³é”®å‚æ•°
                        }
                        
                        headers = get_headers(api_key, secret_key, passphrase, timestamp, 'POST', request_path, order_body)
                        
                        response = requests.post(
                            f'{OKEX_REST_URL}{request_path}',
                            headers=headers,
                            json=order_body,
                            timeout=10
                        )
                        
                        result = response.json()
                        print(f"     å“åº”: code={result.get('code')}, msg={result.get('msg', 'N/A')}")
                        
                        if result.get('code') == '0' and result.get('data'):
                            order_id = result['data'][0].get('ordId', '--')
                            close_success = True
                            print(f"     âœ… ç­–ç•¥2æˆåŠŸ")
                        else:
                            error_details.append(f"ç­–ç•¥2å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    except Exception as e:
                        error_details.append(f"ç­–ç•¥2å¼‚å¸¸: {str(e)}")
                        print(f"     âŒ ç­–ç•¥2å¼‚å¸¸: {str(e)}")
                
                # ç­–ç•¥3: ä¸å¸¦reduceOnlyçš„æ ‡å‡†ä¸‹å•ï¼ˆæœ€åçš„å°è¯•ï¼‰
                if not close_success:
                    print(f"  ğŸ¯ ç­–ç•¥3: æ ‡å‡†ä¸‹å•æ¥å£ï¼ˆæ— reduceOnlyï¼‰")
                    try:
                        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
                        request_path = '/api/v5/trade/order'
                        
                        close_side = 'sell' if pos_side == 'long' else 'buy'
                        
                        order_body = {
                            'instId': inst_id,
                            'tdMode': mgn_mode,  # ä½¿ç”¨å®é™…çš„æŒä»“æ¨¡å¼
                            'side': close_side,
                            'posSide': pos_side,
                            'ordType': 'market',
                            'sz': str(int(pos_size))
                        }
                        
                        headers = get_headers(api_key, secret_key, passphrase, timestamp, 'POST', request_path, order_body)
                        
                        response = requests.post(
                            f'{OKEX_REST_URL}{request_path}',
                            headers=headers,
                            json=order_body,
                            timeout=10
                        )
                        
                        result = response.json()
                        print(f"     å“åº”: code={result.get('code')}, msg={result.get('msg', 'N/A')}")
                        
                        if result.get('code') == '0' and result.get('data'):
                            order_id = result['data'][0].get('ordId', '--')
                            close_success = True
                            print(f"     âœ… ç­–ç•¥3æˆåŠŸ")
                        else:
                            error_details.append(f"ç­–ç•¥3å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    except Exception as e:
                        error_details.append(f"ç­–ç•¥3å¼‚å¸¸: {str(e)}")
                        print(f"     âŒ ç­–ç•¥3å¼‚å¸¸: {str(e)}")
                
                # æ±‡æ€»ç»“æœ
                if close_success:
                    print(f"  âœ… {account_name} {inst_id} {pos_side}: å¹³ä»“æˆåŠŸ (è®¢å•ID: {order_id})")
                    success_count += 1
                    results.append({
                        'account_name': account_name,
                        'inst_id': inst_id,
                        'pos_side': pos_side,
                        'success': True,
                        'order_id': order_id,
                        'size': pos_size
                    })
                else:
                    print(f"  âŒ {account_name} {inst_id} {pos_side}: æ‰€æœ‰ç­–ç•¥å‡å¤±è´¥")
                    print(f"     å¤±è´¥è¯¦æƒ…: {'; '.join(error_details)}")
                    fail_count += 1
                    results.append({
                        'account_name': account_name,
                        'inst_id': inst_id,
                        'pos_side': pos_side,
                        'success': False,
                        'message': '; '.join(error_details) if error_details else 'æ‰€æœ‰ç­–ç•¥å‡å¤±è´¥'
                    })
                
            except Exception as e:
                print(f"  âŒ {account_name} {inst_id} {pos_side}: å¹³ä»“å¼‚å¸¸ - {str(e)}")
                fail_count += 1
                results.append({
                    'account_name': account_name,
                    'inst_id': inst_id,
                    'pos_side': pos_side,
                    'success': False,
                    'message': str(e)
                })
        
        print(f"ğŸ¯ ä¸€é”®å…¨éƒ¨å¹³ä»“å®Œæˆï¼æˆåŠŸ: {success_count}ä¸ªï¼Œå¤±è´¥: {fail_count}ä¸ª")
        
        return jsonify({
            'success': True,
            'message': f'å¹³ä»“å®Œæˆ',
            'success_count': success_count,
            'fail_count': fail_count,
            'total': len(positions),
            'results': results
        })
        
    except Exception as e:
        import traceback
        print(f"âŒ ä¸€é”®å…¨éƒ¨å¹³ä»“å¤±è´¥: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            'success': False,
            'message': f'ä¸€é”®å¹³ä»“å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/close-sub-account-position', methods=['POST'])
def close_sub_account_position():
    """å­è´¦æˆ·å¹³ä»“ï¼šéƒ¨åˆ†æˆ–å…¨éƒ¨å¹³ä»“"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        from position_close_guard import validate_close_request, MIN_KEEP_MARGIN
        
        data = request.json
        account_name = data.get('account_name')
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')
        close_size = float(data.get('close_size', 0))
        reason = data.get('reason', 'æ‰‹åŠ¨å¹³ä»“')
        
        if not all([account_name, inst_id, pos_side, close_size]):
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            })
        
        # è¯»å–å­è´¦æˆ·é…ç½®
        with open('sub_account_config.json', 'r', encoding='utf-8') as f:
            config = json_lib.load(f)
        
        # æŸ¥æ‰¾å¯¹åº”çš„å­è´¦æˆ·
        sub_account = None
        for acc in config.get('sub_accounts', []):
            if acc['account_name'] == account_name:
                sub_account = acc
                break
        
        if not sub_account:
            return jsonify({
                'success': False,
                'message': f'æœªæ‰¾åˆ°å­è´¦æˆ·: {account_name}'
            })
        
        api_key = sub_account['api_key']
        secret_key = sub_account['secret_key']
        passphrase = sub_account['passphrase']
        
        # OKEx APIç­¾åå‡½æ•°
        def generate_signature(timestamp, method, request_path, body=''):
            if body:
                body = json.dumps(body)
            message = timestamp + method + request_path + body
            mac = hmac.new(
                bytes(secret_key, encoding='utf8'),
                bytes(message, encoding='utf-8'),
                digestmod=hashlib.sha256
            )
            return base64.b64encode(mac.digest()).decode()
        
        def get_headers(method, request_path, body=''):
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
            sign = generate_signature(timestamp, method, request_path, body)
            return {
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': sign,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
                'Content-Type': 'application/json'
            }
        
        # OKEx API URL
        OKEX_REST_URL = 'https://www.okx.com'
        
        # ğŸ›¡ï¸ åº•ä»“ä¿æŠ¤ï¼šè·å–å½“å‰æŒä»“ä¿¡æ¯
        positions_path = '/api/v5/account/positions'
        positions_params = f'?instType=SWAP&instId={inst_id}'
        positions_headers = get_headers('GET', positions_path + positions_params)
        positions_response = requests.get(
            OKEX_REST_URL + positions_path + positions_params,
            headers=positions_headers,
            timeout=10
        )
        positions_data = positions_response.json()
        
        if positions_data.get('code') != '0':
            return jsonify({
                'success': False,
                'message': f'è·å–æŒä»“ä¿¡æ¯å¤±è´¥: {positions_data.get("msg")}'
            })
        
        # æŸ¥æ‰¾å¯¹åº”çš„æŒä»“
        current_position = None
        for pos in positions_data.get('data', []):
            if pos['instId'] == inst_id and pos['posSide'] == pos_side:
                current_position = pos
                break
        
        if not current_position:
            return jsonify({
                'success': False,
                'message': f'æœªæ‰¾åˆ°æŒä»“: {inst_id} {pos_side}'
            })
        
        # æå–æŒä»“ä¿¡æ¯ï¼ˆå®‰å…¨è½¬æ¢ï¼Œå¤„ç†ç©ºå­—ç¬¦ä¸²ï¼‰
        pos_size = abs(float(current_position['pos']) if current_position['pos'] else 0)
        
        # å¦‚æœ markPx ä¸ºç©ºï¼Œå°è¯•ä»è¡Œæƒ…APIè·å–
        mark_price_str = current_position.get('markPx', '')
        if mark_price_str and mark_price_str.strip():
            mark_price = float(mark_price_str)
        else:
            # ä»tickerè·å–ä»·æ ¼
            ticker_path = f'/api/v5/market/ticker?instId={inst_id}'
            ticker_headers = get_headers('GET', ticker_path)
            ticker_response = requests.get(
                OKEX_REST_URL + ticker_path,
                headers=ticker_headers,
                timeout=10
            )
            ticker_data = ticker_response.json()
            if ticker_data.get('code') == '0' and ticker_data.get('data'):
                mark_price = float(ticker_data['data'][0].get('last', 0))
            else:
                return jsonify({
                    'success': False,
                    'message': 'æ— æ³•è·å–æ ‡è®°ä»·æ ¼'
                })
        
        leverage_str = current_position.get('lever', '10')
        leverage = float(leverage_str) if leverage_str and leverage_str.strip() else 10.0
        
        # ğŸ›¡ï¸ åº•ä»“ä¿æŠ¤éªŒè¯
        is_safe, adjusted_close_size, warning_msg = validate_close_request(
            pos_size, close_size, mark_price, leverage, MIN_KEEP_MARGIN
        )
        
        if not is_safe:
            print(f"âš ï¸  {warning_msg}")
            close_size = adjusted_close_size
            reason = f"{reason} (åº•ä»“ä¿æŠ¤è‡ªåŠ¨è°ƒæ•´)"
        
        # æ‰§è¡Œå¹³ä»“
        order_path = '/api/v5/trade/order'
        
        # ç¡®å®šå¹³ä»“æ–¹å‘
        close_side = 'buy' if pos_side == 'short' else 'sell'
        
        close_order_body = {
            'instId': inst_id,
            'tdMode': 'isolated',  # é€ä»“æ¨¡å¼ï¼šæ¯ä¸ªæŒä»“ç‹¬ç«‹ä¿è¯é‡‘
            'side': close_side,
            'posSide': pos_side,
            'ordType': 'market',
            'sz': str(int(close_size))
        }
        
        print(f"ğŸ¯ å­è´¦æˆ·å¹³ä»“: {account_name} {inst_id} {pos_side} {close_size}")
        print(f"   åŸå› : {reason}")
        
        headers = get_headers('POST', order_path, close_order_body)
        close_response = requests.post(
            OKEX_REST_URL + order_path,
            headers=headers,
            json=close_order_body,
            timeout=10
        )
        close_data = close_response.json()
        
        if close_data.get('code') != '0':
            return jsonify({
                'success': False,
                'message': f'å¹³ä»“å¤±è´¥: {close_data.get("msg")}',
                'error_code': close_data.get('code')
            })
        
        order_id = close_data['data'][0]['ordId']
        print(f"âœ… å¹³ä»“è®¢å•æäº¤æˆåŠŸ: {order_id}")
        
        return jsonify({
            'success': True,
            'message': 'å¹³ä»“æˆåŠŸ',
            'order_id': order_id,
            'close_size': int(close_size),
            'reason': reason
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'å¹³ä»“å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor/open-sub-account-position', methods=['POST'])
def open_sub_account_position():
    """å­è´¦æˆ·å¼€ä»“ï¼šæŒ‰æŒ‡å®šé‡‘é¢å¼€ä»“"""
    try:
        import requests
        import hmac
        import base64
        import hashlib
        import json as json_lib
        from datetime import datetime, timezone
        import pytz
        import os
        import math
        import time
        
        data = request.json
        account_name = data.get('account_name')
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')  # 'long' or 'short'
        amount = float(data.get('amount', 10))  # é»˜è®¤10U
        
        if not all([account_name, inst_id, pos_side]):
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            })
        
        # è¯»å–å­è´¦æˆ·é…ç½®
        with open('sub_account_config.json', 'r', encoding='utf-8') as f:
            config = json_lib.load(f)
        
        # æŸ¥æ‰¾å¯¹åº”çš„å­è´¦æˆ·
        sub_account = None
        for acc in config.get('sub_accounts', []):
            if acc['account_name'] == account_name:
                sub_account = acc
                break
        
        if not sub_account:
            return jsonify({
                'success': False,
                'message': f'æœªæ‰¾åˆ°å­è´¦æˆ·: {account_name}'
            })
        
        api_key = sub_account['api_key']
        secret_key = sub_account['secret_key']
        passphrase = sub_account['passphrase']
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ å­è´¦æˆ·å¼€ä»“")
        print(f"è´¦æˆ·: {account_name}")
        print(f"å¸ç§: {inst_id}")
        print(f"æ–¹å‘: {pos_side}")
        print(f"é‡‘é¢: {amount} USDT")
        print(f"{'='*80}\n")
        
        # 1. è·å–å½“å‰æ ‡è®°ä»·æ ¼
        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        request_path = f'/api/v5/public/mark-price?instType=SWAP&instId={inst_id}'
        message = timestamp + 'GET' + request_path
        mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(message, encoding='utf-8'), digestmod=hashlib.sha256)
        signature = base64.b64encode(mac.digest()).decode()
        
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        mark_price_url = f'https://www.okx.com{request_path}'
        mark_response = requests.get(mark_price_url, headers=headers, timeout=10)
        mark_result = mark_response.json()
        
        if mark_result['code'] != '0' or not mark_result['data']:
            return jsonify({
                'success': False,
                'message': f'è·å–æ ‡è®°ä»·æ ¼å¤±è´¥: {mark_result.get("msg")}'
            })
        
        mark_price = float(mark_result['data'][0]['markPx'])
        print(f"ğŸ“Š å½“å‰æ ‡è®°ä»·æ ¼: {mark_price}")
        
        # 2. è·å–åˆçº¦ä¿¡æ¯ï¼ˆå¼ æ•°å’Œé¢å€¼ï¼‰
        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        request_path = f'/api/v5/public/instruments?instType=SWAP&instId={inst_id}'
        message = timestamp + 'GET' + request_path
        mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(message, encoding='utf-8'), digestmod=hashlib.sha256)
        signature = base64.b64encode(mac.digest()).decode()
        
        headers['OK-ACCESS-SIGN'] = signature
        headers['OK-ACCESS-TIMESTAMP'] = timestamp
        
        instruments_url = f'https://www.okx.com{request_path}'
        instruments_response = requests.get(instruments_url, headers=headers, timeout=10)
        instruments_result = instruments_response.json()
        
        if instruments_result['code'] != '0' or not instruments_result['data']:
            return jsonify({
                'success': False,
                'message': f'è·å–åˆçº¦ä¿¡æ¯å¤±è´¥: {instruments_result.get("msg")}'
            })
        
        ct_val = float(instruments_result['data'][0]['ctVal'])
        lot_sz = float(instruments_result['data'][0]['lotSz'])
        print(f"ğŸ“Š åˆçº¦é¢å€¼: {ct_val}, æœ€å°å¼ æ•°: {lot_sz}")
        
        # 3. è®¡ç®—å¼€ä»“å¼ æ•°ï¼ˆ10å€æ æ†ï¼‰
        leverage = 10
        # amount USDT * æ æ† / æ ‡è®°ä»·æ ¼ = å¯å¼€å¼ æ•°
        raw_size = (amount * leverage) / (mark_price * ct_val)
        # å‘ä¸‹å–æ•´åˆ°æœ€å°å¼ æ•°çš„å€æ•°
        open_size = math.floor(raw_size / lot_sz) * lot_sz
        
        if open_size < lot_sz:
            return jsonify({
                'success': False,
                'message': f'å¼€ä»“é‡‘é¢å¤ªå°ï¼Œæ— æ³•å¼€ä»“ï¼ˆæœ€å°‘éœ€è¦ {lot_sz} å¼ ï¼‰'
            })
        
        print(f"ğŸ“Š è®¡ç®—å¼€ä»“å¼ æ•°: {open_size}")
        
        # 4. è®¾ç½®æ æ†
        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        request_path = '/api/v5/account/set-leverage'
        body = json_lib.dumps({
            'instId': inst_id,
            'lever': str(leverage),
            'mgnMode': 'isolated',
            'posSide': pos_side if pos_side in ['long', 'short'] else 'net'
        })
        message = timestamp + 'POST' + request_path + body
        mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(message, encoding='utf-8'), digestmod=hashlib.sha256)
        signature = base64.b64encode(mac.digest()).decode()
        
        headers['OK-ACCESS-SIGN'] = signature
        headers['OK-ACCESS-TIMESTAMP'] = timestamp
        
        leverage_url = f'https://www.okx.com{request_path}'
        leverage_response = requests.post(leverage_url, headers=headers, data=body, timeout=10)
        leverage_result = leverage_response.json()
        print(f"ğŸ“Š è®¾ç½®æ æ†ç»“æœ: {leverage_result}")
        
        # 5. æäº¤å¼€ä»“è®¢å•
        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        request_path = '/api/v5/trade/order'
        
        # åˆ¤æ–­è®¢å•æ–¹å‘
        if pos_side == 'long':
            side = 'buy'
        elif pos_side == 'short':
            side = 'sell'
        else:
            side = 'buy'  # é»˜è®¤ä¹°å…¥
        
        body = json_lib.dumps({
            'instId': inst_id,
            'tdMode': 'isolated',  # é€ä»“æ¨¡å¼ï¼šæ¯ä¸ªæŒä»“ç‹¬ç«‹ä¿è¯é‡‘
            'side': side,
            'ordType': 'market',
            'sz': str(int(open_size)),
            'posSide': pos_side if pos_side in ['long', 'short'] else 'net'
        })
        
        message = timestamp + 'POST' + request_path + body
        mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(message, encoding='utf-8'), digestmod=hashlib.sha256)
        signature = base64.b64encode(mac.digest()).decode()
        
        headers['OK-ACCESS-SIGN'] = signature
        headers['OK-ACCESS-TIMESTAMP'] = timestamp
        
        order_url = f'https://www.okx.com{request_path}'
        order_response = requests.post(order_url, headers=headers, data=body, timeout=10)
        order_result = order_response.json()
        
        print(f"ğŸ“Š å¼€ä»“è®¢å•ç»“æœ: {order_result}")
        
        if order_result['code'] != '0':
            return jsonify({
                'success': False,
                'message': f'å¼€ä»“å¤±è´¥: {order_result.get("msg", "æœªçŸ¥é”™è¯¯")}'
            })
        
        order_id = order_result['data'][0]['ordId']
        print(f"âœ… å¼€ä»“è®¢å•ID: {order_id}")
        
        # 6. ä¿å­˜å¼€ä»“è®°å½•
        opened_positions = {}
        try:
            if os.path.exists('sub_account_opened_positions.json'):
                with open('sub_account_opened_positions.json', 'r', encoding='utf-8') as f:
                    opened_positions = json_lib.load(f)
        except:
            pass
        
        position_key = f"{account_name}_{inst_id}_{pos_side}"
        opened_positions[position_key] = {
            'account_name': account_name,
            'inst_id': inst_id,
            'pos_side': pos_side,
            'order_id': order_id,
            'open_size': open_size,
            'open_price': mark_price,
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        with open('sub_account_opened_positions.json', 'w', encoding='utf-8') as f:
            json_lib.dump(opened_positions, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': 'å¼€ä»“æˆåŠŸ',
            'data': {
                'account_name': account_name,
                'inst_id': inst_id,
                'pos_side': pos_side,
                'order_id': order_id,
                'open_size': open_size,
                'open_price': mark_price,
                'amount': amount
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'å¼€ä»“å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/sub-account/reset-maintenance-count', methods=['POST'])
def reset_sub_account_maintenance_count():
    """æ¸…é›¶å­è´¦æˆ·ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°"""
    try:
        import json as json_lib
        from datetime import datetime
        import pytz
        
        data = request.json
        account_name = data.get('account_name')
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')
        
        if not all([account_name, inst_id, pos_side]):
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            })
        
        # è¯»å–ç»´æŠ¤è®°å½•æ–‡ä»¶
        maintenance_file = 'sub_account_maintenance.json'
        try:
            with open(maintenance_file, 'r', encoding='utf-8') as f:
                maintenance_data = json.load(f)
        except FileNotFoundError:
            maintenance_data = {}
        
        # æ„å»ºè®°å½•é”®
        record_key = f"{account_name}_{inst_id}_{pos_side}"
        
        # è·å–å½“å‰åŒ—äº¬æ—¶é—´çš„æ—¥æœŸ
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now_beijing = datetime.now(beijing_tz)
        today_date = now_beijing.strftime('%Y-%m-%d')
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»Šæ—¥è®°å½•
        if record_key not in maintenance_data:
            return jsonify({
                'success': False,
                'message': 'è¯¥æŒä»“æ²¡æœ‰ç»´æŠ¤è®°å½•'
            })
        
        record = maintenance_data[record_key]
        
        # æ¸…é›¶ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°
        old_count = record.get('count', 0)
        
        # é‡ç½®è®°å½•
        record['count'] = 0
        record['date'] = today_date
        record['last_reset'] = now_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(maintenance_file, 'w', encoding='utf-8') as f:
            json.dump(maintenance_data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'message': f'æ¸…é›¶æˆåŠŸï¼åŸç»´æŠ¤æ¬¡æ•°: {old_count}æ¬¡',
            'account_name': account_name,
            'inst_id': inst_id,
            'pos_side': pos_side,
            'old_count': old_count,
            'new_count': 0,
            'reset_time': now_beijing.strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ¸…é›¶å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/main-account/reset-maintenance-count', methods=['POST'])
def reset_main_account_maintenance_count():
    """æ¸…é›¶ä¸»è´¦æˆ·ä»Šæ—¥è¶…çº§ç»´æŠ¤æ¬¡æ•°"""
    try:
        import json as json_lib
        from datetime import datetime
        
        data = request.json
        inst_id = data.get('inst_id')
        pos_side = data.get('pos_side')
        
        if not all([inst_id, pos_side]):
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
            })
        
        # è¯»å–ç»´æŠ¤è®°å½•æ–‡ä»¶
        maintenance_file = 'main_account_maintenance.json'
        try:
            with open(maintenance_file, 'r', encoding='utf-8') as f:
                maintenance_data = json.load(f)
        except FileNotFoundError:
            maintenance_data = {}
        
        # æ„å»ºè®°å½•é”®
        record_key = f"{inst_id}_{pos_side}"
        
        # è·å–å½“å‰æ—¥æœŸ
        today_date = datetime.now().strftime('%Y-%m-%d')
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»Šæ—¥è®°å½•
        if record_key not in maintenance_data:
            return jsonify({
                'success': False,
                'message': 'è¯¥æŒä»“æ²¡æœ‰ç»´æŠ¤è®°å½•'
            })
        
        record = maintenance_data[record_key]
        
        # æ¸…é›¶ä»Šæ—¥ç»´æŠ¤æ¬¡æ•°
        old_count = record.get('count', 0)
        
        # é‡ç½®è®°å½•
        record['count'] = 0
        record['date'] = today_date
        record['last_reset'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(maintenance_file, 'w', encoding='utf-8') as f:
            json.dump(maintenance_data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'message': f'æ¸…é›¶æˆåŠŸï¼åŸè¶…çº§ç»´æŠ¤æ¬¡æ•°: {old_count}æ¬¡',
            'inst_id': inst_id,
            'pos_side': pos_side,
            'old_count': old_count,
            'new_count': 0,
            'reset_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'æ¸…é›¶å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/sub-account/take-profit-records', methods=['GET'])
def get_sub_account_take_profit_records():
    """è·å–å­è´¦æˆ·æ­¢ç›ˆè®°å½•"""
    try:
        import json as json_lib
        from datetime import datetime, timedelta
        
        # è·å–æŸ¥è¯¢å‚æ•°
        account_name = request.args.get('account_name')
        days = int(request.args.get('days', 7))  # é»˜è®¤æŸ¥è¯¢æœ€è¿‘7å¤©
        
        # è¯»å–æ­¢ç›ˆè®°å½•æ–‡ä»¶
        records_file = 'sub_account_take_profit_records.json'
        try:
            with open(records_file, 'r', encoding='utf-8') as f:
                all_records = json_lib.load(f)
        except FileNotFoundError:
            all_records = []
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # è¿‡æ»¤è®°å½•
        filtered_records = []
        total_profit = 0
        total_closed_amount = 0
        
        for record in all_records:
            # æŒ‰è´¦æˆ·åè¿‡æ»¤
            if account_name and record.get('account_name') != account_name:
                continue
            
            # æŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤
            record_time = datetime.strptime(record['timestamp'], '%Y-%m-%d %H:%M:%S')
            if record_time < start_date or record_time > end_date:
                continue
            
            filtered_records.append(record)
            
            # ç»Ÿè®¡æ•°æ®
            if 'estimated_profit' in record:
                total_profit += record['estimated_profit']
            if 'close_amount' in record:
                total_closed_amount += record['close_amount']
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        filtered_records.sort(key=lambda x: x['timestamp'], reverse=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_records': len(filtered_records),
            'total_profit': round(total_profit, 2),
            'total_closed_amount': round(total_closed_amount, 2),
            'avg_profit_per_trade': round(total_profit / len(filtered_records), 2) if len(filtered_records) > 0 else 0,
            'rule1_count': len([r for r in filtered_records if r.get('rule') == 'rule1']),
            'rule2_count': len([r for r in filtered_records if r.get('rule') == 'rule2']),
            'date_range': {
                'start': start_date.strftime('%Y-%m-%d'),
                'end': end_date.strftime('%Y-%m-%d')
            }
        }
        
        return jsonify({
            'success': True,
            'records': filtered_records,
            'stats': stats
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–è®°å½•å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

# æµ‹è¯•é¡µé¢è·¯ç”±
@app.route('/api/anchor/decline-strength', methods=['GET'])
def get_decline_strength():
    """
    è·å–ä¸‹è·Œå¼ºåº¦åˆ†ç±»
    æ ¹æ®ç©ºå•ç›ˆåˆ©æƒ…å†µåˆ¤æ–­å¸‚åœºä¸‹è·Œå¼ºåº¦
    """
    try:
        import sys
        sys.path.append('/home/user/webapp')
        from anchor_system import get_positions_from_okex
        
        # è·å–å®ç›˜æŒä»“
        raw_positions = get_positions_from_okex()
        
        # ç»Ÿè®¡ç©ºå•ç›ˆåˆ©æƒ…å†µ
        short_profits = []
        for pos in raw_positions:
            if pos.get('posSide') == 'short':  # OKEx API ä½¿ç”¨ posSide
                profit_rate = float(pos.get('uplRatio', 0)) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                short_profits.append({
                    'inst_id': pos.get('instId'),
                    'profit_rate': profit_rate,
                    'margin': float(pos.get('margin', 0)),
                    'upl': float(pos.get('upl', 0))
                })
        
        # è®¡ç®—å„ç›ˆåˆ©åŒºé—´çš„ç©ºå•æ•°é‡ï¼ˆæ–°å¢100%ã€90%ã€80%ç»Ÿè®¡ï¼‰
        count_100 = len([p for p in short_profits if p['profit_rate'] >= 100])
        count_90 = len([p for p in short_profits if p['profit_rate'] >= 90])
        count_80 = len([p for p in short_profits if p['profit_rate'] >= 80])
        count_70 = len([p for p in short_profits if p['profit_rate'] >= 70])
        count_60 = len([p for p in short_profits if p['profit_rate'] >= 60])
        count_50 = len([p for p in short_profits if p['profit_rate'] >= 50])
        count_40 = len([p for p in short_profits if p['profit_rate'] >= 40])
        
        # åˆ¤æ–­ä¸‹è·Œç­‰çº§ï¼ˆæ–°çš„5çº§è§„åˆ™ï¼‰
        strength_level = 0
        strength_name = ''
        buy_suggestion = ''
        color_class = ''
        
        # æ²¡æœ‰ç©ºå•çš„æƒ…å†µ
        if len(short_profits) == 0:
            strength_level = 0
            strength_name = 'å¸‚åœºæ­£å¸¸'
            buy_suggestion = 'æš‚æ— æ˜æ˜¾ä¸‹è·Œä¿¡å·'
            color_class = 'strength-0'
        # ä¸‹è·Œç­‰çº§5ï¼šæç«¯ä¸‹è·Œ
        elif count_100 >= 1:
            strength_level = 5
            strength_name = 'ä¸‹è·Œç­‰çº§5 - æç«¯ä¸‹è·Œ'
            buy_suggestion = 'äº¤æ˜“å¯¹çš„ç©ºä»“ç›ˆåˆ©è¦å¤§äº100%'
            color_class = 'strength-5'
        # ä¸‹è·Œç­‰çº§4ï¼šè¶…é«˜å¼ºåº¦ä¸‹è·Œ
        elif count_100 == 0 and count_90 >= 1 and count_80 >= 1:
            strength_level = 4
            strength_name = 'ä¸‹è·Œç­‰çº§4 - è¶…é«˜å¼ºåº¦ä¸‹è·Œ'
            buy_suggestion = 'äº¤æ˜“å¯¹çš„ç©ºä»“ç›ˆåˆ©è¦å¤§äº90%'
            color_class = 'strength-4'
        # ä¸‹è·Œç­‰çº§3ï¼šé«˜å¼ºåº¦ä¸‹è·Œ
        elif count_100 == 0 and count_90 == 0 and count_80 == 0 and count_70 >= 1 and count_60 >= 2:
            strength_level = 3
            strength_name = 'ä¸‹è·Œç­‰çº§3 - é«˜å¼ºåº¦ä¸‹è·Œ'
            buy_suggestion = 'äº¤æ˜“å¯¹çš„ç©ºä»“ç›ˆåˆ©è¦å¤§äº70%'
            color_class = 'strength-3'
        # ä¸‹è·Œç­‰çº§2ï¼šä¸­ç­‰å¼ºåº¦ä¸‹è·Œ
        elif count_100 == 0 and count_90 == 0 and count_80 == 0 and count_70 == 0 and count_60 >= 2:
            strength_level = 2
            strength_name = 'ä¸‹è·Œç­‰çº§2 - ä¸­ç­‰å¼ºåº¦ä¸‹è·Œ'
            buy_suggestion = 'äº¤æ˜“å¯¹çš„ç©ºä»“ç›ˆåˆ©è¦å¤§äº60%'
            color_class = 'strength-2'
        # ä¸‹è·Œç­‰çº§1ï¼šè½»å¾®ä¸‹è·Œ
        elif count_100 == 0 and count_90 == 0 and count_80 == 0 and count_70 == 0 and count_60 == 0 and count_50 == 0 and count_40 >= 3:
            strength_level = 1
            strength_name = 'ä¸‹è·Œç­‰çº§1 - è½»å¾®ä¸‹è·Œ'
            buy_suggestion = 'äº¤æ˜“å¯¹çš„ç©ºä»“ç›ˆåˆ©è¦å¤§äº40%'
            color_class = 'strength-1'
        # ä¸æ»¡è¶³ä»»ä½•æ¡ä»¶
        else:
            strength_level = 0
            strength_name = 'å¸‚åœºæ­£å¸¸'
            buy_suggestion = 'æš‚æ— æ˜æ˜¾ä¸‹è·Œä¿¡å·'
            color_class = 'strength-0'
        
        return jsonify({
            'success': True,
            'data': {
                'strength_level': strength_level,
                'strength_name': strength_name,
                'buy_suggestion': buy_suggestion,
                'color_class': color_class,
                'statistics': {
                    'total_shorts': len(short_profits),
                    'profit_100': count_100,
                    'profit_90': count_90,
                    'profit_80': count_80,
                    'profit_70': count_70,
                    'profit_60': count_60,
                    'profit_50': count_50,
                    'profit_40': count_40
                },
                'short_positions': short_profits
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–ä¸‹è·Œå¼ºåº¦å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/test-positions')
def test_positions_page():
    """æŒä»“æ•°æ®æµ‹è¯•é¡µé¢"""
    return render_template('test_positions.html')

@app.route('/sub-account-trades')
def sub_account_trades_page():
    """å­è´¦æˆ·äº¤æ˜“è¯¦æƒ…é¡µé¢"""
    return render_template('sub_account_trades.html')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
