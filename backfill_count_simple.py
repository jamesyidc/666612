import os
import re
import sqlite3
from datetime import datetime
import asyncio
from gdrive_home_data_reader import get_latest_file_by_sorting

def extract_count_times(content):
    """ä»å†…å®¹ä¸­æå–è®¡æ¬¡"""
    # æŸ¥æ‰¾ é€æ˜æ ‡ç­¾_è®¡æ¬¡=2
    match = re.search(r'é€æ˜æ ‡ç­¾_è®¡æ¬¡=(\d+)', content)
    if match:
        return int(match.group(1))
    return None

async def backfill_from_gdrive():
    """ä»Google Driveè·å–æ–‡ä»¶å¹¶å›å¡«"""
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect('crypto_data.db')
    cursor = conn.cursor()
    
    # è·å–æ‰€æœ‰è®¡æ¬¡ä¸ºNULLçš„è®°å½•
    cursor.execute("""
        SELECT id, filename, record_time 
        FROM stats_history 
        WHERE count_times IS NULL
        ORDER BY record_time DESC
        LIMIT 50
    """)
    
    records = cursor.fetchall()
    print(f"\nğŸ“Š æ‰¾åˆ° {len(records)} æ¡éœ€è¦å›å¡«è®¡æ¬¡æ•°æ®çš„è®°å½•ï¼ˆæœ€å¤šå¤„ç†50æ¡ï¼‰")
    
    if not records:
        print("âœ… æ²¡æœ‰éœ€è¦å›å¡«çš„è®°å½•")
        conn.close()
        return
    
    # å¯¼å…¥PyDrive
    try:
        from pydrive.auth import GoogleAuth
        from pydrive.drive import GoogleDrive
        
        gauth = GoogleAuth()
        gauth.LoadCredentialsFile("credentials.json")
        if gauth.credentials is None:
            print("âŒ Google Driveè®¤è¯å¤±è´¥")
            return
        elif gauth.access_token_expired:
            gauth.Refresh()
        else:
            gauth.Authorize()
        
        drive = GoogleDrive(gauth)
        
        # è·å–2025-12-03æ–‡ä»¶å¤¹
        root_folder_id = "1j8YV6KysUCmgcmASFOxztWWIE1Vq-kYV"
        file_list = drive.ListFile({'q': f"'{root_folder_id}' in parents and trashed=false"}).GetList()
        
        date_folder = None
        for f in file_list:
            if f['title'] == '2025-12-03':
                date_folder = f
                break
        
        if not date_folder:
            print("âŒ æœªæ‰¾åˆ°2025-12-03æ–‡ä»¶å¤¹")
            return
        
        # è·å–æ—¥æœŸæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        files = drive.ListFile({'q': f"'{date_folder['id']}' in parents and trashed=false"}).GetList()
        print(f"ğŸ“‚ ä»Google Driveè·å–åˆ° {len(files)} ä¸ªæ–‡ä»¶")
        
        # åˆ›å»ºæ–‡ä»¶ååˆ°æ–‡ä»¶å¯¹è±¡çš„æ˜ å°„
        file_map = {f['title']: f for f in files}
        
        updated = 0
        not_found = 0
        
        for record_id, filename, record_time in records:
            if filename in file_map:
                file_obj = file_map[filename]
                
                # è·å–æ–‡ä»¶å†…å®¹
                content = file_obj.GetContentString()
                
                # æå–è®¡æ¬¡
                count_times = extract_count_times(content)
                
                if count_times is not None:
                    # æ›´æ–°æ•°æ®åº“
                    cursor.execute("""
                        UPDATE stats_history 
                        SET count_times = ? 
                        WHERE id = ?
                    """, (count_times, record_id))
                    
                    updated += 1
                    print(f"âœ… {record_time}: æ›´æ–°è®¡æ¬¡ = {count_times}")
                else:
                    print(f"âš ï¸  {record_time}: æ–‡ä»¶ä¸­æœªæ‰¾åˆ°è®¡æ¬¡æ•°æ®")
            else:
                not_found += 1
                print(f"âŒ {record_time}: æ–‡ä»¶ {filename} æœªæ‰¾åˆ°")
        
        conn.commit()
        print(f"\nâœ… æˆåŠŸæ›´æ–° {updated} æ¡è®°å½•")
        print(f"âš ï¸  {not_found} æ¡è®°å½•çš„æ–‡ä»¶æœªæ‰¾åˆ°")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn.close()

if __name__ == '__main__':
    asyncio.run(backfill_from_gdrive())
