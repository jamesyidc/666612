#!/usr/bin/env python3
"""
æ‰¹é‡å¯¼å…¥Google Driveå†å²TXTæ–‡ä»¶åˆ°æ•°æ®åº“
ç”¨äºè¡¥å……ç¼ºå¤±çš„å†å²æ•°æ®
"""
import requests
import re
import sqlite3
from datetime import datetime
import pytz
import json
import sys

# ä»gdrive_final_detectorå¯¼å…¥å¿…è¦å‡½æ•°
from calculate_count_score import calculate_count_score

# é…ç½®
DB_PATH = "/home/user/webapp/crypto_data.db"
CONFIG_FILE = "/home/user/webapp/daily_folder_config.json"
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

def log(msg):
    """æ‰“å°æ—¥å¿—"""
    timestamp = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {msg}", flush=True)

def get_folder_id_for_date(date_str):
    """è·å–æŒ‡å®šæ—¥æœŸçš„æ–‡ä»¶å¤¹ID"""
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            # æ£€æŸ¥é…ç½®ä¸­çš„æ—¥æœŸæ˜¯å¦åŒ¹é…
            if config.get('current_date') == date_str:
                return config.get('folder_id')
            # å¦‚æœä¸åŒ¹é…ï¼Œè¿”å›None
            return None
    except Exception as e:
        log(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

def list_txt_files_in_folder(folder_id):
    """åˆ—å‡ºæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰TXTæ–‡ä»¶"""
    try:
        url = f"https://drive.google.com/drive/folders/{folder_id}"
        response = requests.get(url, timeout=10)
        
        if response.status_code != 200:
            return []
        
        # æå–æ–‡ä»¶IDå’Œåç§°
        pattern = r'\["([\w-]+)","([^"]+\.txt)"'
        matches = re.findall(pattern, response.text)
        
        files = []
        for file_id, filename in matches:
            if filename.endswith('.txt') and '2025-12-' in filename:
                files.append({'id': file_id, 'name': filename})
        
        return sorted(files, key=lambda x: x['name'])
    
    except Exception as e:
        log(f"âŒ åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        return []

def download_file_content(file_id):
    """ä¸‹è½½æ–‡ä»¶å†…å®¹"""
    try:
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            return response.text
        else:
            return None
    
    except Exception as e:
        log(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
        return None

def parse_content(content, file_timestamp=None):
    """è§£æTXTæ–‡ä»¶å†…å®¹"""
    try:
        data = {}
        
        # æå–å¿«ç…§æ—¶é—´
        time_match = re.search(r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})', content)
        if time_match:
            data['snapshot_time'] = time_match.group(1)
        elif file_timestamp:
            data['snapshot_time'] = file_timestamp
        else:
            return None
        
        # æå–æ—¥æœŸ
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', data['snapshot_time'])
        if date_match:
            data['snapshot_date'] = date_match.group(1)
        else:
            return None
        
        # æå–æ€¥æ¶¨æ€¥è·Œæ•°æ®
        rush_up_match = re.search(r'æœ¬è½®æ€¥æ¶¨æ•°é‡[:ï¼š]\s*(\d+)', content)
        rush_down_match = re.search(r'æœ¬è½®æ€¥è·Œæ•°é‡[:ï¼š]\s*(\d+)', content)
        
        data['rush_up'] = int(rush_up_match.group(1)) if rush_up_match else 0
        data['rush_down'] = int(rush_down_match.group(1)) if rush_down_match else 0
        data['diff'] = data['rush_up'] - data['rush_down']
        
        # æå–è®¡æ¬¡
        count_match = re.search(r'æœ¬è½®è®¡æ¬¡[:ï¼š]\s*(\d+)', content)
        data['count'] = int(count_match.group(1)) if count_match else 0
        
        # è®¡ç®—è®¡æ¬¡å¾—åˆ†
        score_result = calculate_count_score(data['count'])
        data['count_score_display'] = score_result['display']
        data['count_score_type'] = score_result['type']
        
        # æå–çŠ¶æ€
        status_match = re.search(r'æœ¬è½®çŠ¶æ€[:ï¼š]\s*([^\n]+)', content)
        data['status'] = status_match.group(1).strip() if status_match else 'éœ‡è¡æ— åº'
        
        return data
    
    except Exception as e:
        log(f"âŒ è§£æå†…å®¹å¤±è´¥: {e}")
        return None

def parse_coin_data(content):
    """è§£æå¸ç§æ•°æ®"""
    try:
        coins = []
        
        # æŸ¥æ‰¾è¡¨æ ¼æ•°æ®
        lines = content.split('\n')
        in_table = False
        index_order = 1
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œå’Œåˆ†éš”çº¿
            if not line or line.startswith('---') or line.startswith('==='):
                continue
            
            # æ£€æµ‹è¡¨æ ¼å¼€å§‹
            if '|' in line and ('å¸ç§' in line or 'symbol' in line.lower()):
                in_table = True
                continue
            
            # è§£æè¡¨æ ¼è¡Œ
            if in_table and '|' in line:
                parts = [p.strip() for p in line.split('|')]
                parts = [p for p in parts if p]  # ç§»é™¤ç©ºå­—ç¬¦ä¸²
                
                if len(parts) >= 4:
                    try:
                        symbol = parts[0]
                        change = float(parts[1].replace('%', '').strip())
                        rush_up = int(parts[2]) if parts[2].isdigit() else 0
                        rush_down = int(parts[3]) if parts[3].isdigit() else 0
                        
                        # æ„å»ºå¸ç§æ•°æ®
                        coin = {
                            'symbol': symbol,
                            'index_order': index_order,
                            'change': change,
                            'rush_up': rush_up,
                            'rush_down': rush_down,
                            'update_time': '',
                            'high_price': 0.0,
                            'high_time': '',
                            'decline': 0.0,
                            'change_24h': 0.0,
                            'rank': 0,
                            'current_price': 0.0,
                            'ratio1': 0.0,
                            'ratio2': 0.0,
                            'priority_level': 0
                        }
                        
                        coins.append(coin)
                        index_order += 1
                    
                    except (ValueError, IndexError):
                        continue
        
        return coins
    
    except Exception as e:
        log(f"âŒ è§£æå¸ç§æ•°æ®å¤±è´¥: {e}")
        return []

def check_exists(cursor, snapshot_time):
    """æ£€æŸ¥æ•°æ®æ˜¯å¦å·²å­˜åœ¨"""
    cursor.execute("""
        SELECT COUNT(*) FROM crypto_snapshots 
        WHERE snapshot_time = ?
    """, (snapshot_time,))
    return cursor.fetchone()[0] > 0

def import_file_to_database(file_info, folder_id):
    """å¯¼å…¥å•ä¸ªæ–‡ä»¶åˆ°æ•°æ®åº“"""
    try:
        # ä¸‹è½½æ–‡ä»¶å†…å®¹
        content = download_file_content(file_info['id'])
        if not content:
            log(f"   âŒ æ— æ³•ä¸‹è½½æ–‡ä»¶: {file_info['name']}")
            return False
        
        # è§£ææ–‡ä»¶å†…å®¹
        data = parse_content(content)
        if not data:
            log(f"   âŒ æ— æ³•è§£ææ–‡ä»¶: {file_info['name']}")
            return False
        
        # è¿æ¥æ•°æ®åº“
        conn = sqlite3.connect(DB_PATH, timeout=30)
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if check_exists(cursor, data['snapshot_time']):
            log(f"   â„¹ï¸  æ•°æ®å·²å­˜åœ¨: {data['snapshot_time']}")
            conn.close()
            return False
        
        # æ’å…¥å¿«ç…§æ•°æ®
        cursor.execute("""
            INSERT INTO crypto_snapshots 
            (snapshot_time, snapshot_date, rush_up, rush_down, diff, count, status, 
             count_score_display, count_score_type, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+8 hours'))
        """, (
            data['snapshot_time'],
            data['snapshot_date'],
            data['rush_up'],
            data['rush_down'],
            data['diff'],
            data['count'],
            data['status'],
            data['count_score_display'],
            data['count_score_type']
        ))
        
        snapshot_id = cursor.lastrowid
        
        # è§£æå¹¶æ’å…¥å¸ç§æ•°æ®
        coins = parse_coin_data(content)
        for coin in coins:
            cursor.execute("""
                INSERT INTO crypto_coin_data 
                (snapshot_id, snapshot_time, symbol, index_order, change, rush_up, rush_down, 
                 update_time, high_price, high_time, decline, change_24h, rank, current_price, 
                 ratio1, ratio2, priority_level, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+8 hours'))
            """, (
                snapshot_id,
                data['snapshot_time'],
                coin['symbol'],
                coin['index_order'],
                coin['change'],
                coin['rush_up'],
                coin['rush_down'],
                coin['update_time'],
                coin['high_price'],
                coin['high_time'],
                coin['decline'],
                coin['change_24h'],
                coin['rank'],
                coin['current_price'],
                coin['ratio1'],
                coin['ratio2'],
                coin['priority_level']
            ))
        
        conn.commit()
        conn.close()
        
        log(f"   âœ… æˆåŠŸå¯¼å…¥: {data['snapshot_time']} ({len(coins)} ä¸ªå¸ç§)")
        return True
    
    except Exception as e:
        log(f"   âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def batch_import_date(date_str):
    """æ‰¹é‡å¯¼å…¥æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æ–‡ä»¶"""
    log(f"\n{'='*80}")
    log(f"ğŸ“… å¼€å§‹å¤„ç†æ—¥æœŸ: {date_str}")
    log(f"{'='*80}")
    
    # è·å–æ–‡ä»¶å¤¹ID
    folder_id = get_folder_id_for_date(date_str)
    if not folder_id:
        log(f"âŒ æœªæ‰¾åˆ°æ—¥æœŸ {date_str} çš„æ–‡ä»¶å¤¹é…ç½®")
        return 0
    
    log(f"ğŸ“‚ æ–‡ä»¶å¤¹ID: {folder_id}")
    
    # åˆ—å‡ºæ‰€æœ‰TXTæ–‡ä»¶
    files = list_txt_files_in_folder(folder_id)
    if not files:
        log(f"âŒ æœªæ‰¾åˆ°ä»»ä½•TXTæ–‡ä»¶")
        return 0
    
    log(f"ğŸ“„ æ‰¾åˆ° {len(files)} ä¸ªTXTæ–‡ä»¶")
    
    # é€ä¸ªå¯¼å…¥
    success_count = 0
    for i, file_info in enumerate(files, 1):
        log(f"\n[{i}/{len(files)}] å¤„ç†æ–‡ä»¶: {file_info['name']}")
        if import_file_to_database(file_info, folder_id):
            success_count += 1
    
    log(f"\n{'='*80}")
    log(f"âœ… å®Œæˆ! æˆåŠŸå¯¼å…¥ {success_count}/{len(files)} ä¸ªæ–‡ä»¶")
    log(f"{'='*80}\n")
    
    return success_count

if __name__ == "__main__":
    log("ğŸš€ æ‰¹é‡å¯¼å…¥å·¥å…·å¯åŠ¨")
    log("="*80)
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2:
        log("ç”¨æ³•: python3 batch_import_gdrive_files.py <æ—¥æœŸ>")
        log("ç¤ºä¾‹: python3 batch_import_gdrive_files.py 2025-12-26")
        sys.exit(1)
    
    date_str = sys.argv[1]
    
    # éªŒè¯æ—¥æœŸæ ¼å¼
    try:
        datetime.strptime(date_str, '%Y-%m-%d')
    except ValueError:
        log(f"âŒ æ— æ•ˆçš„æ—¥æœŸæ ¼å¼: {date_str}")
        log("æ­£ç¡®æ ¼å¼: YYYY-MM-DD (ä¾‹å¦‚: 2025-12-26)")
        sys.exit(1)
    
    # æ‰§è¡Œæ‰¹é‡å¯¼å…¥
    total = batch_import_date(date_str)
    
    log(f"\nğŸ‰ æ‰¹é‡å¯¼å…¥å®Œæˆ! å…±å¯¼å…¥ {total} æ¡è®°å½•")
