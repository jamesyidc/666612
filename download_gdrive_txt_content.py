#!/usr/bin/env python3
"""
æå–çœŸå®Google Driveæ–‡ä»¶IDå¹¶ä¸‹è½½å†…å®¹
"""
import requests
import re

folder_id = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"
target_filename = "2025-12-09_1758.txt"
entry_id = "1Hpoye1MieqjxzsnNSeN4D5q7zF"  # ä»entry-xxxä¸­æå–

print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½æ–‡ä»¶: {target_filename}")
print(f"   Entry ID: {entry_id}")
print()

# æ–¹æ³•1: å°è¯•ç›´æ¥ä¸‹è½½
download_urls = [
    f"https://drive.google.com/uc?export=download&id={entry_id}",
    f"https://docs.google.com/uc?export=download&id={entry_id}",
    f"https://drive.google.com/file/d/{entry_id}/view",
]

for url in download_urls:
    try:
        print(f"ğŸ”„ å°è¯•URL: {url}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30, allow_redirects=True)
        
        if response.status_code == 200:
            content = response.text
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯HTMLé¡µé¢è¿˜æ˜¯å®é™…å†…å®¹
            if '<html' in content.lower()[:100]:
                print(f"   âš ï¸  è¿”å›çš„æ˜¯HTMLé¡µé¢ï¼Œä¸æ˜¯æ–‡ä»¶å†…å®¹")
                
                # å¦‚æœæ˜¯viewé¡µé¢ï¼Œå°è¯•ä»ä¸­æå–å®é™…å†…å®¹
                if 'file/d/' in url:
                    # å°è¯•æ‰¾åˆ°çœŸå®çš„æ–‡ä»¶ID
                    real_id_match = re.search(r'"([a-zA-Z0-9_-]{33})"', content)
                    if real_id_match:
                        real_id = real_id_match.group(1)
                        print(f"   ğŸ’¡ æ‰¾åˆ°çœŸå®ID: {real_id}")
                        
                        # å°è¯•ç”¨çœŸå®IDä¸‹è½½
                        real_url = f"https://drive.google.com/uc?export=download&id={real_id}"
                        print(f"   ğŸ”„ å°è¯•çœŸå®URL: {real_url}")
                        real_response = requests.get(real_url, headers=headers, timeout=30)
                        
                        if real_response.status_code == 200:
                            content = real_response.text
                            if '<html' not in content.lower()[:100]:
                                print(f"   âœ… æˆåŠŸä¸‹è½½æ–‡ä»¶å†…å®¹ï¼")
                                break
            else:
                print(f"   âœ… æˆåŠŸä¸‹è½½æ–‡ä»¶å†…å®¹ï¼")
                break
        else:
            print(f"   âŒ HTTP {response.status_code}")
            
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {e}")
        continue

else:
    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨æœ€åçš„æ‰‹æ®µï¼š
    # åˆ©ç”¨ç°æœ‰çš„Google Driveæ–‡ä»¶å¤¹ç»“æ„æ¥æ‰‹åŠ¨æ„é€ 
    print("\nâš ï¸  æ‰€æœ‰ç›´æ¥ä¸‹è½½æ–¹æ³•å¤±è´¥")
    print("ğŸ’¡ ä½¿ç”¨alternativeæ–¹æ¡ˆï¼šæ¨¡æ‹Ÿauto_gdrive_updaterçš„é€»è¾‘")
    print()
    
    # æ—¢ç„¶æˆ‘ä»¬èƒ½çœ‹åˆ°æ–‡ä»¶å¤¹åˆ—è¡¨ï¼Œè®©æˆ‘ä»¬å°è¯•ç›´æ¥æ„é€ content
    # æˆ–è€…åˆ©ç”¨gdrive_content_reader.py
    print("å°è¯•ä½¿ç”¨gdrive_content_reader.py...")
    
    content = None

if content:
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_path = f"/home/user/webapp/{target_filename}"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"\nâœ… æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {len(content)} å­—èŠ‚")
    print()
    
    # æ˜¾ç¤ºå‰å‡ è¡Œ
    lines = content.split('\n')
    print("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆå‰20è¡Œï¼‰:")
    print("-" * 60)
    for i, line in enumerate(lines[:20], 1):
        print(f"{i:2d}. {line}")
    print("-" * 60)
else:
    print("\nâŒ æ— æ³•ä¸‹è½½æ–‡ä»¶å†…å®¹")
    print("ğŸ’¡ fallback: ä½¿ç”¨gdrive_content_readeræˆ–web scraping...")

