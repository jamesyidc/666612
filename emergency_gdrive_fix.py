#!/usr/bin/env python3
"""
ç´§æ€¥Google Driveä¿®å¤è„šæœ¬
å½“æ‰¾ä¸åˆ°ä»Šå¤©æ–‡ä»¶å¤¹æ—¶çš„åº”æ€¥æ–¹æ¡ˆ
"""
import requests
import json
from datetime import datetime, timedelta
import pytz

beijing_tz = pytz.timezone('Asia/Shanghai')
today = datetime.now(beijing_tz).strftime('%Y-%m-%d')

print("="*70)
print("ğŸš¨ Google Drive ç´§æ€¥è¯Šæ–­å’Œä¿®å¤å·¥å…·")
print("="*70)
print(f"ğŸ“… å½“å‰æ—¥æœŸ: {today} ({datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')})")
print()

# è¯»å–ç°æœ‰é…ç½®
try:
    with open('daily_folder_config.json', 'r') as f:
        config = json.load(f)
    print(f"ğŸ“‚ å½“å‰é…ç½®:")
    print(f"   æ—¥æœŸ: {config.get('current_date')}")
    print(f"   æ–‡ä»¶å¤¹ID: {config.get('folder_id')}")
    print(f"   æ›´æ–°æ—¶é—´: {config.get('updated_at')}")
    print()
except:
    config = {}
    print("âš ï¸ æ— æ³•è¯»å–é…ç½®æ–‡ä»¶\n")

# æµ‹è¯•å›ºå®šæ–‡ä»¶IDï¼ˆä»gdrive_final_detector.pyï¼‰
FIXED_FILE_ID = "1eyYiU6lU8n7SwWUvFtm_kUIvaZI0SO4U"

print(f"ğŸ” æ–¹æ¡ˆ1: æµ‹è¯•å›ºå®šæ–‡ä»¶IDè®¿é—®...")
print(f"   æ–‡ä»¶ID: {FIXED_FILE_ID}")

url = f"https://drive.google.com/uc?export=download&id={FIXED_FILE_ID}"
try:
    response = requests.get(url, timeout=10)
    if response.status_code == 200:
        content = response.text[:200]
        print(f"   âœ… å¯ä»¥è®¿é—®å›ºå®šæ–‡ä»¶IDï¼")
        print(f"   æ•°æ®é¢„è§ˆ: {content[:100]}...")
        print(f"   â†’ å»ºè®®ï¼šç»§ç»­ä½¿ç”¨å›ºå®šæ–‡ä»¶IDæ¨¡å¼")
    else:
        print(f"   âŒ å›ºå®šæ–‡ä»¶IDæ— æ³•è®¿é—® (çŠ¶æ€ç : {response.status_code})")
except Exception as e:
    print(f"   âŒ é”™è¯¯: {e}")

print()

# æ–¹æ¡ˆ2: æœç´¢æœ€è¿‘å‡ å¤©çš„æ–‡ä»¶å¤¹
known_folders = {
    "2025-12-11": "1k3I_NALUR24-lAapPnSJ7_gMvCOiX5cV",
    "2025-12-09": "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM",
}

print(f"ğŸ” æ–¹æ¡ˆ2: æ£€æŸ¥å·²çŸ¥æ–‡ä»¶å¤¹...")
for date_str, folder_id in known_folders.items():
    url = f"https://drive.google.com/embeddedfolderview?id={folder_id}"
    try:
        response = requests.get(url, timeout=5)
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')
        
        txt_files = [link.text.strip() for link in soup.find_all('a', href=True) 
                     if '.txt' in link.text.lower()]
        
        if txt_files:
            latest = sorted(txt_files)[-1] if txt_files else "æ— "
            print(f"   ğŸ“ {date_str}: {len(txt_files)}ä¸ªæ–‡ä»¶ (æœ€æ–°: {latest})")
    except:
        print(f"   âŒ {date_str}: æ— æ³•è®¿é—®")

print()
print("="*70)
print("ğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
print("="*70)
print("1. å¦‚æœå›ºå®šæ–‡ä»¶IDå¯ç”¨ â†’ ç³»ç»Ÿå¯ä»¥ç»§ç»­å·¥ä½œï¼ˆä½¿ç”¨å®æ—¶æ›´æ–°çš„æ–‡ä»¶ï¼‰")
print("2. å¦‚æœä»Šå¤©çš„æ–‡ä»¶å¤¹è¿˜æœªåˆ›å»º â†’ ç­‰å¾…æ–‡ä»¶å¤¹åˆ›å»ºåæ‰‹åŠ¨æ›´æ–°é…ç½®")
print("3. å¦‚æœéœ€è¦æ‰‹åŠ¨æ›´æ–° â†’ æä¾›ä»Šå¤©çš„æ–‡ä»¶å¤¹IDï¼Œæˆ‘ç«‹å³æ›´æ–°")
print()
print("ğŸ”— æ‰‹åŠ¨æ›´æ–°å‘½ä»¤ç¤ºä¾‹:")
print("   python3 -c \"import json; json.dump({'current_date': '2025-12-12',")
print("   'folder_id': 'ä½ çš„æ–‡ä»¶å¤¹ID'}, open('daily_folder_config.json','w'))\"")
print("="*70)
