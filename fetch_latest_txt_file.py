#!/usr/bin/env python3
"""
ä»Google Driveè·å–æŒ‡å®šçš„æœ€æ–°TXTæ–‡ä»¶
"""
import requests
import re

folder_id = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"
target_filename = "2025-12-09_1758"  # ä¸å«.txtæ‰©å±•å

print(f"ğŸ” æ­£åœ¨è·å–æ–‡ä»¶: {target_filename}.txt")
print(f"   æ–‡ä»¶å¤¹ID: {folder_id}")
print()

try:
    # è·å–æ–‡ä»¶å¤¹å†…å®¹
    folder_url = f"https://drive.google.com/drive/folders/{folder_id}"
    response = requests.get(folder_url, timeout=30)
    
    if response.status_code != 200:
        print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
        exit(1)
    
    print("âœ… æˆåŠŸè·å–æ–‡ä»¶å¤¹é¡µé¢")
    
    # æŸ¥æ‰¾æ–‡ä»¶ID
    # æ ¼å¼: "2025-12-09_1758.txt".*?"id":"FILE_ID"
    txt_pattern = r'"' + re.escape(target_filename) + r'\.txt".*?"id":"([^"]+)"'
    match = re.search(txt_pattern, response.text)
    
    if not match:
        print(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {target_filename}.txt")
        print("å°è¯•æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„ID...")
        
        # Alternative: æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ–‡ä»¶åçš„è¡Œ
        all_matches = re.findall(target_filename, response.text)
        print(f"   æ‰¾åˆ° {len(all_matches)} å¤„æ–‡ä»¶åå‡ºç°")
        
        # æ›´å®½æ¾çš„åŒ¹é…
        pattern2 = r'(' + re.escape(target_filename) + r'[^"]*)"[^}]*"id":"([^"]+)"'
        matches2 = re.findall(pattern2, response.text)
        
        if matches2:
            print(f"   ä½¿ç”¨å®½æ¾åŒ¹é…æ‰¾åˆ° {len(matches2)} ä¸ªå€™é€‰")
            file_id = matches2[0][1]
            print(f"âœ… æ–‡ä»¶ID: {file_id}")
        else:
            exit(1)
    else:
        file_id = match.group(1)
        print(f"âœ… æ–‡ä»¶ID: {file_id}")
    
    # æ„é€ ä¸‹è½½URL
    download_url = f"https://drive.google.com/uc?id={file_id}&export=download"
    print(f"ğŸ“¥ ä¸‹è½½URL: {download_url}")
    print()
    
    # ä¸‹è½½æ–‡ä»¶
    print("æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
    download_response = requests.get(download_url, timeout=30)
    
    if download_response.status_code == 200:
        content = download_response.text
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤ï¼ˆå¤§æ–‡ä»¶ï¼‰
        if 'download_warning' in content:
            # éœ€è¦ç¡®è®¤ä¸‹è½½
            print("   éœ€è¦ç¡®è®¤ä¸‹è½½ï¼ˆå¤§æ–‡ä»¶ï¼‰...")
            confirm_token = re.search(r'download_warning[^"]*', content)
            if confirm_token:
                confirmed_url = f"{download_url}&confirm={confirm_token.group(0)}"
                download_response = requests.get(confirmed_url, timeout=30)
                content = download_response.text
        
        # ä¿å­˜æ–‡ä»¶
        output_filename = f"{target_filename}.txt"
        output_path = f"/home/user/webapp/{output_filename}"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {output_path}")
        print(f"   æ–‡ä»¶å¤§å°: {len(content)} å­—èŠ‚")
        print()
        
        # æ˜¾ç¤ºæ–‡ä»¶å‰20è¡Œ
        lines = content.split('\n')
        print("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆå‰20è¡Œï¼‰:")
        print("=" * 70)
        for i, line in enumerate(lines[:20], 1):
            print(f"{i:2d}. {line}")
        print("=" * 70)
        print(f"æ€»è¡Œæ•°: {len(lines)}")
        
    else:
        print(f"âŒ ä¸‹è½½å¤±è´¥: HTTP {download_response.status_code}")
        
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()

