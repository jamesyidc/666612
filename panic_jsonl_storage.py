"""
Panic Data JSONL Storage System
ææ…Œæ¸…æ´—æŒ‡æ•°æ•°æ® JSONL å­˜å‚¨ç³»ç»Ÿ
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
import pytz

class PanicJSONLStorage:
    def __init__(self, data_dir="data/panic_snapshots"):
        """åˆå§‹åŒ–JSONLå­˜å‚¨ç³»ç»Ÿ"""
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.keep_days = 30  # ä¿ç•™30å¤©æ•°æ®
        self.tz = pytz.timezone('Asia/Shanghai')
    
    def _get_date_file(self, date_str):
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ–‡ä»¶è·¯å¾„"""
        return self.data_dir / f"{date_str}.jsonl"
    
    def save_snapshot(self, snapshot_data):
        """ä¿å­˜å¿«ç…§æ•°æ®åˆ°JSONL"""
        try:
            # è·å–åŒ—äº¬æ—¶é—´
            snapshot_time = snapshot_data.get('snapshot_time')
            if isinstance(snapshot_time, str):
                dt = datetime.fromisoformat(snapshot_time.replace('Z', '+00:00'))
                if dt.tzinfo is None:
                    dt = self.tz.localize(dt)
                else:
                    dt = dt.astimezone(self.tz)
            else:
                dt = datetime.now(self.tz)
            
            date_str = dt.strftime('%Y-%m-%d')
            file_path = self._get_date_file(date_str)
            
            # æ·»åŠ å†™å…¥æ—¶é—´æˆ³
            snapshot_data['written_at'] = datetime.now(self.tz).isoformat()
            
            # è¿½åŠ å†™å…¥JSONL
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(snapshot_data, ensure_ascii=False) + '\n')
            
            # æ¸…ç†æ—§æ•°æ®
            self._cleanup_old_data()
            
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜å¿«ç…§å¤±è´¥: {e}")
            return False
    
    def read_latest(self, limit=1):
        """è¯»å–æœ€æ–°çš„Næ¡è®°å½•"""
        try:
            # è·å–æœ€è¿‘å‡ å¤©çš„æ–‡ä»¶
            files = sorted(self.data_dir.glob('*.jsonl'), reverse=True)
            
            records = []
            for file_path in files[:7]:  # æœ€å¤šæ£€æŸ¥æœ€è¿‘7å¤©
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    for line in reversed(lines):
                        if line.strip():
                            records.append(json.loads(line))
                            if len(records) >= limit:
                                return records
            
            return records
        except Exception as e:
            print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
            return []
    
    def read_by_date_range(self, start_date, end_date, limit=1000):
        """è¯»å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„è®°å½•"""
        try:
            records = []
            current_date = datetime.strptime(end_date, '%Y-%m-%d')
            start = datetime.strptime(start_date, '%Y-%m-%d')
            
            while current_date >= start:
                date_str = current_date.strftime('%Y-%m-%d')
                file_path = self._get_date_file(date_str)
                
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            if line.strip():
                                record = json.loads(line)
                                records.append(record)
                                if len(records) >= limit:
                                    return records
                
                current_date -= timedelta(days=1)
            
            return records
        except Exception as e:
            print(f"âŒ è¯»å–æ—¥æœŸèŒƒå›´æ•°æ®å¤±è´¥: {e}")
            return []
    
    def read_today(self):
        """è¯»å–ä»Šå¤©çš„æ‰€æœ‰è®°å½•"""
        try:
            now = datetime.now(self.tz)
            date_str = now.strftime('%Y-%m-%d')
            file_path = self._get_date_file(date_str)
            
            if not file_path.exists():
                return []
            
            records = []
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        records.append(json.loads(line))
            
            return records
        except Exception as e:
            print(f"âŒ è¯»å–ä»Šæ—¥æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _cleanup_old_data(self):
        """æ¸…ç†è¶…è¿‡ä¿ç•™æœŸçš„æ—§æ•°æ®"""
        try:
            cutoff_date = datetime.now(self.tz) - timedelta(days=self.keep_days)
            cutoff_str = cutoff_date.strftime('%Y-%m-%d')
            
            for file_path in self.data_dir.glob('*.jsonl'):
                file_date = file_path.stem
                if file_date < cutoff_str:
                    file_path.unlink()
                    print(f"ğŸ—‘ï¸  å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path.name}")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
    
    def get_stats(self):
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            files = list(self.data_dir.glob('*.jsonl'))
            total_size = sum(f.stat().st_size for f in files)
            
            total_records = 0
            for file_path in files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    total_records += sum(1 for line in f if line.strip())
            
            return {
                'total_files': len(files),
                'total_records': total_records,
                'total_size_mb': round(total_size / 1024 / 1024, 2),
                'date_range': {
                    'earliest': min(f.stem for f in files) if files else None,
                    'latest': max(f.stem for f in files) if files else None
                }
            }
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}

# å…¨å±€å®ä¾‹
panic_storage = PanicJSONLStorage()
