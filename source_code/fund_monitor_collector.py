#!/usr/bin/env python3
"""
èµ„é‡‘ç›‘æ§ç³»ç»Ÿæ•°æ®é‡‡é›†å™¨
- æ¯5åˆ†é’Ÿé‡‡é›†27ä¸ªå¸ç§çš„æˆäº¤é‡æ•°æ®ï¼ˆä»OKExï¼‰
- è®¡ç®—15åˆ†é’Ÿã€30åˆ†é’Ÿã€60åˆ†é’Ÿçš„èšåˆæˆäº¤é‡
- ä¸è¿‡å»3å¤©å¹³å‡é‡èƒ½å¯¹æ¯”ï¼Œæ£€æµ‹å¼‚å¸¸æ³¢åŠ¨ï¼ˆ>20%ï¼Œå¯é…ç½®ï¼‰
- æ•°æ®ä¸V1V2ç³»ç»Ÿå…±äº«OKExæ•°æ®æº
"""
import requests
import sqlite3
import time
import logging
from datetime import datetime, timedelta
import pytz
import json
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fund_monitor_collector.log'),
        logging.StreamHandler()
    ]
)

# 27ä¸ªç›‘æ§å¸ç§
COINS = [
    'BTC', 'ETH', 'XRP', 'BNB', 'SOL', 'LTC', 'DOGE', 'SUI', 'TRX', 'TON',
    'ETC', 'BCH', 'HBAR', 'XLM', 'FIL', 'LINK', 'CRO', 'DOT', 'AAVE', 'UNI',
    'NEAR', 'APT', 'CFX', 'CRV', 'STX', 'LDO', 'TAO'
]

DB_FILE = 'fund_monitor.db'
CONFIG_FILE = 'fund_monitor_config.json'
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    'threshold_percentage': 20.0,  # å¼‚å¸¸æ³¢åŠ¨é˜ˆå€¼ç™¾åˆ†æ¯”
    'lookback_days': 3,  # å›çœ‹å¤©æ•°
    'collection_interval': 300  # é‡‡é›†é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
}

# å…¨å±€é…ç½®
CONFIG = DEFAULT_CONFIG.copy()

def load_config():
    """åŠ è½½é…ç½®"""
    global CONFIG
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                CONFIG.update(user_config)
            logging.info(f'âœ… é…ç½®åŠ è½½æˆåŠŸ: é˜ˆå€¼={CONFIG["threshold_percentage"]}%, å›çœ‹={CONFIG["lookback_days"]}å¤©')
        else:
            # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
            save_config()
            logging.info('âš ï¸ ä½¿ç”¨é»˜è®¤é…ç½®å¹¶åˆ›å»ºé…ç½®æ–‡ä»¶')
    except Exception as e:
        logging.error(f'âŒ åŠ è½½é…ç½®å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®')
        CONFIG = DEFAULT_CONFIG.copy()

def save_config():
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(CONFIG, f, ensure_ascii=False, indent=2)
        logging.info('âœ… é…ç½®ä¿å­˜æˆåŠŸ')
    except Exception as e:
        logging.error(f'âŒ é…ç½®ä¿å­˜å¤±è´¥: {str(e)}')

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    # 5åˆ†é’ŸåŸå§‹æ•°æ®è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS fund_monitor_5min (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            timestamp INTEGER NOT NULL,
            collect_time TEXT NOT NULL,
            volume REAL NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(symbol, timestamp)
        )
    ''')
    
    # èšåˆæ•°æ®è¡¨ï¼ˆ15/30/60åˆ†é’Ÿï¼‰
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS fund_monitor_aggregated (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            timestamp INTEGER NOT NULL,
            collect_time TEXT NOT NULL,
            interval_type TEXT NOT NULL,
            volume REAL NOT NULL,
            avg_3day REAL,
            deviation_percent REAL,
            is_abnormal INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(symbol, timestamp, interval_type)
        )
    ''')
    
    # é…ç½®è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS fund_monitor_config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            key TEXT UNIQUE NOT NULL,
            value REAL NOT NULL,
            description TEXT,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # æ’å…¥é»˜è®¤é…ç½®
    cursor.execute('''
        INSERT OR IGNORE INTO fund_monitor_config (key, value, description)
        VALUES ('threshold_percentage', 20.0, 'å¼‚å¸¸æ³¢åŠ¨é˜ˆå€¼ç™¾åˆ†æ¯”')
    ''')
    
    # åˆ›å»ºç´¢å¼•
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_5min_symbol_time ON fund_monitor_5min(symbol, timestamp DESC)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_agg_symbol_time ON fund_monitor_aggregated(symbol, timestamp DESC, interval_type)')
    
    conn.commit()
    conn.close()
    logging.info('âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ')

def fetch_volume_from_okex(symbol):
    """
    ä»OKExè·å–5åˆ†é’ŸKçº¿çš„æˆäº¤é‡æ•°æ®
    è¿”å›: (timestamp, volume_usdt) æˆ– (None, None)
    """
    try:
        url = 'https://www.okx.com/api/v5/market/candles'
        params = {
            'instId': f'{symbol}-USDT-SWAP',
            'bar': '5m',
            'limit': '1'  # åªè·å–æœ€æ–°ä¸€æ ¹Kçº¿
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        if data['code'] == '0' and data['data']:
            # Kçº¿æ•°æ®: [timestamp, open, high, low, close, volume, volCcy, volCcyQuote, confirm]
            # volCcyQuote(ç´¢å¼•7) æ˜¯USDTæˆäº¤é¢
            candle = data['data'][0]
            timestamp = int(candle[0])  # æ¯«ç§’æ—¶é—´æˆ³
            volume_usdt = float(candle[7])  # USDTæˆäº¤é¢
            
            logging.info(f'âœ… {symbol}: Vol=${volume_usdt:,.2f} USDT')
            return timestamp, volume_usdt
        else:
            logging.warning(f'âš ï¸ {symbol}: APIè¿”å›æ— æ•°æ® - {data}')
            return None, None
            
    except requests.exceptions.Timeout:
        logging.error(f'âŒ {symbol}: è¯·æ±‚è¶…æ—¶')
        return None, None
    except requests.exceptions.RequestException as e:
        logging.error(f'âŒ {symbol}: ç½‘ç»œé”™è¯¯ - {str(e)}')
        return None, None
    except Exception as e:
        logging.error(f'âŒ {symbol}: æ•°æ®è§£æé”™è¯¯ - {str(e)}')
        return None, None

def store_5min_data(conn, symbol, timestamp, volume):
    """å­˜å‚¨5åˆ†é’ŸåŸå§‹æ•°æ®"""
    cursor = conn.cursor()
    collect_time = datetime.fromtimestamp(timestamp / 1000, BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
    
    try:
        cursor.execute('''
            INSERT OR REPLACE INTO fund_monitor_5min 
            (symbol, timestamp, collect_time, volume)
            VALUES (?, ?, ?, ?)
        ''', (symbol, timestamp, collect_time, volume))
        return True
    except Exception as e:
        logging.error(f'âŒ {symbol}: å­˜å‚¨5åˆ†é’Ÿæ•°æ®å¤±è´¥ - {str(e)}')
        return False

def calculate_aggregated_volume(conn, symbol, timestamp, interval_minutes):
    """
    è®¡ç®—èšåˆæˆäº¤é‡ï¼ˆ15/30/60åˆ†é’Ÿï¼‰
    ä»å½“å‰æ—¶é—´æˆ³å‘å‰å›æº¯æŒ‡å®šåˆ†é’Ÿæ•°
    """
    cursor = conn.cursor()
    
    # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆæ¯«ç§’ï¼‰
    lookback_ms = interval_minutes * 60 * 1000
    start_timestamp = timestamp - lookback_ms + 1  # +1é¿å…åŒ…å«è¾¹ç•Œå¤–çš„æ•°æ®
    
    # æŸ¥è¯¢è¯¥æ—¶é—´æ®µå†…çš„5åˆ†é’Ÿæ•°æ®
    cursor.execute('''
        SELECT SUM(volume) 
        FROM fund_monitor_5min
        WHERE symbol = ? 
        AND timestamp > ? 
        AND timestamp <= ?
    ''', (symbol, start_timestamp, timestamp))
    
    result = cursor.fetchone()
    total_volume = result[0] if result[0] is not None else 0.0
    
    return total_volume

def calculate_3day_average(conn, symbol, timestamp, interval_minutes):
    """
    è®¡ç®—è¿‡å»3å¤©è¯¥æ—¶é—´æ®µçš„å¹³å‡æˆäº¤é‡
    ä¾‹å¦‚ï¼šå½“å‰æ˜¯15åˆ†é’Ÿæ•°æ®ï¼Œåˆ™è®¡ç®—è¿‡å»3å¤©åŒä¸€æ—¶åˆ»çš„15åˆ†é’Ÿå¹³å‡é‡
    """
    cursor = conn.cursor()
    
    # 3å¤©å‰çš„æ—¶é—´æˆ³
    three_days_ago = timestamp - (3 * 24 * 60 * 60 * 1000)
    
    # æŸ¥è¯¢è¿‡å»3å¤©çš„èšåˆæ•°æ®
    cursor.execute('''
        SELECT AVG(volume)
        FROM fund_monitor_aggregated
        WHERE symbol = ?
        AND interval_type = ?
        AND timestamp > ?
        AND timestamp < ?
    ''', (symbol, f'{interval_minutes}min', three_days_ago, timestamp))
    
    result = cursor.fetchone()
    avg_volume = result[0] if result[0] is not None else None
    
    return avg_volume

def store_abnormal_history(conn, symbol, timestamp, interval_minutes, volume, avg_3day, deviation_percent):
    """
    è®°å½•å¼‚å¸¸æ•°æ®åˆ°å†å²è¡¨
    """
    cursor = conn.cursor()
    collect_time = datetime.fromtimestamp(timestamp / 1000, BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
    collect_date = datetime.fromtimestamp(timestamp / 1000, BEIJING_TZ).strftime('%Y-%m-%d')
    interval_type = f'{interval_minutes}min'
    
    # åˆ¤æ–­åå·®ç±»å‹
    deviation_type = 'surge' if deviation_percent > 0 else 'drop'
    
    # åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
    abs_deviation = abs(deviation_percent)
    if abs_deviation >= 50:
        severity = 'critical'  # ä¸¥é‡
    elif abs_deviation >= 30:
        severity = 'high'  # é«˜
    else:
        severity = 'medium'  # ä¸­ç­‰
    
    try:
        cursor.execute('''
            INSERT INTO fund_monitor_abnormal_history
            (symbol, interval_type, timestamp, collect_time, collect_date, 
             volume, avg_3day, deviation_percent, deviation_type, severity)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (symbol, interval_type, timestamp, collect_time, collect_date,
              volume, avg_3day, deviation_percent, deviation_type, severity))
        return True
    except Exception as e:
        logging.error(f'âŒ {symbol}: è®°å½•å¼‚å¸¸å†å²å¤±è´¥ - {str(e)}')
        return False

def store_aggregated_data(conn, symbol, timestamp, interval_minutes, volume):
    """
    å­˜å‚¨èšåˆæ•°æ®å¹¶æ£€æµ‹å¼‚å¸¸
    """
    cursor = conn.cursor()
    collect_time = datetime.fromtimestamp(timestamp / 1000, BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
    interval_type = f'{interval_minutes}min'
    
    # è®¡ç®—3å¤©å¹³å‡
    avg_3day = calculate_3day_average(conn, symbol, timestamp, interval_minutes)
    
    # è®¡ç®—åå·®ç™¾åˆ†æ¯”å’Œå¼‚å¸¸æ ‡è®°
    deviation_percent = None
    is_abnormal = 0
    
    if avg_3day is not None and avg_3day > 0:
        deviation_percent = ((volume - avg_3day) / avg_3day) * 100
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if abs(deviation_percent) >= CONFIG['threshold_percentage']:
            is_abnormal = 1
            logging.warning(f'ğŸš¨ {symbol} {interval_type}: å¼‚å¸¸æ³¢åŠ¨ {deviation_percent:+.2f}% (å½“å‰={volume:,.0f}, 3æ—¥å‡={avg_3day:,.0f})')
            
            # è®°å½•åˆ°å¼‚å¸¸å†å²è¡¨
            store_abnormal_history(conn, symbol, timestamp, interval_minutes, volume, avg_3day, deviation_percent)
    
    try:
        cursor.execute('''
            INSERT OR REPLACE INTO fund_monitor_aggregated
            (symbol, timestamp, collect_time, interval_type, volume, avg_3day, deviation_percent, is_abnormal)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (symbol, timestamp, collect_time, interval_type, volume, avg_3day, deviation_percent, is_abnormal))
        return True
    except Exception as e:
        logging.error(f'âŒ {symbol}: å­˜å‚¨èšåˆæ•°æ®å¤±è´¥ - {str(e)}')
        return False

def collect_and_process():
    """é‡‡é›†æ•°æ®å¹¶å¤„ç†"""
    conn = sqlite3.connect(DB_FILE)
    
    logging.info('='*60)
    logging.info(f'å¼€å§‹é‡‡é›† - {datetime.now(BEIJING_TZ).strftime("%Y-%m-%d %H:%M:%S")}')
    
    success_count = 0
    fail_count = 0
    
    for symbol in COINS:
        # 1. ä»OKExè·å–5åˆ†é’Ÿæ•°æ®
        timestamp, volume = fetch_volume_from_okex(symbol)
        
        if timestamp is None or volume is None:
            fail_count += 1
            continue
        
        # 2. å­˜å‚¨5åˆ†é’ŸåŸå§‹æ•°æ®
        if store_5min_data(conn, symbol, timestamp, volume):
            success_count += 1
        else:
            fail_count += 1
            continue
        
        # 3. è®¡ç®—å¹¶å­˜å‚¨èšåˆæ•°æ®ï¼ˆ15/30/60åˆ†é’Ÿï¼‰
        for interval_min in [15, 30, 60]:
            agg_volume = calculate_aggregated_volume(conn, symbol, timestamp, interval_min)
            store_aggregated_data(conn, symbol, timestamp, interval_min, agg_volume)
    
    conn.commit()
    conn.close()
    
    logging.info(f'é‡‡é›†å®Œæˆ: æˆåŠŸ={success_count}, å¤±è´¥={fail_count}')
    logging.info('='*60)

def main():
    """ä¸»å‡½æ•°"""
    logging.info('ğŸš€ èµ„é‡‘ç›‘æ§ç³»ç»Ÿé‡‡é›†å™¨å¯åŠ¨')
    logging.info(f'ç›‘æ§å¸ç§: {len(COINS)}ä¸ª - {", ".join(COINS)}')
    
    # åŠ è½½é…ç½®
    load_config()
    logging.info(f'é…ç½®: é˜ˆå€¼={CONFIG["threshold_percentage"]}%, å›çœ‹={CONFIG["lookback_days"]}å¤©, é—´éš”={CONFIG["collection_interval"]}ç§’')
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    # é¦–æ¬¡ç«‹å³é‡‡é›†
    try:
        collect_and_process()
    except Exception as e:
        logging.error(f'âŒ é¦–æ¬¡é‡‡é›†å¤±è´¥: {str(e)}')
    
    # å®šæ—¶é‡‡é›†å¾ªç¯
    logging.info(f'â° å¼€å§‹å®šæ—¶é‡‡é›†ï¼ˆé—´éš”={CONFIG["collection_interval"]}ç§’ï¼‰')
    
    while True:
        try:
            time.sleep(CONFIG['collection_interval'])
            
            # é‡æ–°åŠ è½½é…ç½®ï¼ˆæ”¯æŒçƒ­æ›´æ–°ï¼‰
            load_config()
            
            # é‡‡é›†æ•°æ®
            collect_and_process()
            
        except KeyboardInterrupt:
            logging.info('ğŸ‘‹ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºé‡‡é›†å™¨')
            break
        except Exception as e:
            logging.error(f'âŒ é‡‡é›†è¿‡ç¨‹å‡ºé”™: {str(e)}')
            time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†ç»§ç»­

if __name__ == '__main__':
    main()
