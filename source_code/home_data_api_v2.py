#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¦–é¡µæ•°æ®API - å¸¦ç¼“å­˜ç‰ˆæœ¬
"""

from flask import Flask, jsonify, send_file
import asyncio
import sys
import os
import threading
import time
from datetime import datetime, timedelta

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

app = Flask(__name__)

# å…¨å±€ç¼“å­˜
CACHE = {
    'data': None,
    'last_update': None,
    'updating': False
}

# ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
CACHE_VALIDITY = 60  # 1åˆ†é’Ÿï¼ˆé™ä½ç¼“å­˜æ—¶é—´ä»¥è·å–æ›´åŠæ—¶çš„æ•°æ®ï¼‰

# æ›´æ–°å‘¨æœŸï¼ˆç§’ï¼‰- åŒ¹é…Google Driveçš„3åˆ†é’Ÿæ›´æ–°å‘¨æœŸ
UPDATE_CYCLE = 180  # 3åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡ï¼ˆåŒ¹é…æ•°æ®æºæ›´æ–°é¢‘ç‡ï¼‰

# Google Driveä¸Šä¼ ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰- åœ¨æ¯ä¸ª3åˆ†é’Ÿå‘¨æœŸçš„10-15ç§’ä¹‹é—´è·å–æ•°æ®
GDRIVE_WAIT_TIME = 10  # ç­‰å¾…åˆ°ç¬¬10ç§’å¼€å§‹è·å–æ•°æ®
GDRIVE_WAIT_MAX = 15  # æœ€å¤šç­‰å¾…åˆ°ç¬¬15ç§’

def parse_home_data(content):
    """è§£æé¦–é¡µæ•°æ®å†…å®¹"""
    lines = content.strip().split('\n')
    
    stats = {}
    coins = []
    
    in_coin_section = False
    
    for line in lines:
        line = line.strip()
        
        # è§£æç»Ÿè®¡æ•°æ®
        if line.startswith('é€æ˜æ ‡ç­¾_'):
            parts = line.split('=')
            if len(parts) == 2:
                key = parts[0].replace('é€æ˜æ ‡ç­¾_', '')
                value = parts[1]
                
                if 'æ€¥æ¶¨æ€»å’Œ' in key:
                    stats['rushUp'] = value.split('ï¼š')[1] if 'ï¼š' in value else value
                elif 'æ€¥è·Œæ€»å’Œ' in key:
                    stats['rushDown'] = value.split('ï¼š')[1] if 'ï¼š' in value else value
                elif 'äº”ç§çŠ¶æ€' in key:
                    stats['status'] = value.split('ï¼š')[1] if 'ï¼š' in value else value
                elif 'æ€¥æ¶¨æ€¥è·Œæ¯”å€¼' in key:
                    stats['ratio'] = value.split('ï¼š')[1] if 'ï¼š' in value else value
                elif 'ç»¿è‰²æ•°é‡' in key:
                    stats['greenCount'] = value
                elif 'ç™¾åˆ†æ¯”' in key:
                    stats['percentage'] = value
        
        # å¸ç§æ•°æ®
        if '[è¶…çº§åˆ—è¡¨æ¡†_é¦–é¡µå¼€å§‹]' in line:
            in_coin_section = True
            continue
        
        if '[è¶…çº§åˆ—è¡¨æ¡†_é¦–é¡µç»“æŸ]' in line:
            break
        
        if in_coin_section and '|' in line:
            parts = line.split('|')
            if len(parts) >= 16:
                coin = {
                    'index': parts[0],
                    'symbol': parts[1],
                    'change': parts[2],
                    'rushUp': parts[3],
                    'rushDown': parts[4],
                    'updateTime': parts[5],
                    'highPrice': parts[6],
                    'highTime': parts[7],
                    'decline': parts[8],
                    'change24h': parts[9],
                    'rank': parts[12],
                    'currentPrice': parts[13],
                    'ratio1': parts[14],
                    'ratio2': parts[15]
                }
                coins.append(coin)
    
    # è·å–æ›´æ–°æ—¶é—´
    update_time = coins[0]['updateTime'] if coins else ''
    
    return {
        'stats': stats,
        'coins': coins,
        'updateTime': update_time
    }

def save_to_home_cache(parsed_data, filename, time_diff, update_time):
    """ä¿å­˜é¦–é¡µæ•°æ®åˆ°ç¼“å­˜è¡¨"""
    import json
    
    try:
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        # æå–ç»Ÿè®¡æ•°æ®
        stats = parsed_data.get('stats', {})
        coins = parsed_data.get('coins', [])
        
        cursor.execute("""
            INSERT INTO home_data_cache 
            (filename, time_diff, rush_up, rush_down, status, ratio, 
             green_count, percentage, coin_data, update_time)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            filename,
            time_diff,
            stats.get('rushUp', 0),
            stats.get('rushDown', 0),
            stats.get('status', ''),
            stats.get('ratio', 0),
            stats.get('green_count', 0),
            stats.get('percentage', 0),
            json.dumps(coins, ensure_ascii=False),
            update_time
        ))
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"   âš ï¸  ä¿å­˜åˆ°home_cacheå¤±è´¥: {str(e)}")
        return False

def update_cache():
    """åå°æ›´æ–°ç¼“å­˜"""
    global CACHE
    
    if CACHE['updating']:
        print("å·²ç»åœ¨æ›´æ–°ä¸­ï¼Œè·³è¿‡...")
        return
    
    CACHE['updating'] = True
    print(f"\n{'='*60}")
    print(f"å¼€å§‹æ›´æ–°æ•°æ®ç¼“å­˜... {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}")
    
    try:
        from gdrive_home_data_reader import get_latest_file_by_sorting
        
        # è·å–æœ€æ–°æ•°æ®
        result = asyncio.run(get_latest_file_by_sorting())
        
        if result and result.get('content'):
            parsed_data = parse_home_data(result['content'])
            
            CACHE['data'] = {
                'parsed_data': parsed_data,
                'filename': result['filename'],
                'time_diff': result['time_diff']
            }
            CACHE['last_update'] = time.time()
            
            print(f"âœ… ç¼“å­˜æ›´æ–°æˆåŠŸ")
            print(f"   æ–‡ä»¶å: {result['filename']}")
            print(f"   æ—¶é—´å·®: {result['time_diff']:.1f} åˆ†é’Ÿ")
            
            # ä¿å­˜åˆ°home_data_cacheè¡¨ï¼ˆå¿«é€Ÿç¼“å­˜ï¼‰
            try:
                update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                if save_to_home_cache(parsed_data, result['filename'], result['time_diff'], update_time):
                    print(f"   ğŸ’¾ å·²ä¿å­˜åˆ°å¿«é€Ÿç¼“å­˜è¡¨")
            except Exception as cache_error:
                print(f"   âš ï¸  å¿«é€Ÿç¼“å­˜ä¿å­˜å¤±è´¥: {str(cache_error)}")
            
            # è‡ªåŠ¨ä¿å­˜åˆ°å†å²æ•°æ®åº“
            try:
                from import_history_simple import parse_filename_datetime, parse_home_data as parse_for_db, save_to_database
                
                filename = result['filename']
                content = result['content']
                record_time = parse_filename_datetime(filename)
                
                if record_time:
                    stats, coins = parse_for_db(content)
                    success, msg = save_to_database(filename, record_time, stats, coins)
                    if success:
                        print(f"   ğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜åˆ°å†å²æ•°æ®åº“")
                    else:
                        print(f"   ğŸ’¾ å†å²æ•°æ®åº“: {msg}")
            except Exception as db_error:
                print(f"   âš ï¸  ä¿å­˜åˆ°å†å²æ•°æ®åº“å¤±è´¥: {str(db_error)}")
            
            # è§¦å‘æ¯”ä»·æ£€æŸ¥
            try:
                trigger_price_comparison(parsed_data['coins'])
            except Exception as price_error:
                print(f"   âš ï¸  æ¯”ä»·æ£€æŸ¥å¤±è´¥: {str(price_error)}")
            
            print(f"{'='*60}\n")
        else:
            print("âŒ è·å–æ•°æ®å¤±è´¥")
    except Exception as e:
        print(f"âŒ æ›´æ–°ç¼“å­˜å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        CACHE['updating'] = False

def sync_signal_stats():
    """åŒæ­¥åšå¤šåšç©ºä¿¡å·ç»Ÿè®¡æ•°æ®"""
    try:
        print("\n" + "="*60)
        print("åŒæ­¥ä¿¡å·ç»Ÿè®¡æ•°æ®...")
        print("="*60)
        
        import requests
        from datetime import timezone, timedelta
        
        BEIJING_TZ = timezone(timedelta(hours=8))
        EXTERNAL_API = "https://8080-ieo4kftymfy546kbm6o33-2e77fc33.sandbox.novita.ai/api/filtered-signals/stats"
        
        # è·å–æ•°æ®
        params = {
            'limit': 200,
            'rsi_short_threshold': 65,
            'rsi_long_threshold': 30
        }
        
        response = requests.get(EXTERNAL_API, params=params, timeout=10)
        data = response.json()
        
        if not data.get('success'):
            print(f"âŒ APIè¿”å›å¤±è´¥")
            return False
        
        # æå–æ•°æ®
        summary = data.get('summary', {})
        breakdown = data.get('breakdown', {})
        
        # ç”Ÿæˆè®°å½•æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼Œç²¾ç¡®åˆ°åˆ†é’Ÿï¼‰
        beijing_now = datetime.now(BEIJING_TZ)
        record_time = beijing_now.strftime('%Y-%m-%d %H:%M:00')
        
        total_count = summary.get('total', 0)
        long_count = summary.get('long', 0)
        short_count = summary.get('short', 0)
        chaodi_count = breakdown.get('æŠ„åº•åšå¤š', 0)
        dibu_count = breakdown.get('åº•éƒ¨åšå¤š', 0)
        dingbu_count = breakdown.get('é¡¶éƒ¨åšç©º', 0)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        import sqlite3
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        cursor.execute(
            'SELECT id FROM signal_stats_history WHERE record_time = ?',
            (record_time,)
        )
        existing = cursor.fetchone()
        
        if existing:
            print(f"â­ï¸  è®°å½•å·²å­˜åœ¨: {record_time}")
            conn.close()
            return False
        
        # æ’å…¥æ•°æ®
        cursor.execute('''
            INSERT INTO signal_stats_history 
            (record_time, total_count, long_count, short_count,
             chaodi_count, dibu_count, dingbu_count, source_url)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            record_time, total_count, long_count, short_count,
            chaodi_count, dibu_count, dingbu_count, EXTERNAL_API
        ))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… ä¿¡å·æ•°æ®åŒæ­¥æˆåŠŸ: {record_time}")
        print(f"   æ€»è®¡: {total_count}, åšå¤š: {long_count}, åšç©º: {short_count}")
        print("="*60 + "\n")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿¡å·æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def sync_panic_wash_data():
    """åŒæ­¥ææ…Œæ¸…æ´—æŒ‡æ ‡æ•°æ®"""
    try:
        import sqlite3
        
        # ä»ææ…Œæ¸…æ´—APIè·å–æœ€æ–°æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨V4è¯»å–å™¨ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶ï¼‰
        try:
            from panic_wash_reader_v5 import get_panic_wash_data_sync
        except:
            try:
                from panic_wash_reader_v4 import get_panic_wash_data_sync
            except:
                from panic_wash_simple import get_panic_wash_data_sync
        data = get_panic_wash_data_sync()
        
        if not data:
            print("âš ï¸  ææ…Œæ¸…æ´—æ•°æ®è·å–å¤±è´¥")
            return False
        
        # è§£ææ•°æ®
        panic_indicator_str = data['panic_indicator']  # ä¾‹å¦‚: "10.77-ç»¿"
        parts = panic_indicator_str.split('-')
        panic_indicator = float(parts[0])
        panic_color = parts[1] if len(parts) > 1 else None
        
        trend_rating = int(data['trend_rating'])
        market_zone = data['market_zone']
        liquidation_24h_people = int(data['liquidation_24h_people'])
        liquidation_24h_amount = float(data['liquidation_24h_amount'])
        total_position = float(data['total_position'])
        record_time = data['update_time']
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR IGNORE INTO panic_wash_history 
            (record_time, panic_indicator, panic_color, trend_rating, market_zone,
             liquidation_24h_people, liquidation_24h_amount, total_position)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (record_time, panic_indicator, panic_color, trend_rating, market_zone,
              liquidation_24h_people, liquidation_24h_amount, total_position))
        
        conn.commit()
        conn.close()
        
        if cursor.rowcount > 0:
            print(f"âœ… ææ…Œæ¸…æ´—æ•°æ®åŒæ­¥æˆåŠŸ: {record_time}")
            print(f"   æŒ‡æ ‡: {panic_indicator} ({panic_color}), æŒä»“é‡: {total_position}äº¿")
        else:
            print(f"âš ï¸  ææ…Œæ¸…æ´—æ•°æ®å·²å­˜åœ¨: {record_time}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ææ…Œæ¸…æ´—æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def background_updater():
    """åå°å®šæ—¶æ›´æ–°çº¿ç¨‹ - ä¸¥æ ¼æ¯3åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡"""
    print("ğŸš€ åå°æ›´æ–°çº¿ç¨‹å¯åŠ¨")
    print(f"â° æ›´æ–°å‘¨æœŸ: {UPDATE_CYCLE}ç§’ ({UPDATE_CYCLE/60:.1f}åˆ†é’Ÿ)")
    print(f"â° æ•°æ®é‡‡é›†ç­–ç•¥: é¦–æ¬¡å¯¹é½3åˆ†é’Ÿå‘¨æœŸï¼Œåç»­å›ºå®šé—´éš”180ç§’")
    print("="*70)
    
    # é¦–æ¬¡å¯åŠ¨ï¼šè®¡ç®—åˆ°ä¸‹ä¸€ä¸ª3åˆ†é’Ÿå‘¨æœŸï¼ˆå¯¹é½åˆ°0,3,6,9...åˆ†é’Ÿï¼‰
    now = datetime.now()
    current_minute = now.minute
    current_second = now.second
    
    # è®¡ç®—ä¸‹ä¸€ä¸ª3åˆ†é’Ÿå‘¨æœŸçš„åˆ†é’Ÿæ•°
    next_cycle_minute = ((current_minute // 3) + 1) * 3
    
    # å¤„ç†è·¨å°æ—¶çš„æƒ…å†µ
    if next_cycle_minute >= 60:
        next_hour = (now.hour + 1) % 24
        next_minute = next_cycle_minute - 60
        target_time = now.replace(hour=next_hour, minute=next_minute, second=GDRIVE_WAIT_TIME, microsecond=0)
        if target_time < now:  # è·¨å¤©çš„æƒ…å†µ
            target_time = target_time + timedelta(days=1)
    else:
        target_time = now.replace(minute=next_cycle_minute, second=GDRIVE_WAIT_TIME, microsecond=0)
    
    # é¦–æ¬¡ç­‰å¾…åˆ°ç›®æ ‡æ—¶é—´
    wait_seconds = (target_time - now).total_seconds()
    if wait_seconds > 0:
        beijing_time = (datetime.utcnow() + timedelta(hours=8)).strftime('%H:%M:%S')
        print(f"â° [{beijing_time}åŒ—äº¬] é¦–æ¬¡å¯åŠ¨ï¼Œç­‰å¾… {wait_seconds:.0f}ç§’ åˆ°ä¸‹ä¸€ä¸ª3åˆ†é’Ÿå‘¨æœŸ", flush=True)
        print(f"   ç›®æ ‡æ—¶é—´: {(target_time + timedelta(hours=8)).strftime('%H:%M:%S')} åŒ—äº¬æ—¶é—´", flush=True)
        time.sleep(wait_seconds)
    
    # ä¸»å¾ªç¯ï¼šå›ºå®š180ç§’é—´éš”
    while True:
        try:
            # æ‰§è¡Œæ•°æ®é‡‡é›†
            collect_time = datetime.now()
            beijing_time = (datetime.utcnow() + timedelta(hours=8)).strftime('%H:%M:%S')
            print(f"\nğŸ“¡ [{beijing_time}åŒ—äº¬] ===== å¼€å§‹æ•°æ®æ›´æ–° =====", flush=True)
            
            try:
                print("  â†³ æ›´æ–°é¦–é¡µç¼“å­˜...")
                update_cache()
                print("  âœ“ é¦–é¡µç¼“å­˜æ›´æ–°å®Œæˆ")
            except Exception as e:
                print(f"  âœ— é¦–é¡µç¼“å­˜æ›´æ–°å¤±è´¥: {e}")
            
            try:
                print("  â†³ åŒæ­¥ä¿¡å·ç»Ÿè®¡...")
                sync_signal_stats()
                print("  âœ“ ä¿¡å·ç»Ÿè®¡åŒæ­¥å®Œæˆ")
            except Exception as e:
                print(f"  âœ— ä¿¡å·ç»Ÿè®¡åŒæ­¥å¤±è´¥: {e}")
            
            try:
                print("  â†³ åŒæ­¥ææ…Œæ¸…æ´—æ•°æ®...")
                sync_panic_wash_data()
                print("  âœ“ ææ…Œæ¸…æ´—æ•°æ®åŒæ­¥å®Œæˆ")
            except Exception as e:
                print(f"  âœ— ææ…Œæ¸…æ´—æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            
            finish_time = datetime.now()
            duration = (finish_time - collect_time).total_seconds()
            
            # è®¡ç®—å®é™…åº”è¯¥ç­‰å¾…çš„æ—¶é—´ï¼ˆä»å‘¨æœŸå¼€å§‹è®¡ç®—ï¼‰
            sleep_time = max(0, UPDATE_CYCLE - duration)
            next_update_time = collect_time + timedelta(seconds=UPDATE_CYCLE)
            next_beijing = (next_update_time + timedelta(hours=8)).strftime('%H:%M:%S')
            
            print(f"\nâœ… [{beijing_time}åŒ—äº¬] æ•°æ®æ›´æ–°å®Œæˆ (è€—æ—¶: {duration:.1f}ç§’)", flush=True)
            print(f"â° ä¸‹æ¬¡æ›´æ–°æ—¶é—´: {next_beijing} åŒ—äº¬æ—¶é—´", flush=True)
            print(f"ğŸ’¤ ç­‰å¾… {sleep_time:.1f}ç§’ åˆ°ä¸‹ä¸€ä¸ªå‘¨æœŸ", flush=True)
            print("="*70 + "\n", flush=True)
            
            # ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªå‘¨æœŸï¼ˆä»å‘¨æœŸå¼€å§‹è®¡ç®—ï¼Œæ‰£é™¤å·²ç”¨æ—¶é—´ï¼‰
            time.sleep(sleep_time)
            
        except Exception as e:
            print(f"\nâŒ åå°æ›´æ–°çº¿ç¨‹é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            print(f"â° 60ç§’åé‡è¯•...\n")
            time.sleep(60)

@app.route('/')
def index():
    """é¦–é¡µ - å¯¼èˆªé¡µ"""
    return send_file('index.html')

@app.route('/live')
def live():
    """å®æ—¶ç›‘æ§é¡µé¢"""
    return send_file('crypto_home_v2.html')

@app.route('/history')
def history():
    """å†å²å›çœ‹é¡µé¢"""
    return send_file('history_viewer.html')

@app.route('/panic-wash')
def panic_wash():
    """ææ…Œæ¸…æ´—æŒ‡æ ‡ç›‘æ§é¡µé¢"""
    return send_file('panic_wash_monitor.html')

@app.route('/panic-wash-v3')
def panic_wash_v3():
    """ææ…Œæ¸…æ´—æŒ‡æ ‡ç›‘æ§é¡µé¢ V3 - åŒYè½´æ›²çº¿å›¾+å®Œæ•´æ•°æ®åˆ—è¡¨"""
    return send_file('panic_wash_monitor_v3.html')

@app.route('/panic-wash-history')
def panic_wash_history():
    """ææ…Œæ¸…æ´—å†å²æ›²çº¿é¡µé¢"""
    return send_file('panic_wash_history.html')

@app.route('/test-cache')
def test_cache():
    """ç¼“å­˜æµ‹è¯•é¡µé¢"""
    return send_file('test_cache.html')

@app.route('/test-coin-display')
def test_coin_display():
    """å¸åæ˜¾ç¤ºæµ‹è¯•é¡µé¢"""
    return send_file('test_coin_display.html')

@app.route('/coin-list-test')
def coin_list_test():
    """å¸ååˆ—è¡¨ç®€å•æµ‹è¯•é¡µé¢"""
    return send_file('coin_list_simple.html')

@app.route('/api/panic-wash')
def get_panic_wash_api():
    """ææ…Œæ¸…æ´—API - ç›´æ¥è¿”å›æ•°æ®"""
    try:
        try:
            from panic_wash_reader_v5 import get_panic_wash_data_sync
        except:
            try:
                from panic_wash_reader_v4 import get_panic_wash_data_sync
            except:
                from panic_wash_simple import get_panic_wash_data_sync
        data = get_panic_wash_data_sync()
        
        if data:
            return jsonify({
                'success': True,
                'data': data
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æš‚æ— æ•°æ®'
            }), 404
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/home-data')
def get_home_data():
    """è·å–é¦–é¡µæ•°æ®APIï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    try:
        # æ£€æŸ¥ç¼“å­˜
        if CACHE['data'] is None:
            # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œç«‹å³æ›´æ–°
            update_cache()
        elif CACHE['last_update'] and (time.time() - CACHE['last_update']) > CACHE_VALIDITY:
            # ç¼“å­˜è¿‡æœŸï¼Œè§¦å‘åå°æ›´æ–°ï¼ˆä½†ç«‹å³è¿”å›æ—§æ•°æ®ï¼‰
            threading.Thread(target=update_cache, daemon=True).start()
        
        if CACHE['data'] is None:
            return jsonify({
                'success': False,
                'error': 'æ•°æ®å°šæœªåŠ è½½'
            }), 503
        
        cached = CACHE['data']
        
        return jsonify({
            'success': True,
            'data': cached['parsed_data'],
            'filename': cached['filename'],
            'time_diff': cached['time_diff'],
            'cached_at': datetime.fromtimestamp(CACHE['last_update']).strftime('%Y-%m-%d %H:%M:%S') if CACHE['last_update'] else None
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/home-data/force-refresh')
def force_refresh_home_data():
    """å¼ºåˆ¶åˆ·æ–°é¦–é¡µæ•°æ®APIï¼ˆç»•è¿‡ç¼“å­˜ç«‹å³è·å–æœ€æ–°æ•°æ®ï¼‰"""
    try:
        print("ğŸ”„ æ”¶åˆ°å¼ºåˆ¶åˆ·æ–°è¯·æ±‚ï¼Œç«‹å³è·å–æœ€æ–°æ•°æ®...")
        update_cache()
        
        if CACHE['data'] is None:
            return jsonify({
                'success': False,
                'error': 'æ•°æ®åˆ·æ–°å¤±è´¥'
            }), 503
        
        cached = CACHE['data']
        
        return jsonify({
            'success': True,
            'data': cached['parsed_data'],
            'filename': cached['filename'],
            'time_diff': cached['time_diff'],
            'cached_at': datetime.fromtimestamp(CACHE['last_update']).strftime('%Y-%m-%d %H:%M:%S') if CACHE['last_update'] else None,
            'message': 'å·²å¼ºåˆ¶åˆ·æ–°æ•°æ®'
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== å†å²æ•°æ®API ====================

def query_history_data(start_time=None, end_time=None, limit=100):
    """æŸ¥è¯¢å†å²æ•°æ®"""
    import sqlite3
    conn = sqlite3.connect('crypto_data.db')
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    try:
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        where_clauses = []
        params = []
        
        if start_time:
            where_clauses.append('record_time >= ?')
            params.append(start_time)
        
        if end_time:
            where_clauses.append('record_time <= ?')
            params.append(end_time)
        
        where_sql = ' AND '.join(where_clauses) if where_clauses else '1=1'
        
        # æŸ¥è¯¢ç»Ÿè®¡æ•°æ®
        cursor.execute(f'''
            SELECT * FROM stats_history
            WHERE {where_sql}
            ORDER BY record_time DESC
            LIMIT ?
        ''', params + [limit])
        
        stats_records = [dict(row) for row in cursor.fetchall()]
        
        # ä¸ºæ¯æ¡ç»Ÿè®¡æ•°æ®æŸ¥è¯¢å¯¹åº”çš„å¸ç§æ•°æ®
        for record in stats_records:
            cursor.execute('''
                SELECT * FROM coin_history
                WHERE stats_id = ?
                ORDER BY index_num
            ''', (record['id'],))
            
            record['coins'] = [dict(row) for row in cursor.fetchall()]
        
        return stats_records
        
    finally:
        conn.close()

@app.route('/api/history/dates')
def get_dates():
    """è·å–æœ‰æ•°æ®çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        import sqlite3
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT DISTINCT DATE(record_time) as date
            FROM stats_history
            ORDER BY date DESC
        ''')
        
        dates = [row[0] for row in cursor.fetchall()]
        
        # è·å–æ¯ä¸ªæ—¥æœŸçš„ç»Ÿè®¡ä¿¡æ¯
        date_info = []
        for date in dates:
            cursor.execute('''
                SELECT COUNT(*) as count,
                       MIN(record_time) as min_time,
                       MAX(record_time) as max_time
                FROM stats_history
                WHERE DATE(record_time) = ?
            ''', (date,))
            
            row = cursor.fetchone()
            date_info.append({
                'date': date,
                'count': row[0],
                'min_time': row[1],
                'max_time': row[2]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'dates': date_info
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/history/query')
def query_history():
    """æŸ¥è¯¢å†å²æ•°æ®"""
    try:
        from flask import request
        
        # è·å–æŸ¥è¯¢å‚æ•°
        start_time = request.args.get('start_time')
        end_time = request.args.get('end_time')
        date = request.args.get('date')  # å¦‚æœåªæŸ¥è¯¢æŸä¸€å¤©
        limit = int(request.args.get('limit', 100))
        
        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œè‡ªåŠ¨è®¾ç½®æ—¶é—´èŒƒå›´
        if date:
            start_time = f"{date} 00:00:00"
            end_time = f"{date} 23:59:59"
        
        records = query_history_data(start_time, end_time, limit)
        
        return jsonify({
            'success': True,
            'count': len(records),
            'data': records,
            'query': {
                'start_time': start_time,
                'end_time': end_time,
                'limit': limit
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/history/stats')
def get_history_stats():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    try:
        import sqlite3
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM stats_history')
        stats_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM coin_history')
        coin_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT MIN(record_time), MAX(record_time) FROM stats_history')
        time_range = cursor.fetchone()
        
        cursor.execute('SELECT COUNT(DISTINCT DATE(record_time)) FROM stats_history')
        day_count = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'stats': {
                'total_records': stats_count,
                'total_coins': coin_count,
                'earliest': time_range[0],
                'latest': time_range[1],
                'days': day_count
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/import/current', methods=['POST'])
def import_current():
    """å¯¼å…¥å½“å‰æœ€æ–°æ•°æ®"""
    try:
        from import_history_simple import import_current_data
        asyncio.run(import_current_data())
        return jsonify({
            'success': True,
            'message': 'å¯¼å…¥æˆåŠŸ'
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ============== ä¿¡å·ç»Ÿè®¡å†å²API ==============

@app.route('/signal-history')
def signal_history_page():
    """ä¿¡å·ç»Ÿè®¡å†å²å›çœ‹é¡µé¢"""
    return send_file('signal_history_viewer.html')

@app.route('/api/signal-stats/save', methods=['POST'])
def save_signal_stats():
    """ä¿å­˜ä¿¡å·ç»Ÿè®¡æ•°æ®"""
    try:
        from flask import request
        import sqlite3
        
        data = request.json
        record_time = data.get('record_time')
        
        if not record_time:
            record_time = datetime.now().strftime('%Y-%m-%d %H:%M:00')
        
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO signal_stats_history 
            (record_time, total_count, long_count, short_count, 
             chaodi_count, dibu_count, dingbu_count, source_url)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            record_time,
            data.get('total', 0),
            data.get('long', 0),
            data.get('short', 0),
            data.get('chaodi', 0),
            data.get('dibu', 0),
            data.get('dingbu', 0),
            data.get('source_url', '')
        ))
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': 'ä¿å­˜æˆåŠŸ',
            'record_time': record_time
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/signal-stats/query')
def query_signal_stats():
    """æŸ¥è¯¢ä¿¡å·ç»Ÿè®¡å†å²æ•°æ®"""
    try:
        from flask import request
        import sqlite3
        
        date = request.args.get('date')
        start_time = request.args.get('start_time')
        end_time = request.args.get('end_time')
        limit = request.args.get('limit', 200, type=int)
        
        conn = sqlite3.connect('crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        where_clauses = []
        params = []
        
        if date:
            if start_time and end_time:
                where_clauses.append('record_time BETWEEN ? AND ?')
                params.extend([f'{date} {start_time}:00', f'{date} {end_time}:59'])
            else:
                where_clauses.append('DATE(record_time) = ?')
                params.append(date)
        
        where_sql = f"WHERE {' AND '.join(where_clauses)}" if where_clauses else ''
        
        query = f'''
            SELECT 
                record_time, total_count, long_count, short_count,
                chaodi_count, dibu_count, dingbu_count, source_url
            FROM signal_stats_history
            {where_sql}
            ORDER BY record_time DESC
            LIMIT ?
        '''
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        data = []
        for row in rows:
            data.append({
                'record_time': row['record_time'],
                'total': row['total_count'],
                'long': row['long_count'],
                'short': row['short_count'],
                'chaodi': row['chaodi_count'],
                'dibu': row['dibu_count'],
                'dingbu': row['dingbu_count'],
                'source_url': row['source_url']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'count': len(data),
            'data': data
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/signal-stats/stats')
def signal_stats_db_stats():
    """è·å–ä¿¡å·ç»Ÿè®¡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    try:
        import sqlite3
        
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM signal_stats_history')
        total = cursor.fetchone()[0]
        
        cursor.execute('SELECT MIN(record_time), MAX(record_time) FROM signal_stats_history')
        time_range = cursor.fetchone()
        
        conn.close()
        
        return jsonify({
            'success': True,
            'total_records': total,
            'time_range': {
                'start': time_range[0],
                'end': time_range[1]
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/signal-stats/latest')
def get_latest_signal_stats():
    """è·å–æœ€æ–°çš„ä¿¡å·ç»Ÿè®¡æ•°æ®"""
    try:
        import sqlite3
        
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æœ€æ–°çš„ä¸€æ¡è®°å½•
        cursor.execute('''
            SELECT long_count, short_count, record_time
            FROM signal_stats_history
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return jsonify({
                'success': True,
                'data': {
                    'long_count': row[0],
                    'short_count': row[1],
                    'record_time': row[2]
                }
            })
        else:
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›é»˜è®¤å€¼
            return jsonify({
                'success': True,
                'data': {
                    'long_count': 0,
                    'short_count': 0,
                    'record_time': None
                }
            })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/panic-wash/history')
def get_panic_wash_history():
    """æŸ¥è¯¢ææ…Œæ¸…æ´—å†å²æ•°æ®"""
    try:
        import sqlite3
        from flask import request
        
        # è·å–æŸ¥è¯¢å‚æ•°
        start_time = request.args.get('start')
        end_time = request.args.get('end')
        limit = request.args.get('limit', 1000)  # é»˜è®¤æœ€å¤šè¿”å›1000æ¡
        
        conn = sqlite3.connect('crypto_data.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢å†å²æ•°æ®
        if start_time and end_time:
            # æŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢
            cursor.execute('''
                SELECT 
                    record_time,
                    panic_indicator,
                    panic_color,
                    trend_rating,
                    market_zone,
                    liquidation_24h_people,
                    liquidation_24h_amount,
                    total_position
                FROM panic_wash_history
                WHERE record_time BETWEEN ? AND ?
                ORDER BY record_time DESC
                LIMIT ?
            ''', (start_time, end_time, limit))
        else:
            # æŸ¥è¯¢æ‰€æœ‰æ•°æ®ï¼ˆæˆ–æœ€è¿‘çš„limitæ¡ï¼‰
            cursor.execute('''
                SELECT 
                    record_time,
                    panic_indicator,
                    panic_color,
                    trend_rating,
                    market_zone,
                    liquidation_24h_people,
                    liquidation_24h_amount,
                    total_position
                FROM panic_wash_history
                ORDER BY record_time DESC
                LIMIT ?
            ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        # æ ¼å¼åŒ–æ•°æ®
        data = []
        for row in rows:
            # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆåªä¿ç•™æ—¶åˆ†ï¼‰
            time_str = row[0]  # 2025-12-03 15:09:05
            if len(time_str) >= 16:
                time_display = time_str[5:16]  # 12-03 15:09
            else:
                time_display = time_str
            
            # ç»„åˆææ…ŒæŒ‡æ ‡å’Œé¢œè‰²
            panic_indicator_full = f"{row[1]}-{row[2]}" if row[2] else str(row[1])
            
            data.append({
                'time': time_display,
                'record_time': row[0],
                'full_time': row[0],
                'panic_indicator': panic_indicator_full,
                'panic_indicator_value': row[1],
                'panic_color': row[2],
                'trend_rating': row[3],
                'market_zone': row[4],
                'liquidation_24h_people': row[5],
                'liquidation_24h_amount': row[6],
                'total_position': row[7]
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data)
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ============================================================
# æ¯”ä»·ç³»ç»Ÿé›†æˆ
# ============================================================

from price_comparison_system import PriceComparisonSystem

# åˆå§‹åŒ–æ¯”ä»·ç³»ç»Ÿ
price_comparison = PriceComparisonSystem()

@app.route('/price-comparison')
def price_comparison_page():
    """æ¯”ä»·ç³»ç»Ÿé¡µé¢"""
    return send_file('price_comparison.html')

@app.route('/api/price-comparison/report')
def get_price_comparison_report():
    """è·å–å®Œæ•´æ¯”ä»·æŠ¥å‘Š"""
    try:
        report = price_comparison.get_full_report()
        return jsonify(report)
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/price-comparison/baseline')
def get_baseline():
    """è·å–ä»·æ ¼åŸºå‡†æ•°æ®"""
    try:
        baseline = price_comparison.get_baseline_data()
        return jsonify({
            'success': True,
            'data': baseline
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/price-comparison/today')
def get_today_records():
    """è·å–ä»Šæ—¥åˆ›æ–°é«˜ä½è®°å½•"""
    try:
        records = price_comparison.get_daily_new_records()
        return jsonify({
            'success': True,
            'data': records
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def trigger_price_comparison(coins_data):
    """
    è§¦å‘æ¯”ä»·æ£€æŸ¥
    åœ¨æ•°æ®æ›´æ–°åè°ƒç”¨æ­¤å‡½æ•°
    """
    try:
        # æ‰¹é‡æ¯”ä»·
        results = price_comparison.batch_compare(coins_data)
        
        # ç»Ÿè®¡åˆ›æ–°é«˜ä½
        new_highs = [r for r in results if r['action'] == 'new_high']
        new_lows = [r for r in results if r['action'] == 'new_low']
        
        if new_highs or new_lows:
            print(f"\nğŸ“Š æ¯”ä»·ç»“æœ:")
            print(f"   ğŸ”¥ åˆ›æ–°é«˜: {len(new_highs)} ä¸ªå¸ç§")
            print(f"   ğŸ“‰ åˆ›æ–°ä½: {len(new_lows)} ä¸ªå¸ç§")
            
            # æ˜¾ç¤ºåˆ›æ–°é«˜
            for r in new_highs[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"      {r['symbol']}: {r['old_value']:.8f} â†’ {r['new_value']:.8f}")
            
            # æ˜¾ç¤ºåˆ›æ–°ä½
            for r in new_lows[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"      {r['symbol']}: {r['old_value']:.8f} â†’ {r['new_value']:.8f}")
        
        return results
    except Exception as e:
        print(f"âŒ æ¯”ä»·å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []

if __name__ == '__main__':
    print("="*60)
    print("é¦–é¡µæ•°æ®ç›‘æ§æœåŠ¡å™¨ V2 (å¸¦ç¼“å­˜)")
    print("="*60)
    print("è®¿é—®: http://0.0.0.0:5003/")
    print("ç¼“å­˜æœ‰æ•ˆæœŸ: 5 åˆ†é’Ÿ")
    print("="*60)
    
    # å¯åŠ¨åå°æ›´æ–°çº¿ç¨‹
    updater_thread = threading.Thread(target=background_updater, daemon=True)
    updater_thread.start()
    print("âœ… åå°æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨\n")
    
    app.run(host='0.0.0.0', port=5003, debug=False, threaded=True)
