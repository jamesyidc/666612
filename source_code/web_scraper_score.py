#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘é¡µæ•°æ®çˆ¬è™« - ä»ä¸¤ä¸ªå¾—åˆ†ç½‘é¡µæŠ“å–æ•°æ®å¹¶åˆå¹¶
"""

import requests
from bs4 import BeautifulSoup
import re
import json
from typing import Dict, List, Tuple
import time
from datetime import datetime

class ScoreWebScraper:
    """ä»ç½‘é¡µæŠ“å–å¾—åˆ†æ•°æ®"""
    
    def __init__(self):
        self.urls = {
            'source_1': 'https://3000-i42fq2f1mk8544uuc8pew-5c13a017.sandbox.novita.ai/score_overview.html',
            'source_2': 'https://3000-itkyuobnbphje7wgo4xbk-c07dda5e.sandbox.novita.ai/score_overview.html'
        }
        self.time_ranges = ['3m', '1h', '3h', '6h', '12h', '24h']
        self.timeout = 15
    
    def fetch_page(self, url: str) -> str:
        """è·å–ç½‘é¡µHTMLå†…å®¹"""
        try:
            print(f"ğŸ“¡ æ­£åœ¨è·å–: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=self.timeout)
            response.raise_for_status()
            print(f"âœ… æˆåŠŸè·å–ï¼Œå¤§å°: {len(response.text)} å­—èŠ‚")
            return response.text
        except Exception as e:
            print(f"âŒ è·å–å¤±è´¥: {e}")
            return None
    
    def parse_table_data(self, html: str, source_name: str) -> Dict:
        """è§£æHTMLè¡¨æ ¼æ•°æ®"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            data = {}
            
            # æŸ¥æ‰¾è¡¨æ ¼
            table = soup.find('table')
            if not table:
                print(f"âš ï¸ {source_name}: æœªæ‰¾åˆ°è¡¨æ ¼")
                return data
            
            # è§£æè¡¨å¤´ï¼Œæ‰¾åˆ°æ—¶é—´èŒƒå›´åˆ—çš„ä½ç½®
            headers = []
            thead = table.find('thead')
            if thead:
                header_row = thead.find_all('th')
                for th in header_row:
                    text = th.get_text(strip=True)
                    headers.append(text)
                print(f"ğŸ“‹ {source_name} è¡¨å¤´: {headers}")
            
            # è§£æè¡¨æ ¼æ•°æ®è¡Œ
            tbody = table.find('tbody')
            if not tbody:
                print(f"âš ï¸ {source_name}: æœªæ‰¾åˆ°è¡¨æ ¼æ•°æ®")
                return data
            
            rows = tbody.find_all('tr')
            print(f"ğŸ“Š {source_name}: æ‰¾åˆ° {len(rows)} è¡Œæ•°æ®")
            
            for row in rows:
                cells = row.find_all('td')
                if len(cells) < 2:
                    continue
                
                # ç¬¬ä¸€åˆ—æ˜¯å¸ç§åç§°
                coin_cell = cells[0]
                coin_name = coin_cell.get_text(strip=True)
                
                # æ ‡å‡†åŒ–å¸ç§åç§°
                if not coin_name.endswith('-USDT-SWAP'):
                    coin_name = f"{coin_name}-USDT-SWAP"
                
                data[coin_name] = {}
                
                # è§£æå„æ—¶é—´æ®µçš„æ•°æ®
                # é€šå¸¸æ ¼å¼æ˜¯ï¼šå¸ç§ | 3måšå¤š 3måšç©º 3må·®å€¼ | 1håšå¤š 1håšç©º 1hå·®å€¼ | ...
                cell_idx = 1
                for time_range in self.time_ranges:
                    if cell_idx + 2 < len(cells):
                        try:
                            # æå–åšå¤šã€åšç©ºã€å·®å€¼
                            long_text = cells[cell_idx].get_text(strip=True)
                            short_text = cells[cell_idx + 1].get_text(strip=True)
                            diff_text = cells[cell_idx + 2].get_text(strip=True)
                            
                            # æ¸…ç†æ•°æ®ï¼Œæå–æ•°å­—
                            long_score = self.extract_number(long_text)
                            short_score = self.extract_number(short_text)
                            diff_score = self.extract_number(diff_text)
                            
                            if long_score is not None and short_score is not None:
                                data[coin_name][time_range] = {
                                    'long_score': long_score,
                                    'short_score': short_score,
                                    'diff': diff_score if diff_score is not None else (long_score - short_score)
                                }
                        except Exception as e:
                            print(f"âš ï¸ è§£æ {coin_name} {time_range} æ•°æ®å¤±è´¥: {e}")
                        
                        cell_idx += 3
            
            return data
            
        except Exception as e:
            print(f"âŒ {source_name} è§£æå¤±è´¥: {e}")
            return {}
    
    def extract_number(self, text: str) -> float:
        """ä»æ–‡æœ¬ä¸­æå–æ•°å­—"""
        if not text:
            return None
        
        # ç§»é™¤æ‰€æœ‰éæ•°å­—å’Œå°æ•°ç‚¹ã€è´Ÿå·çš„å­—ç¬¦
        cleaned = re.sub(r'[^\d.\-+]', '', text)
        if not cleaned or cleaned in ['-', '+', '.']:
            return None
        
        try:
            return float(cleaned)
        except:
            return None
    
    def scrape_all_sources(self) -> Dict:
        """æŠ“å–æ‰€æœ‰æ•°æ®æº"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹æŠ“å–ç½‘é¡µæ•°æ®")
        print("="*80 + "\n")
        
        all_data = {}
        
        # æŠ“å–ç¬¬ä¸€ä¸ªæ•°æ®æºï¼ˆ19ç§å¸ï¼‰
        print("\nğŸ“Œ æ•°æ®æº1ï¼ˆ19ç§å¸ï¼‰")
        html1 = self.fetch_page(self.urls['source_1'])
        if html1:
            data1 = self.parse_table_data(html1, 'source_1')
            print(f"âœ… æ•°æ®æº1: è·å–åˆ° {len(data1)} ä¸ªå¸ç§")
            all_data.update(data1)
        else:
            print("âŒ æ•°æ®æº1: æ— æ³•è·å–æ•°æ®")
        
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        # æŠ“å–ç¬¬äºŒä¸ªæ•°æ®æºï¼ˆ8ç§å¸ï¼‰
        print("\nğŸ“Œ æ•°æ®æº2ï¼ˆ8ç§å¸ï¼‰")
        html2 = self.fetch_page(self.urls['source_2'])
        if html2:
            data2 = self.parse_table_data(html2, 'source_2')
            print(f"âœ… æ•°æ®æº2: è·å–åˆ° {len(data2)} ä¸ªå¸ç§")
            
            # åˆå¹¶æ•°æ®ï¼ˆå¦‚æœæœ‰é‡å¤å¸ç§ï¼Œä¿ç•™ç¬¬ä¸€ä¸ªæ•°æ®æºçš„æ•°æ®ï¼‰
            for coin, scores in data2.items():
                if coin not in all_data:
                    all_data[coin] = scores
                else:
                    print(f"â„¹ï¸  {coin}: å·²å­˜åœ¨ï¼Œè·³è¿‡")
        else:
            print("âŒ æ•°æ®æº2: æ— æ³•è·å–æ•°æ®")
        
        print("\n" + "="*80)
        print(f"âœ… æŠ“å–å®Œæˆ: æ€»è®¡ {len(all_data)} ä¸ªå¸ç§")
        print("="*80 + "\n")
        
        return all_data
    
    def calculate_statistics(self, all_data: Dict) -> List[Dict]:
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        statistics = []
        
        for time_range in self.time_ranges:
            long_scores = []
            short_scores = []
            diffs = []
            
            for coin, scores in all_data.items():
                if time_range in scores:
                    score_data = scores[time_range]
                    long_scores.append(score_data['long_score'])
                    short_scores.append(score_data['short_score'])
                    diffs.append(score_data['diff'])
            
            if long_scores and short_scores:
                avg_long = sum(long_scores) / len(long_scores)
                avg_short = sum(short_scores) / len(short_scores)
                avg_diff = sum(diffs) / len(diffs)
                
                statistics.append({
                    'time_range': time_range,
                    'avg_long_score': round(avg_long, 2),
                    'avg_short_score': round(avg_short, 2),
                    'avg_diff': round(avg_diff, 2),
                    'coin_count': len(long_scores),
                    'trend': 'ğŸ“ˆ çœ‹å¤š' if avg_diff > 0 else 'ğŸ“‰ çœ‹ç©º'
                })
        
        return statistics
    
    def print_statistics(self, statistics: List[Dict]):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print("\n" + "â•”" + "â•"*78 + "â•—")
        print("â•‘" + "åˆå¹¶åçš„ç»Ÿè®¡æ•°æ®".center(78) + "â•‘")
        print("â• " + "â•"*78 + "â•£")
        
        time_labels = {
            '3m': '3åˆ†é’Ÿ',
            '1h': '1å°æ—¶',
            '3h': '3å°æ—¶',
            '6h': '6å°æ—¶',
            '12h': '12å°æ—¶',
            '24h': '24å°æ—¶'
        }
        
        print("â•‘" + "æ—¶é—´æ®µ".center(10) + "â”‚" + "å¹³å‡åšå¤š".center(12) + "â”‚" + 
              "å¹³å‡åšç©º".center(12) + "â”‚" + "å¹³å‡å·®å€¼".center(12) + "â”‚" + 
              "å¸ç§æ•°".center(8) + "â”‚" + "è¶‹åŠ¿".center(10) + "â•‘")
        print("â• " + "â”€"*10 + "â”¼" + "â”€"*12 + "â”¼" + "â”€"*12 + "â”¼" + 
              "â”€"*12 + "â”¼" + "â”€"*8 + "â”¼" + "â”€"*10 + "â•£")
        
        for stat in statistics:
            tr = time_labels.get(stat['time_range'], stat['time_range'])
            long_score = f"{stat['avg_long_score']:.2f}"
            short_score = f"{stat['avg_short_score']:.2f}"
            diff = f"{stat['avg_diff']:+.2f}"
            count = str(stat['coin_count'])
            trend = 'ğŸ“ˆ' if stat['avg_diff'] > 0 else 'ğŸ“‰'
            
            print(f"â•‘ {tr:>8s} â”‚ {long_score:>10s} â”‚ {short_score:>10s} â”‚ " +
                  f"{diff:>10s} â”‚ {count:>6s} â”‚ {trend:^8s} â•‘")
        
        print("â•š" + "â•"*78 + "â•\n")


def main():
    """ä¸»å‡½æ•°"""
    scraper = ScoreWebScraper()
    
    # æŠ“å–æ‰€æœ‰æ•°æ®
    all_data = scraper.scrape_all_sources()
    
    if not all_data:
        print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
        return
    
    # æ‰“å°å¸ç§åˆ—è¡¨
    print("\nğŸ“‹ è·å–åˆ°çš„å¸ç§åˆ—è¡¨:")
    for i, coin in enumerate(sorted(all_data.keys()), 1):
        time_ranges = list(all_data[coin].keys())
        print(f"  {i:2d}. {coin:20s} - {len(time_ranges)} ä¸ªæ—¶é—´æ®µ")
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    print("\nğŸ“Š è®¡ç®—ç»Ÿè®¡æ•°æ®...")
    statistics = scraper.calculate_statistics(all_data)
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    scraper.print_statistics(statistics)
    
    # ä¿å­˜æ•°æ®åˆ°JSON
    output_data = {
        'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'statistics': statistics,
        'coins': all_data
    }
    
    with open('scraped_score_data.json', 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: scraped_score_data.json\n")


if __name__ == '__main__':
    main()
